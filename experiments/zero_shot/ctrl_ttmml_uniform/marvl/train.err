WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

12/02/2021 16:55:54 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
12/02/2021 16:55:55 - INFO - volta.task_utils -   Loading NLVR2 Dataset with batch size 16
12/02/2021 16:55:55 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/iglue/marvl/ctrl_xuniter_base/NLVR2_ctrl_xuniter_base
12/02/2021 16:55:55 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/iglue/pretrain/ctrl_xuniter/ctrl_xuniter_base/pytorch_model_9.bin
12/02/2021 16:56:14 - INFO - volta.utils -   
12/02/2021 16:56:14 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
12/02/2021 16:56:14 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
12/02/2021 16:56:22 - INFO - __main__ -   ** ** * Saving model * ** ** 
/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
12/02/2021 16:56:34 - INFO - __main__ -   >> Parameters:
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |Name                                                       |Dtype            |Shape            |#Params      |Trainable|
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.word_embeddings.weight                     |torch.float32    |(250002, 768)    |192001536    |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.position_embeddings.weight                 |torch.float32    |(514, 768)       |394752       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.token_type_embeddings.weight               |torch.float32    |(1, 768)         |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)         |3840         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_token_type_embeddings.weight         |torch.float32    |(1, 768)         |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.t_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.t_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.v_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |bert.v_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.weight                         |torch.float32    |(1536, 2048)     |3145728      |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.bias                           |torch.float32    |(1536,)          |1536         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.weight                         |torch.float32    |(1536,)          |1536         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.bias                           |torch.float32    |(1536,)          |1536         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.weight                         |torch.float32    |(2, 1536)        |3072         |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.bias                           |torch.float32    |(2,)             |2            |True    |
12/02/2021 16:56:34 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 16:56:34 - INFO - __main__ -   >> # TrainableParams:       	283.76	M
12/02/2021 16:56:34 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
12/02/2021 16:56:34 - INFO - __main__ -   >> # TotalParams:           	283.76	M
Epoch:   0%|          | 0/20 [00:00<?, ?it/s]/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
12/02/2021 16:56:57 - INFO - volta.train_utils -   [NLVR2]: iter 80 Ep: 0.01 loss 0.047 score 0.121 lr 9.72582e-09 
12/02/2021 16:57:18 - INFO - volta.train_utils -   [NLVR2]: iter 160 Ep: 0.03 loss 0.048 score 0.123 lr 2.82512e-08 
12/02/2021 16:57:40 - INFO - volta.train_utils -   [NLVR2]: iter 240 Ep: 0.04 loss 0.046 score 0.126 lr 4.67766e-08 
12/02/2021 16:58:02 - INFO - volta.train_utils -   [NLVR2]: iter 320 Ep: 0.06 loss 0.047 score 0.121 lr 6.5302e-08 
12/02/2021 16:58:24 - INFO - volta.train_utils -   [NLVR2]: iter 400 Ep: 0.07 loss 0.048 score 0.122 lr 8.38273e-08 
12/02/2021 16:58:46 - INFO - volta.train_utils -   [NLVR2]: iter 480 Ep: 0.09 loss 0.047 score 0.122 lr 1.02353e-07 
12/02/2021 16:59:08 - INFO - volta.train_utils -   [NLVR2]: iter 560 Ep: 0.10 loss 0.045 score 0.124 lr 1.20878e-07 
12/02/2021 16:59:29 - INFO - volta.train_utils -   [NLVR2]: iter 640 Ep: 0.12 loss 0.045 score 0.128 lr 1.39403e-07 
12/02/2021 16:59:51 - INFO - volta.train_utils -   [NLVR2]: iter 720 Ep: 0.13 loss 0.046 score 0.120 lr 1.57929e-07 
12/02/2021 17:00:13 - INFO - volta.train_utils -   [NLVR2]: iter 800 Ep: 0.15 loss 0.046 score 0.126 lr 1.76454e-07 
12/02/2021 17:00:35 - INFO - volta.train_utils -   [NLVR2]: iter 880 Ep: 0.16 loss 0.044 score 0.132 lr 1.9498e-07 
12/02/2021 17:00:57 - INFO - volta.train_utils -   [NLVR2]: iter 960 Ep: 0.18 loss 0.047 score 0.127 lr 2.13505e-07 
12/02/2021 17:01:19 - INFO - volta.train_utils -   [NLVR2]: iter 1040 Ep: 0.19 loss 0.046 score 0.126 lr 2.3203e-07 
12/02/2021 17:01:40 - INFO - volta.train_utils -   [NLVR2]: iter 1120 Ep: 0.21 loss 0.047 score 0.124 lr 2.50556e-07 
12/02/2021 17:02:02 - INFO - volta.train_utils -   [NLVR2]: iter 1200 Ep: 0.22 loss 0.045 score 0.129 lr 2.69081e-07 
12/02/2021 17:02:24 - INFO - volta.train_utils -   [NLVR2]: iter 1280 Ep: 0.24 loss 0.045 score 0.128 lr 2.87607e-07 
12/02/2021 17:02:46 - INFO - volta.train_utils -   [NLVR2]: iter 1360 Ep: 0.25 loss 0.047 score 0.129 lr 3.06132e-07 
12/02/2021 17:03:08 - INFO - volta.train_utils -   [NLVR2]: iter 1440 Ep: 0.27 loss 0.045 score 0.129 lr 3.24657e-07 
12/02/2021 17:03:30 - INFO - volta.train_utils -   [NLVR2]: iter 1520 Ep: 0.28 loss 0.046 score 0.130 lr 3.43183e-07 
12/02/2021 17:03:52 - INFO - volta.train_utils -   [NLVR2]: iter 1600 Ep: 0.30 loss 0.045 score 0.128 lr 3.61708e-07 
12/02/2021 17:04:14 - INFO - volta.train_utils -   [NLVR2]: iter 1680 Ep: 0.31 loss 0.046 score 0.125 lr 3.80233e-07 
12/02/2021 17:04:35 - INFO - volta.train_utils -   [NLVR2]: iter 1760 Ep: 0.33 loss 0.045 score 0.128 lr 3.98759e-07 
12/02/2021 17:04:57 - INFO - volta.train_utils -   [NLVR2]: iter 1840 Ep: 0.34 loss 0.045 score 0.128 lr 4.17284e-07 
12/02/2021 17:05:19 - INFO - volta.train_utils -   [NLVR2]: iter 1920 Ep: 0.36 loss 0.045 score 0.128 lr 4.3581e-07 
12/02/2021 17:05:41 - INFO - volta.train_utils -   [NLVR2]: iter 2000 Ep: 0.37 loss 0.045 score 0.127 lr 4.54335e-07 
12/02/2021 17:06:03 - INFO - volta.train_utils -   [NLVR2]: iter 2080 Ep: 0.39 loss 0.044 score 0.135 lr 4.7286e-07 
12/02/2021 17:06:25 - INFO - volta.train_utils -   [NLVR2]: iter 2160 Ep: 0.40 loss 0.044 score 0.133 lr 4.91386e-07 
12/02/2021 17:06:47 - INFO - volta.train_utils -   [NLVR2]: iter 2240 Ep: 0.41 loss 0.045 score 0.127 lr 5.09911e-07 
12/02/2021 17:07:08 - INFO - volta.train_utils -   [NLVR2]: iter 2320 Ep: 0.43 loss 0.044 score 0.134 lr 5.28436e-07 
12/02/2021 17:07:30 - INFO - volta.train_utils -   [NLVR2]: iter 2400 Ep: 0.44 loss 0.044 score 0.132 lr 5.46962e-07 
12/02/2021 17:07:52 - INFO - volta.train_utils -   [NLVR2]: iter 2480 Ep: 0.46 loss 0.044 score 0.125 lr 5.65487e-07 
12/02/2021 17:08:14 - INFO - volta.train_utils -   [NLVR2]: iter 2560 Ep: 0.47 loss 0.044 score 0.130 lr 5.84013e-07 
12/02/2021 17:08:36 - INFO - volta.train_utils -   [NLVR2]: iter 2640 Ep: 0.49 loss 0.044 score 0.134 lr 6.02538e-07 
12/02/2021 17:08:58 - INFO - volta.train_utils -   [NLVR2]: iter 2720 Ep: 0.50 loss 0.043 score 0.136 lr 6.21063e-07 
12/02/2021 17:09:19 - INFO - volta.train_utils -   [NLVR2]: iter 2800 Ep: 0.52 loss 0.044 score 0.138 lr 6.39589e-07 
12/02/2021 17:09:41 - INFO - volta.train_utils -   [NLVR2]: iter 2880 Ep: 0.53 loss 0.044 score 0.126 lr 6.58114e-07 
12/02/2021 17:10:03 - INFO - volta.train_utils -   [NLVR2]: iter 2960 Ep: 0.55 loss 0.044 score 0.136 lr 6.76639e-07 
12/02/2021 17:10:25 - INFO - volta.train_utils -   [NLVR2]: iter 3040 Ep: 0.56 loss 0.045 score 0.132 lr 6.95165e-07 
12/02/2021 17:10:47 - INFO - volta.train_utils -   [NLVR2]: iter 3120 Ep: 0.58 loss 0.044 score 0.132 lr 7.1369e-07 
12/02/2021 17:11:08 - INFO - volta.train_utils -   [NLVR2]: iter 3200 Ep: 0.59 loss 0.044 score 0.133 lr 7.32216e-07 
12/02/2021 17:11:30 - INFO - volta.train_utils -   [NLVR2]: iter 3280 Ep: 0.61 loss 0.044 score 0.129 lr 7.50741e-07 
12/02/2021 17:11:52 - INFO - volta.train_utils -   [NLVR2]: iter 3360 Ep: 0.62 loss 0.044 score 0.134 lr 7.69266e-07 
12/02/2021 17:12:13 - INFO - volta.train_utils -   [NLVR2]: iter 3440 Ep: 0.64 loss 0.043 score 0.129 lr 7.87792e-07 
12/02/2021 17:12:35 - INFO - volta.train_utils -   [NLVR2]: iter 3520 Ep: 0.65 loss 0.044 score 0.132 lr 8.06317e-07 
12/02/2021 17:12:57 - INFO - volta.train_utils -   [NLVR2]: iter 3600 Ep: 0.67 loss 0.043 score 0.137 lr 8.24843e-07 
12/02/2021 17:13:19 - INFO - volta.train_utils -   [NLVR2]: iter 3680 Ep: 0.68 loss 0.043 score 0.138 lr 8.43368e-07 
12/02/2021 17:13:41 - INFO - volta.train_utils -   [NLVR2]: iter 3760 Ep: 0.70 loss 0.044 score 0.131 lr 8.61893e-07 
12/02/2021 17:14:02 - INFO - volta.train_utils -   [NLVR2]: iter 3840 Ep: 0.71 loss 0.043 score 0.133 lr 8.80419e-07 
12/02/2021 17:14:24 - INFO - volta.train_utils -   [NLVR2]: iter 3920 Ep: 0.73 loss 0.044 score 0.127 lr 8.98944e-07 
12/02/2021 17:14:46 - INFO - volta.train_utils -   [NLVR2]: iter 4000 Ep: 0.74 loss 0.044 score 0.133 lr 9.17469e-07 
12/02/2021 17:15:08 - INFO - volta.train_utils -   [NLVR2]: iter 4080 Ep: 0.76 loss 0.043 score 0.131 lr 9.35995e-07 
12/02/2021 17:15:30 - INFO - volta.train_utils -   [NLVR2]: iter 4160 Ep: 0.77 loss 0.044 score 0.138 lr 9.5452e-07 
12/02/2021 17:15:51 - INFO - volta.train_utils -   [NLVR2]: iter 4240 Ep: 0.79 loss 0.043 score 0.134 lr 9.73046e-07 
12/02/2021 17:16:13 - INFO - volta.train_utils -   [NLVR2]: iter 4320 Ep: 0.80 loss 0.043 score 0.136 lr 9.91571e-07 
12/02/2021 17:16:35 - INFO - volta.train_utils -   [NLVR2]: iter 4400 Ep: 0.82 loss 0.042 score 0.135 lr 1.0101e-06 
12/02/2021 17:16:57 - INFO - volta.train_utils -   [NLVR2]: iter 4480 Ep: 0.83 loss 0.042 score 0.140 lr 1.02862e-06 
12/02/2021 17:17:18 - INFO - volta.train_utils -   [NLVR2]: iter 4560 Ep: 0.84 loss 0.044 score 0.136 lr 1.04715e-06 
12/02/2021 17:17:40 - INFO - volta.train_utils -   [NLVR2]: iter 4640 Ep: 0.86 loss 0.044 score 0.132 lr 1.06567e-06 
12/02/2021 17:18:02 - INFO - volta.train_utils -   [NLVR2]: iter 4720 Ep: 0.87 loss 0.043 score 0.137 lr 1.0842e-06 
12/02/2021 17:18:24 - INFO - volta.train_utils -   [NLVR2]: iter 4800 Ep: 0.89 loss 0.044 score 0.142 lr 1.10272e-06 
12/02/2021 17:18:46 - INFO - volta.train_utils -   [NLVR2]: iter 4880 Ep: 0.90 loss 0.043 score 0.137 lr 1.12125e-06 
12/02/2021 17:19:08 - INFO - volta.train_utils -   [NLVR2]: iter 4960 Ep: 0.92 loss 0.044 score 0.133 lr 1.13977e-06 
12/02/2021 17:19:29 - INFO - volta.train_utils -   [NLVR2]: iter 5040 Ep: 0.93 loss 0.043 score 0.137 lr 1.1583e-06 
12/02/2021 17:19:51 - INFO - volta.train_utils -   [NLVR2]: iter 5120 Ep: 0.95 loss 0.042 score 0.141 lr 1.17682e-06 
12/02/2021 17:20:13 - INFO - volta.train_utils -   [NLVR2]: iter 5200 Ep: 0.96 loss 0.042 score 0.143 lr 1.19535e-06 
12/02/2021 17:20:35 - INFO - volta.train_utils -   [NLVR2]: iter 5280 Ep: 0.98 loss 0.043 score 0.138 lr 1.21388e-06 
12/02/2021 17:20:57 - INFO - volta.train_utils -   [NLVR2]: iter 5360 Ep: 0.99 loss 0.043 score 0.135 lr 1.2324e-06 
12/02/2021 17:21:52 - INFO - volta.train_utils -   Eval task TASK12 on iteration 5396 
12/02/2021 17:21:52 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.672 score 57.942 
12/02/2021 17:21:52 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:   5%|▌         | 1/20 [25:52<8:11:33, 1552.27s/it]12/02/2021 17:22:49 - INFO - volta.train_utils -   [NLVR2]: iter 5476 Ep: 1.01 loss 0.042 score 0.143 lr 1.25509e-06 
12/02/2021 17:23:11 - INFO - volta.train_utils -   [NLVR2]: iter 5556 Ep: 1.03 loss 0.043 score 0.140 lr 1.27779e-06 
12/02/2021 17:23:33 - INFO - volta.train_utils -   [NLVR2]: iter 5636 Ep: 1.04 loss 0.043 score 0.141 lr 1.29631e-06 
12/02/2021 17:23:55 - INFO - volta.train_utils -   [NLVR2]: iter 5716 Ep: 1.06 loss 0.042 score 0.143 lr 1.31484e-06 
12/02/2021 17:24:17 - INFO - volta.train_utils -   [NLVR2]: iter 5796 Ep: 1.07 loss 0.042 score 0.132 lr 1.33336e-06 
12/02/2021 17:24:39 - INFO - volta.train_utils -   [NLVR2]: iter 5876 Ep: 1.09 loss 0.043 score 0.143 lr 1.35189e-06 
12/02/2021 17:25:01 - INFO - volta.train_utils -   [NLVR2]: iter 5956 Ep: 1.10 loss 0.042 score 0.141 lr 1.37041e-06 
12/02/2021 17:25:23 - INFO - volta.train_utils -   [NLVR2]: iter 6036 Ep: 1.12 loss 0.042 score 0.142 lr 1.38894e-06 
12/02/2021 17:25:44 - INFO - volta.train_utils -   [NLVR2]: iter 6116 Ep: 1.13 loss 0.043 score 0.139 lr 1.40747e-06 
12/02/2021 17:26:06 - INFO - volta.train_utils -   [NLVR2]: iter 6196 Ep: 1.15 loss 0.044 score 0.135 lr 1.42599e-06 
12/02/2021 17:26:28 - INFO - volta.train_utils -   [NLVR2]: iter 6276 Ep: 1.16 loss 0.042 score 0.146 lr 1.44452e-06 
12/02/2021 17:26:50 - INFO - volta.train_utils -   [NLVR2]: iter 6356 Ep: 1.18 loss 0.042 score 0.141 lr 1.46304e-06 
12/02/2021 17:27:12 - INFO - volta.train_utils -   [NLVR2]: iter 6436 Ep: 1.19 loss 0.043 score 0.148 lr 1.48157e-06 
12/02/2021 17:27:34 - INFO - volta.train_utils -   [NLVR2]: iter 6516 Ep: 1.21 loss 0.043 score 0.142 lr 1.50009e-06 
12/02/2021 17:27:56 - INFO - volta.train_utils -   [NLVR2]: iter 6596 Ep: 1.22 loss 0.041 score 0.142 lr 1.51862e-06 
12/02/2021 17:28:18 - INFO - volta.train_utils -   [NLVR2]: iter 6676 Ep: 1.24 loss 0.042 score 0.144 lr 1.53714e-06 
12/02/2021 17:28:40 - INFO - volta.train_utils -   [NLVR2]: iter 6756 Ep: 1.25 loss 0.042 score 0.145 lr 1.55567e-06 
12/02/2021 17:29:02 - INFO - volta.train_utils -   [NLVR2]: iter 6836 Ep: 1.27 loss 0.040 score 0.145 lr 1.57419e-06 
12/02/2021 17:29:24 - INFO - volta.train_utils -   [NLVR2]: iter 6916 Ep: 1.28 loss 0.041 score 0.148 lr 1.59272e-06 
12/02/2021 17:29:45 - INFO - volta.train_utils -   [NLVR2]: iter 6996 Ep: 1.30 loss 0.039 score 0.148 lr 1.61124e-06 
12/02/2021 17:30:07 - INFO - volta.train_utils -   [NLVR2]: iter 7076 Ep: 1.31 loss 0.040 score 0.149 lr 1.62977e-06 
12/02/2021 17:30:29 - INFO - volta.train_utils -   [NLVR2]: iter 7156 Ep: 1.33 loss 0.041 score 0.149 lr 1.6483e-06 
12/02/2021 17:30:51 - INFO - volta.train_utils -   [NLVR2]: iter 7236 Ep: 1.34 loss 0.041 score 0.153 lr 1.66682e-06 
12/02/2021 17:31:13 - INFO - volta.train_utils -   [NLVR2]: iter 7316 Ep: 1.36 loss 0.041 score 0.151 lr 1.68535e-06 
12/02/2021 17:31:35 - INFO - volta.train_utils -   [NLVR2]: iter 7396 Ep: 1.37 loss 0.040 score 0.148 lr 1.70387e-06 
12/02/2021 17:31:57 - INFO - volta.train_utils -   [NLVR2]: iter 7476 Ep: 1.38 loss 0.041 score 0.147 lr 1.7224e-06 
12/02/2021 17:32:19 - INFO - volta.train_utils -   [NLVR2]: iter 7556 Ep: 1.40 loss 0.042 score 0.140 lr 1.74092e-06 
12/02/2021 17:32:41 - INFO - volta.train_utils -   [NLVR2]: iter 7636 Ep: 1.41 loss 0.040 score 0.149 lr 1.75945e-06 
12/02/2021 17:33:02 - INFO - volta.train_utils -   [NLVR2]: iter 7716 Ep: 1.43 loss 0.042 score 0.146 lr 1.77797e-06 
12/02/2021 17:33:24 - INFO - volta.train_utils -   [NLVR2]: iter 7796 Ep: 1.44 loss 0.041 score 0.149 lr 1.7965e-06 
12/02/2021 17:33:46 - INFO - volta.train_utils -   [NLVR2]: iter 7876 Ep: 1.46 loss 0.040 score 0.153 lr 1.81502e-06 
12/02/2021 17:34:08 - INFO - volta.train_utils -   [NLVR2]: iter 7956 Ep: 1.47 loss 0.039 score 0.151 lr 1.83355e-06 
12/02/2021 17:34:30 - INFO - volta.train_utils -   [NLVR2]: iter 8036 Ep: 1.49 loss 0.041 score 0.151 lr 1.85207e-06 
12/02/2021 17:34:52 - INFO - volta.train_utils -   [NLVR2]: iter 8116 Ep: 1.50 loss 0.039 score 0.155 lr 1.8706e-06 
12/02/2021 17:35:13 - INFO - volta.train_utils -   [NLVR2]: iter 8196 Ep: 1.52 loss 0.040 score 0.154 lr 1.88913e-06 
12/02/2021 17:35:35 - INFO - volta.train_utils -   [NLVR2]: iter 8276 Ep: 1.53 loss 0.040 score 0.149 lr 1.90765e-06 
12/02/2021 17:35:57 - INFO - volta.train_utils -   [NLVR2]: iter 8356 Ep: 1.55 loss 0.040 score 0.154 lr 1.92618e-06 
12/02/2021 17:36:19 - INFO - volta.train_utils -   [NLVR2]: iter 8436 Ep: 1.56 loss 0.040 score 0.154 lr 1.9447e-06 
12/02/2021 17:36:41 - INFO - volta.train_utils -   [NLVR2]: iter 8516 Ep: 1.58 loss 0.040 score 0.149 lr 1.96323e-06 
12/02/2021 17:37:03 - INFO - volta.train_utils -   [NLVR2]: iter 8596 Ep: 1.59 loss 0.041 score 0.149 lr 1.98175e-06 
12/02/2021 17:37:25 - INFO - volta.train_utils -   [NLVR2]: iter 8676 Ep: 1.61 loss 0.041 score 0.147 lr 2.00028e-06 
12/02/2021 17:37:47 - INFO - volta.train_utils -   [NLVR2]: iter 8756 Ep: 1.62 loss 0.041 score 0.151 lr 2.0188e-06 
12/02/2021 17:38:08 - INFO - volta.train_utils -   [NLVR2]: iter 8836 Ep: 1.64 loss 0.040 score 0.150 lr 2.03733e-06 
12/02/2021 17:38:30 - INFO - volta.train_utils -   [NLVR2]: iter 8916 Ep: 1.65 loss 0.041 score 0.149 lr 2.05585e-06 
12/02/2021 17:38:52 - INFO - volta.train_utils -   [NLVR2]: iter 8996 Ep: 1.67 loss 0.039 score 0.150 lr 2.07438e-06 
12/02/2021 17:39:14 - INFO - volta.train_utils -   [NLVR2]: iter 9076 Ep: 1.68 loss 0.041 score 0.153 lr 2.0929e-06 
12/02/2021 17:39:36 - INFO - volta.train_utils -   [NLVR2]: iter 9156 Ep: 1.70 loss 0.041 score 0.157 lr 2.11143e-06 
12/02/2021 17:39:58 - INFO - volta.train_utils -   [NLVR2]: iter 9236 Ep: 1.71 loss 0.041 score 0.149 lr 2.12996e-06 
12/02/2021 17:40:20 - INFO - volta.train_utils -   [NLVR2]: iter 9316 Ep: 1.73 loss 0.040 score 0.156 lr 2.14848e-06 
12/02/2021 17:40:41 - INFO - volta.train_utils -   [NLVR2]: iter 9396 Ep: 1.74 loss 0.041 score 0.148 lr 2.16701e-06 
12/02/2021 17:41:03 - INFO - volta.train_utils -   [NLVR2]: iter 9476 Ep: 1.76 loss 0.040 score 0.160 lr 2.18553e-06 
12/02/2021 17:41:25 - INFO - volta.train_utils -   [NLVR2]: iter 9556 Ep: 1.77 loss 0.038 score 0.154 lr 2.20406e-06 
12/02/2021 17:41:47 - INFO - volta.train_utils -   [NLVR2]: iter 9636 Ep: 1.79 loss 0.038 score 0.159 lr 2.22258e-06 
12/02/2021 17:42:09 - INFO - volta.train_utils -   [NLVR2]: iter 9716 Ep: 1.80 loss 0.040 score 0.152 lr 2.24111e-06 
12/02/2021 17:42:31 - INFO - volta.train_utils -   [NLVR2]: iter 9796 Ep: 1.81 loss 0.040 score 0.157 lr 2.25963e-06 
12/02/2021 17:42:53 - INFO - volta.train_utils -   [NLVR2]: iter 9876 Ep: 1.83 loss 0.039 score 0.161 lr 2.27816e-06 
12/02/2021 17:43:15 - INFO - volta.train_utils -   [NLVR2]: iter 9956 Ep: 1.84 loss 0.038 score 0.157 lr 2.29668e-06 
12/02/2021 17:43:37 - INFO - volta.train_utils -   [NLVR2]: iter 10036 Ep: 1.86 loss 0.039 score 0.157 lr 2.31521e-06 
12/02/2021 17:43:59 - INFO - volta.train_utils -   [NLVR2]: iter 10116 Ep: 1.87 loss 0.039 score 0.161 lr 2.33373e-06 
12/02/2021 17:44:20 - INFO - volta.train_utils -   [NLVR2]: iter 10196 Ep: 1.89 loss 0.040 score 0.154 lr 2.35226e-06 
12/02/2021 17:44:42 - INFO - volta.train_utils -   [NLVR2]: iter 10276 Ep: 1.90 loss 0.040 score 0.152 lr 2.37079e-06 
12/02/2021 17:45:04 - INFO - volta.train_utils -   [NLVR2]: iter 10356 Ep: 1.92 loss 0.038 score 0.160 lr 2.38931e-06 
12/02/2021 17:45:26 - INFO - volta.train_utils -   [NLVR2]: iter 10436 Ep: 1.93 loss 0.041 score 0.153 lr 2.40784e-06 
12/02/2021 17:45:48 - INFO - volta.train_utils -   [NLVR2]: iter 10516 Ep: 1.95 loss 0.039 score 0.159 lr 2.42636e-06 
12/02/2021 17:46:10 - INFO - volta.train_utils -   [NLVR2]: iter 10596 Ep: 1.96 loss 0.041 score 0.156 lr 2.44489e-06 
12/02/2021 17:46:32 - INFO - volta.train_utils -   [NLVR2]: iter 10676 Ep: 1.98 loss 0.038 score 0.167 lr 2.46341e-06 
12/02/2021 17:46:54 - INFO - volta.train_utils -   [NLVR2]: iter 10756 Ep: 1.99 loss 0.037 score 0.163 lr 2.48194e-06 
12/02/2021 17:47:51 - INFO - volta.train_utils -   Eval task TASK12 on iteration 10792 
12/02/2021 17:47:51 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.631 score 63.718 
12/02/2021 17:47:51 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  10%|█         | 2/20 [51:53<7:46:31, 1555.09s/it]12/02/2021 17:48:50 - INFO - volta.train_utils -   [NLVR2]: iter 10872 Ep: 2.01 loss 0.039 score 0.161 lr 2.49789e-06 
12/02/2021 17:49:12 - INFO - volta.train_utils -   [NLVR2]: iter 10952 Ep: 2.03 loss 0.040 score 0.158 lr 2.49696e-06 
12/02/2021 17:49:34 - INFO - volta.train_utils -   [NLVR2]: iter 11032 Ep: 2.04 loss 0.039 score 0.164 lr 2.49491e-06 
12/02/2021 17:49:56 - INFO - volta.train_utils -   [NLVR2]: iter 11112 Ep: 2.06 loss 0.038 score 0.156 lr 2.49285e-06 
12/02/2021 17:50:17 - INFO - volta.train_utils -   [NLVR2]: iter 11192 Ep: 2.07 loss 0.040 score 0.159 lr 2.49079e-06 
12/02/2021 17:50:39 - INFO - volta.train_utils -   [NLVR2]: iter 11272 Ep: 2.09 loss 0.041 score 0.160 lr 2.48873e-06 
12/02/2021 17:51:01 - INFO - volta.train_utils -   [NLVR2]: iter 11352 Ep: 2.10 loss 0.040 score 0.159 lr 2.48667e-06 
12/02/2021 17:51:23 - INFO - volta.train_utils -   [NLVR2]: iter 11432 Ep: 2.12 loss 0.038 score 0.157 lr 2.48461e-06 
12/02/2021 17:51:44 - INFO - volta.train_utils -   [NLVR2]: iter 11512 Ep: 2.13 loss 0.040 score 0.156 lr 2.48256e-06 
12/02/2021 17:52:06 - INFO - volta.train_utils -   [NLVR2]: iter 11592 Ep: 2.15 loss 0.038 score 0.159 lr 2.4805e-06 
12/02/2021 17:52:28 - INFO - volta.train_utils -   [NLVR2]: iter 11672 Ep: 2.16 loss 0.038 score 0.163 lr 2.47844e-06 
12/02/2021 17:52:50 - INFO - volta.train_utils -   [NLVR2]: iter 11752 Ep: 2.18 loss 0.037 score 0.164 lr 2.47638e-06 
12/02/2021 17:53:12 - INFO - volta.train_utils -   [NLVR2]: iter 11832 Ep: 2.19 loss 0.041 score 0.159 lr 2.47432e-06 
12/02/2021 17:53:34 - INFO - volta.train_utils -   [NLVR2]: iter 11912 Ep: 2.21 loss 0.039 score 0.157 lr 2.47226e-06 
12/02/2021 17:53:55 - INFO - volta.train_utils -   [NLVR2]: iter 11992 Ep: 2.22 loss 0.038 score 0.161 lr 2.47021e-06 
12/02/2021 17:54:17 - INFO - volta.train_utils -   [NLVR2]: iter 12072 Ep: 2.24 loss 0.041 score 0.155 lr 2.46815e-06 
12/02/2021 17:54:39 - INFO - volta.train_utils -   [NLVR2]: iter 12152 Ep: 2.25 loss 0.038 score 0.167 lr 2.46609e-06 
12/02/2021 17:55:01 - INFO - volta.train_utils -   [NLVR2]: iter 12232 Ep: 2.27 loss 0.040 score 0.158 lr 2.46403e-06 
12/02/2021 17:55:22 - INFO - volta.train_utils -   [NLVR2]: iter 12312 Ep: 2.28 loss 0.039 score 0.158 lr 2.46197e-06 
12/02/2021 17:55:44 - INFO - volta.train_utils -   [NLVR2]: iter 12392 Ep: 2.30 loss 0.039 score 0.159 lr 2.45991e-06 
12/02/2021 17:56:06 - INFO - volta.train_utils -   [NLVR2]: iter 12472 Ep: 2.31 loss 0.039 score 0.162 lr 2.45785e-06 
12/02/2021 17:56:28 - INFO - volta.train_utils -   [NLVR2]: iter 12552 Ep: 2.33 loss 0.037 score 0.165 lr 2.4558e-06 
12/02/2021 17:56:50 - INFO - volta.train_utils -   [NLVR2]: iter 12632 Ep: 2.34 loss 0.039 score 0.166 lr 2.45374e-06 
12/02/2021 17:57:11 - INFO - volta.train_utils -   [NLVR2]: iter 12712 Ep: 2.35 loss 0.036 score 0.166 lr 2.45168e-06 
12/02/2021 17:57:33 - INFO - volta.train_utils -   [NLVR2]: iter 12792 Ep: 2.37 loss 0.038 score 0.162 lr 2.44962e-06 
12/02/2021 17:57:55 - INFO - volta.train_utils -   [NLVR2]: iter 12872 Ep: 2.38 loss 0.039 score 0.161 lr 2.44756e-06 
12/02/2021 17:58:17 - INFO - volta.train_utils -   [NLVR2]: iter 12952 Ep: 2.40 loss 0.039 score 0.167 lr 2.4455e-06 
12/02/2021 17:58:39 - INFO - volta.train_utils -   [NLVR2]: iter 13032 Ep: 2.41 loss 0.038 score 0.167 lr 2.44345e-06 
12/02/2021 17:59:00 - INFO - volta.train_utils -   [NLVR2]: iter 13112 Ep: 2.43 loss 0.040 score 0.160 lr 2.44139e-06 
12/02/2021 17:59:22 - INFO - volta.train_utils -   [NLVR2]: iter 13192 Ep: 2.44 loss 0.039 score 0.165 lr 2.43933e-06 
12/02/2021 17:59:44 - INFO - volta.train_utils -   [NLVR2]: iter 13272 Ep: 2.46 loss 0.040 score 0.163 lr 2.43727e-06 
12/02/2021 18:00:06 - INFO - volta.train_utils -   [NLVR2]: iter 13352 Ep: 2.47 loss 0.036 score 0.165 lr 2.43521e-06 
12/02/2021 18:00:28 - INFO - volta.train_utils -   [NLVR2]: iter 13432 Ep: 2.49 loss 0.040 score 0.164 lr 2.43315e-06 
12/02/2021 18:00:49 - INFO - volta.train_utils -   [NLVR2]: iter 13512 Ep: 2.50 loss 0.038 score 0.161 lr 2.4311e-06 
12/02/2021 18:01:11 - INFO - volta.train_utils -   [NLVR2]: iter 13592 Ep: 2.52 loss 0.037 score 0.160 lr 2.42904e-06 
12/02/2021 18:01:33 - INFO - volta.train_utils -   [NLVR2]: iter 13672 Ep: 2.53 loss 0.036 score 0.167 lr 2.42698e-06 
12/02/2021 18:01:55 - INFO - volta.train_utils -   [NLVR2]: iter 13752 Ep: 2.55 loss 0.038 score 0.168 lr 2.42492e-06 
12/02/2021 18:02:17 - INFO - volta.train_utils -   [NLVR2]: iter 13832 Ep: 2.56 loss 0.037 score 0.167 lr 2.42286e-06 
12/02/2021 18:02:38 - INFO - volta.train_utils -   [NLVR2]: iter 13912 Ep: 2.58 loss 0.038 score 0.162 lr 2.4208e-06 
12/02/2021 18:03:00 - INFO - volta.train_utils -   [NLVR2]: iter 13992 Ep: 2.59 loss 0.037 score 0.165 lr 2.41875e-06 
12/02/2021 18:03:22 - INFO - volta.train_utils -   [NLVR2]: iter 14072 Ep: 2.61 loss 0.037 score 0.164 lr 2.41669e-06 
12/02/2021 18:03:44 - INFO - volta.train_utils -   [NLVR2]: iter 14152 Ep: 2.62 loss 0.038 score 0.163 lr 2.41463e-06 
12/02/2021 18:04:06 - INFO - volta.train_utils -   [NLVR2]: iter 14232 Ep: 2.64 loss 0.038 score 0.164 lr 2.41257e-06 
12/02/2021 18:04:27 - INFO - volta.train_utils -   [NLVR2]: iter 14312 Ep: 2.65 loss 0.038 score 0.159 lr 2.41051e-06 
12/02/2021 18:04:49 - INFO - volta.train_utils -   [NLVR2]: iter 14392 Ep: 2.67 loss 0.037 score 0.174 lr 2.40845e-06 
12/02/2021 18:05:11 - INFO - volta.train_utils -   [NLVR2]: iter 14472 Ep: 2.68 loss 0.035 score 0.168 lr 2.4064e-06 
12/02/2021 18:05:33 - INFO - volta.train_utils -   [NLVR2]: iter 14552 Ep: 2.70 loss 0.037 score 0.162 lr 2.40434e-06 
12/02/2021 18:05:55 - INFO - volta.train_utils -   [NLVR2]: iter 14632 Ep: 2.71 loss 0.036 score 0.165 lr 2.40228e-06 
12/02/2021 18:06:16 - INFO - volta.train_utils -   [NLVR2]: iter 14712 Ep: 2.73 loss 0.037 score 0.166 lr 2.40022e-06 
12/02/2021 18:06:38 - INFO - volta.train_utils -   [NLVR2]: iter 14792 Ep: 2.74 loss 0.036 score 0.170 lr 2.39816e-06 
12/02/2021 18:07:00 - INFO - volta.train_utils -   [NLVR2]: iter 14872 Ep: 2.76 loss 0.036 score 0.169 lr 2.3961e-06 
12/02/2021 18:07:22 - INFO - volta.train_utils -   [NLVR2]: iter 14952 Ep: 2.77 loss 0.038 score 0.163 lr 2.39405e-06 
12/02/2021 18:07:43 - INFO - volta.train_utils -   [NLVR2]: iter 15032 Ep: 2.78 loss 0.037 score 0.171 lr 2.39199e-06 
12/02/2021 18:08:05 - INFO - volta.train_utils -   [NLVR2]: iter 15112 Ep: 2.80 loss 0.038 score 0.170 lr 2.38993e-06 
12/02/2021 18:08:27 - INFO - volta.train_utils -   [NLVR2]: iter 15192 Ep: 2.81 loss 0.035 score 0.169 lr 2.38787e-06 
12/02/2021 18:08:49 - INFO - volta.train_utils -   [NLVR2]: iter 15272 Ep: 2.83 loss 0.035 score 0.172 lr 2.38581e-06 
12/02/2021 18:09:10 - INFO - volta.train_utils -   [NLVR2]: iter 15352 Ep: 2.84 loss 0.035 score 0.165 lr 2.38375e-06 
12/02/2021 18:09:32 - INFO - volta.train_utils -   [NLVR2]: iter 15432 Ep: 2.86 loss 0.036 score 0.166 lr 2.38169e-06 
12/02/2021 18:09:54 - INFO - volta.train_utils -   [NLVR2]: iter 15512 Ep: 2.87 loss 0.037 score 0.168 lr 2.37964e-06 
12/02/2021 18:10:16 - INFO - volta.train_utils -   [NLVR2]: iter 15592 Ep: 2.89 loss 0.038 score 0.166 lr 2.37758e-06 
12/02/2021 18:10:38 - INFO - volta.train_utils -   [NLVR2]: iter 15672 Ep: 2.90 loss 0.039 score 0.167 lr 2.37552e-06 
12/02/2021 18:11:00 - INFO - volta.train_utils -   [NLVR2]: iter 15752 Ep: 2.92 loss 0.036 score 0.172 lr 2.37346e-06 
12/02/2021 18:11:21 - INFO - volta.train_utils -   [NLVR2]: iter 15832 Ep: 2.93 loss 0.035 score 0.167 lr 2.3714e-06 
12/02/2021 18:11:43 - INFO - volta.train_utils -   [NLVR2]: iter 15912 Ep: 2.95 loss 0.037 score 0.167 lr 2.36934e-06 
12/02/2021 18:12:05 - INFO - volta.train_utils -   [NLVR2]: iter 15992 Ep: 2.96 loss 0.036 score 0.172 lr 2.36729e-06 
12/02/2021 18:12:27 - INFO - volta.train_utils -   [NLVR2]: iter 16072 Ep: 2.98 loss 0.038 score 0.171 lr 2.36523e-06 
12/02/2021 18:12:49 - INFO - volta.train_utils -   [NLVR2]: iter 16152 Ep: 2.99 loss 0.037 score 0.172 lr 2.36317e-06 
12/02/2021 18:13:43 - INFO - volta.train_utils -   Eval task TASK12 on iteration 16188 
12/02/2021 18:13:43 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.606 score 65.811 
12/02/2021 18:13:43 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  15%|█▌        | 3/20 [1:17:44<7:20:11, 1553.62s/it]12/02/2021 18:14:41 - INFO - volta.train_utils -   [NLVR2]: iter 16268 Ep: 3.01 loss 0.037 score 0.171 lr 2.36065e-06 
12/02/2021 18:15:03 - INFO - volta.train_utils -   [NLVR2]: iter 16348 Ep: 3.03 loss 0.036 score 0.169 lr 2.35813e-06 
12/02/2021 18:15:25 - INFO - volta.train_utils -   [NLVR2]: iter 16428 Ep: 3.04 loss 0.034 score 0.173 lr 2.35607e-06 
12/02/2021 18:15:47 - INFO - volta.train_utils -   [NLVR2]: iter 16508 Ep: 3.06 loss 0.035 score 0.169 lr 2.35401e-06 
12/02/2021 18:16:08 - INFO - volta.train_utils -   [NLVR2]: iter 16588 Ep: 3.07 loss 0.035 score 0.167 lr 2.35195e-06 
12/02/2021 18:16:30 - INFO - volta.train_utils -   [NLVR2]: iter 16668 Ep: 3.09 loss 0.036 score 0.169 lr 2.34989e-06 
12/02/2021 18:16:52 - INFO - volta.train_utils -   [NLVR2]: iter 16748 Ep: 3.10 loss 0.034 score 0.172 lr 2.34783e-06 
12/02/2021 18:17:14 - INFO - volta.train_utils -   [NLVR2]: iter 16828 Ep: 3.12 loss 0.036 score 0.165 lr 2.34578e-06 
12/02/2021 18:17:36 - INFO - volta.train_utils -   [NLVR2]: iter 16908 Ep: 3.13 loss 0.036 score 0.171 lr 2.34372e-06 
12/02/2021 18:17:58 - INFO - volta.train_utils -   [NLVR2]: iter 16988 Ep: 3.15 loss 0.036 score 0.169 lr 2.34166e-06 
12/02/2021 18:18:20 - INFO - volta.train_utils -   [NLVR2]: iter 17068 Ep: 3.16 loss 0.035 score 0.170 lr 2.3396e-06 
12/02/2021 18:18:42 - INFO - volta.train_utils -   [NLVR2]: iter 17148 Ep: 3.18 loss 0.034 score 0.172 lr 2.33754e-06 
12/02/2021 18:19:04 - INFO - volta.train_utils -   [NLVR2]: iter 17228 Ep: 3.19 loss 0.035 score 0.163 lr 2.33548e-06 
12/02/2021 18:19:26 - INFO - volta.train_utils -   [NLVR2]: iter 17308 Ep: 3.21 loss 0.035 score 0.172 lr 2.33343e-06 
12/02/2021 18:19:48 - INFO - volta.train_utils -   [NLVR2]: iter 17388 Ep: 3.22 loss 0.036 score 0.170 lr 2.33137e-06 
12/02/2021 18:20:09 - INFO - volta.train_utils -   [NLVR2]: iter 17468 Ep: 3.24 loss 0.035 score 0.168 lr 2.32931e-06 
12/02/2021 18:20:31 - INFO - volta.train_utils -   [NLVR2]: iter 17548 Ep: 3.25 loss 0.036 score 0.172 lr 2.32725e-06 
12/02/2021 18:20:53 - INFO - volta.train_utils -   [NLVR2]: iter 17628 Ep: 3.27 loss 0.036 score 0.173 lr 2.32519e-06 
12/02/2021 18:21:15 - INFO - volta.train_utils -   [NLVR2]: iter 17708 Ep: 3.28 loss 0.038 score 0.166 lr 2.32313e-06 
12/02/2021 18:21:37 - INFO - volta.train_utils -   [NLVR2]: iter 17788 Ep: 3.30 loss 0.037 score 0.173 lr 2.32108e-06 
12/02/2021 18:21:59 - INFO - volta.train_utils -   [NLVR2]: iter 17868 Ep: 3.31 loss 0.037 score 0.167 lr 2.31902e-06 
12/02/2021 18:22:21 - INFO - volta.train_utils -   [NLVR2]: iter 17948 Ep: 3.32 loss 0.036 score 0.174 lr 2.31696e-06 
12/02/2021 18:22:43 - INFO - volta.train_utils -   [NLVR2]: iter 18028 Ep: 3.34 loss 0.034 score 0.173 lr 2.3149e-06 
12/02/2021 18:23:05 - INFO - volta.train_utils -   [NLVR2]: iter 18108 Ep: 3.35 loss 0.032 score 0.176 lr 2.31284e-06 
12/02/2021 18:23:27 - INFO - volta.train_utils -   [NLVR2]: iter 18188 Ep: 3.37 loss 0.034 score 0.169 lr 2.31078e-06 
12/02/2021 18:23:49 - INFO - volta.train_utils -   [NLVR2]: iter 18268 Ep: 3.38 loss 0.033 score 0.172 lr 2.30873e-06 
12/02/2021 18:24:10 - INFO - volta.train_utils -   [NLVR2]: iter 18348 Ep: 3.40 loss 0.036 score 0.169 lr 2.30667e-06 
12/02/2021 18:24:32 - INFO - volta.train_utils -   [NLVR2]: iter 18428 Ep: 3.41 loss 0.035 score 0.172 lr 2.30461e-06 
12/02/2021 18:24:54 - INFO - volta.train_utils -   [NLVR2]: iter 18508 Ep: 3.43 loss 0.034 score 0.175 lr 2.30255e-06 
12/02/2021 18:25:16 - INFO - volta.train_utils -   [NLVR2]: iter 18588 Ep: 3.44 loss 0.036 score 0.166 lr 2.30049e-06 
12/02/2021 18:25:38 - INFO - volta.train_utils -   [NLVR2]: iter 18668 Ep: 3.46 loss 0.035 score 0.171 lr 2.29843e-06 
12/02/2021 18:26:00 - INFO - volta.train_utils -   [NLVR2]: iter 18748 Ep: 3.47 loss 0.038 score 0.171 lr 2.29638e-06 
12/02/2021 18:26:22 - INFO - volta.train_utils -   [NLVR2]: iter 18828 Ep: 3.49 loss 0.036 score 0.163 lr 2.29432e-06 
12/02/2021 18:26:44 - INFO - volta.train_utils -   [NLVR2]: iter 18908 Ep: 3.50 loss 0.034 score 0.176 lr 2.29226e-06 
12/02/2021 18:27:06 - INFO - volta.train_utils -   [NLVR2]: iter 18988 Ep: 3.52 loss 0.032 score 0.179 lr 2.2902e-06 
12/02/2021 18:27:28 - INFO - volta.train_utils -   [NLVR2]: iter 19068 Ep: 3.53 loss 0.032 score 0.177 lr 2.28814e-06 
12/02/2021 18:27:50 - INFO - volta.train_utils -   [NLVR2]: iter 19148 Ep: 3.55 loss 0.033 score 0.179 lr 2.28608e-06 
12/02/2021 18:28:12 - INFO - volta.train_utils -   [NLVR2]: iter 19228 Ep: 3.56 loss 0.034 score 0.172 lr 2.28402e-06 
12/02/2021 18:28:33 - INFO - volta.train_utils -   [NLVR2]: iter 19308 Ep: 3.58 loss 0.035 score 0.170 lr 2.28197e-06 
12/02/2021 18:28:55 - INFO - volta.train_utils -   [NLVR2]: iter 19388 Ep: 3.59 loss 0.034 score 0.173 lr 2.27991e-06 
12/02/2021 18:29:17 - INFO - volta.train_utils -   [NLVR2]: iter 19468 Ep: 3.61 loss 0.035 score 0.172 lr 2.27785e-06 
12/02/2021 18:29:39 - INFO - volta.train_utils -   [NLVR2]: iter 19548 Ep: 3.62 loss 0.036 score 0.171 lr 2.27579e-06 
12/02/2021 18:30:02 - INFO - volta.train_utils -   [NLVR2]: iter 19628 Ep: 3.64 loss 0.033 score 0.178 lr 2.27373e-06 
12/02/2021 18:30:24 - INFO - volta.train_utils -   [NLVR2]: iter 19708 Ep: 3.65 loss 0.036 score 0.174 lr 2.27167e-06 
12/02/2021 18:30:46 - INFO - volta.train_utils -   [NLVR2]: iter 19788 Ep: 3.67 loss 0.034 score 0.173 lr 2.26962e-06 
12/02/2021 18:31:08 - INFO - volta.train_utils -   [NLVR2]: iter 19868 Ep: 3.68 loss 0.033 score 0.169 lr 2.26756e-06 
12/02/2021 18:31:30 - INFO - volta.train_utils -   [NLVR2]: iter 19948 Ep: 3.70 loss 0.032 score 0.172 lr 2.2655e-06 
12/02/2021 18:31:52 - INFO - volta.train_utils -   [NLVR2]: iter 20028 Ep: 3.71 loss 0.036 score 0.174 lr 2.26344e-06 
12/02/2021 18:32:14 - INFO - volta.train_utils -   [NLVR2]: iter 20108 Ep: 3.73 loss 0.036 score 0.175 lr 2.26138e-06 
12/02/2021 18:32:36 - INFO - volta.train_utils -   [NLVR2]: iter 20188 Ep: 3.74 loss 0.034 score 0.172 lr 2.25932e-06 
12/02/2021 18:32:58 - INFO - volta.train_utils -   [NLVR2]: iter 20268 Ep: 3.75 loss 0.031 score 0.181 lr 2.25727e-06 
12/02/2021 18:33:20 - INFO - volta.train_utils -   [NLVR2]: iter 20348 Ep: 3.77 loss 0.037 score 0.175 lr 2.25521e-06 
12/02/2021 18:33:42 - INFO - volta.train_utils -   [NLVR2]: iter 20428 Ep: 3.78 loss 0.032 score 0.174 lr 2.25315e-06 
12/02/2021 18:34:04 - INFO - volta.train_utils -   [NLVR2]: iter 20508 Ep: 3.80 loss 0.033 score 0.177 lr 2.25109e-06 
12/02/2021 18:34:26 - INFO - volta.train_utils -   [NLVR2]: iter 20588 Ep: 3.81 loss 0.034 score 0.175 lr 2.24903e-06 
12/02/2021 18:34:48 - INFO - volta.train_utils -   [NLVR2]: iter 20668 Ep: 3.83 loss 0.033 score 0.174 lr 2.24697e-06 
12/02/2021 18:35:10 - INFO - volta.train_utils -   [NLVR2]: iter 20748 Ep: 3.84 loss 0.034 score 0.177 lr 2.24492e-06 
12/02/2021 18:35:32 - INFO - volta.train_utils -   [NLVR2]: iter 20828 Ep: 3.86 loss 0.030 score 0.186 lr 2.24286e-06 
12/02/2021 18:35:54 - INFO - volta.train_utils -   [NLVR2]: iter 20908 Ep: 3.87 loss 0.035 score 0.176 lr 2.2408e-06 
12/02/2021 18:36:16 - INFO - volta.train_utils -   [NLVR2]: iter 20988 Ep: 3.89 loss 0.033 score 0.178 lr 2.23874e-06 
12/02/2021 18:36:38 - INFO - volta.train_utils -   [NLVR2]: iter 21068 Ep: 3.90 loss 0.034 score 0.174 lr 2.23668e-06 
12/02/2021 18:37:00 - INFO - volta.train_utils -   [NLVR2]: iter 21148 Ep: 3.92 loss 0.035 score 0.182 lr 2.23462e-06 
12/02/2021 18:37:22 - INFO - volta.train_utils -   [NLVR2]: iter 21228 Ep: 3.93 loss 0.032 score 0.180 lr 2.23257e-06 
12/02/2021 18:37:44 - INFO - volta.train_utils -   [NLVR2]: iter 21308 Ep: 3.95 loss 0.034 score 0.176 lr 2.23051e-06 
12/02/2021 18:38:06 - INFO - volta.train_utils -   [NLVR2]: iter 21388 Ep: 3.96 loss 0.034 score 0.180 lr 2.22845e-06 
12/02/2021 18:38:27 - INFO - volta.train_utils -   [NLVR2]: iter 21468 Ep: 3.98 loss 0.034 score 0.172 lr 2.22639e-06 
12/02/2021 18:38:49 - INFO - volta.train_utils -   [NLVR2]: iter 21548 Ep: 3.99 loss 0.031 score 0.178 lr 2.22433e-06 
12/02/2021 18:39:44 - INFO - volta.train_utils -   Eval task TASK12 on iteration 21584 
12/02/2021 18:39:44 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.603 score 67.532 
12/02/2021 18:39:44 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  20%|██        | 4/20 [1:43:42<6:54:42, 1555.15s/it]12/02/2021 18:40:39 - INFO - volta.train_utils -   [NLVR2]: iter 21664 Ep: 4.01 loss 0.034 score 0.186 lr 2.22181e-06 
12/02/2021 18:41:01 - INFO - volta.train_utils -   [NLVR2]: iter 21744 Ep: 4.03 loss 0.033 score 0.178 lr 2.21929e-06 
12/02/2021 18:41:23 - INFO - volta.train_utils -   [NLVR2]: iter 21824 Ep: 4.04 loss 0.032 score 0.179 lr 2.21723e-06 
12/02/2021 18:41:45 - INFO - volta.train_utils -   [NLVR2]: iter 21904 Ep: 4.06 loss 0.033 score 0.176 lr 2.21517e-06 
12/02/2021 18:42:07 - INFO - volta.train_utils -   [NLVR2]: iter 21984 Ep: 4.07 loss 0.036 score 0.176 lr 2.21311e-06 
12/02/2021 18:42:29 - INFO - volta.train_utils -   [NLVR2]: iter 22064 Ep: 4.09 loss 0.032 score 0.182 lr 2.21106e-06 
12/02/2021 18:42:51 - INFO - volta.train_utils -   [NLVR2]: iter 22144 Ep: 4.10 loss 0.033 score 0.175 lr 2.209e-06 
12/02/2021 18:43:13 - INFO - volta.train_utils -   [NLVR2]: iter 22224 Ep: 4.12 loss 0.034 score 0.174 lr 2.20694e-06 
12/02/2021 18:43:35 - INFO - volta.train_utils -   [NLVR2]: iter 22304 Ep: 4.13 loss 0.033 score 0.178 lr 2.20488e-06 
12/02/2021 18:43:56 - INFO - volta.train_utils -   [NLVR2]: iter 22384 Ep: 4.15 loss 0.033 score 0.182 lr 2.20282e-06 
12/02/2021 18:44:18 - INFO - volta.train_utils -   [NLVR2]: iter 22464 Ep: 4.16 loss 0.033 score 0.180 lr 2.20076e-06 
12/02/2021 18:44:40 - INFO - volta.train_utils -   [NLVR2]: iter 22544 Ep: 4.18 loss 0.033 score 0.177 lr 2.19871e-06 
12/02/2021 18:45:02 - INFO - volta.train_utils -   [NLVR2]: iter 22624 Ep: 4.19 loss 0.033 score 0.176 lr 2.19665e-06 
12/02/2021 18:45:24 - INFO - volta.train_utils -   [NLVR2]: iter 22704 Ep: 4.21 loss 0.032 score 0.185 lr 2.19459e-06 
12/02/2021 18:45:45 - INFO - volta.train_utils -   [NLVR2]: iter 22784 Ep: 4.22 loss 0.033 score 0.175 lr 2.19253e-06 
12/02/2021 18:46:07 - INFO - volta.train_utils -   [NLVR2]: iter 22864 Ep: 4.24 loss 0.033 score 0.181 lr 2.19047e-06 
12/02/2021 18:46:30 - INFO - volta.train_utils -   [NLVR2]: iter 22944 Ep: 4.25 loss 0.030 score 0.181 lr 2.18841e-06 
12/02/2021 18:46:52 - INFO - volta.train_utils -   [NLVR2]: iter 23024 Ep: 4.27 loss 0.033 score 0.179 lr 2.18636e-06 
12/02/2021 18:47:14 - INFO - volta.train_utils -   [NLVR2]: iter 23104 Ep: 4.28 loss 0.035 score 0.181 lr 2.1843e-06 
12/02/2021 18:47:36 - INFO - volta.train_utils -   [NLVR2]: iter 23184 Ep: 4.29 loss 0.030 score 0.179 lr 2.18224e-06 
12/02/2021 18:47:57 - INFO - volta.train_utils -   [NLVR2]: iter 23264 Ep: 4.31 loss 0.031 score 0.186 lr 2.18018e-06 
12/02/2021 18:48:19 - INFO - volta.train_utils -   [NLVR2]: iter 23344 Ep: 4.32 loss 0.034 score 0.182 lr 2.17812e-06 
12/02/2021 18:48:41 - INFO - volta.train_utils -   [NLVR2]: iter 23424 Ep: 4.34 loss 0.032 score 0.179 lr 2.17606e-06 
12/02/2021 18:49:03 - INFO - volta.train_utils -   [NLVR2]: iter 23504 Ep: 4.35 loss 0.032 score 0.179 lr 2.174e-06 
12/02/2021 18:49:25 - INFO - volta.train_utils -   [NLVR2]: iter 23584 Ep: 4.37 loss 0.033 score 0.180 lr 2.17195e-06 
12/02/2021 18:49:47 - INFO - volta.train_utils -   [NLVR2]: iter 23664 Ep: 4.38 loss 0.029 score 0.185 lr 2.16989e-06 
12/02/2021 18:50:09 - INFO - volta.train_utils -   [NLVR2]: iter 23744 Ep: 4.40 loss 0.033 score 0.179 lr 2.16783e-06 
12/02/2021 18:50:31 - INFO - volta.train_utils -   [NLVR2]: iter 23824 Ep: 4.41 loss 0.034 score 0.178 lr 2.16577e-06 
12/02/2021 18:50:53 - INFO - volta.train_utils -   [NLVR2]: iter 23904 Ep: 4.43 loss 0.033 score 0.179 lr 2.16371e-06 
12/02/2021 18:51:15 - INFO - volta.train_utils -   [NLVR2]: iter 23984 Ep: 4.44 loss 0.032 score 0.190 lr 2.16165e-06 
12/02/2021 18:51:37 - INFO - volta.train_utils -   [NLVR2]: iter 24064 Ep: 4.46 loss 0.031 score 0.184 lr 2.1596e-06 
12/02/2021 18:51:59 - INFO - volta.train_utils -   [NLVR2]: iter 24144 Ep: 4.47 loss 0.033 score 0.182 lr 2.15754e-06 
12/02/2021 18:52:21 - INFO - volta.train_utils -   [NLVR2]: iter 24224 Ep: 4.49 loss 0.033 score 0.184 lr 2.15548e-06 
12/02/2021 18:52:43 - INFO - volta.train_utils -   [NLVR2]: iter 24304 Ep: 4.50 loss 0.033 score 0.183 lr 2.15342e-06 
12/02/2021 18:53:04 - INFO - volta.train_utils -   [NLVR2]: iter 24384 Ep: 4.52 loss 0.034 score 0.180 lr 2.15136e-06 
12/02/2021 18:53:26 - INFO - volta.train_utils -   [NLVR2]: iter 24464 Ep: 4.53 loss 0.030 score 0.181 lr 2.1493e-06 
12/02/2021 18:53:48 - INFO - volta.train_utils -   [NLVR2]: iter 24544 Ep: 4.55 loss 0.029 score 0.186 lr 2.14725e-06 
12/02/2021 18:54:10 - INFO - volta.train_utils -   [NLVR2]: iter 24624 Ep: 4.56 loss 0.032 score 0.183 lr 2.14519e-06 
12/02/2021 18:54:33 - INFO - volta.train_utils -   [NLVR2]: iter 24704 Ep: 4.58 loss 0.034 score 0.177 lr 2.14313e-06 
12/02/2021 18:54:55 - INFO - volta.train_utils -   [NLVR2]: iter 24784 Ep: 4.59 loss 0.033 score 0.179 lr 2.14107e-06 
12/02/2021 18:55:17 - INFO - volta.train_utils -   [NLVR2]: iter 24864 Ep: 4.61 loss 0.034 score 0.183 lr 2.13901e-06 
12/02/2021 18:55:39 - INFO - volta.train_utils -   [NLVR2]: iter 24944 Ep: 4.62 loss 0.030 score 0.178 lr 2.13695e-06 
12/02/2021 18:56:00 - INFO - volta.train_utils -   [NLVR2]: iter 25024 Ep: 4.64 loss 0.030 score 0.181 lr 2.1349e-06 
12/02/2021 18:56:22 - INFO - volta.train_utils -   [NLVR2]: iter 25104 Ep: 4.65 loss 0.033 score 0.183 lr 2.13284e-06 
12/02/2021 18:56:44 - INFO - volta.train_utils -   [NLVR2]: iter 25184 Ep: 4.67 loss 0.031 score 0.186 lr 2.13078e-06 
12/02/2021 18:57:06 - INFO - volta.train_utils -   [NLVR2]: iter 25264 Ep: 4.68 loss 0.032 score 0.177 lr 2.12872e-06 
12/02/2021 18:57:28 - INFO - volta.train_utils -   [NLVR2]: iter 25344 Ep: 4.70 loss 0.031 score 0.183 lr 2.12666e-06 
12/02/2021 18:57:50 - INFO - volta.train_utils -   [NLVR2]: iter 25424 Ep: 4.71 loss 0.030 score 0.183 lr 2.1246e-06 
12/02/2021 18:58:12 - INFO - volta.train_utils -   [NLVR2]: iter 25504 Ep: 4.72 loss 0.030 score 0.184 lr 2.12255e-06 
12/02/2021 18:58:34 - INFO - volta.train_utils -   [NLVR2]: iter 25584 Ep: 4.74 loss 0.030 score 0.188 lr 2.12049e-06 
12/02/2021 18:58:56 - INFO - volta.train_utils -   [NLVR2]: iter 25664 Ep: 4.75 loss 0.030 score 0.188 lr 2.11843e-06 
12/02/2021 18:59:18 - INFO - volta.train_utils -   [NLVR2]: iter 25744 Ep: 4.77 loss 0.032 score 0.184 lr 2.11637e-06 
12/02/2021 18:59:40 - INFO - volta.train_utils -   [NLVR2]: iter 25824 Ep: 4.78 loss 0.030 score 0.185 lr 2.11431e-06 
12/02/2021 19:00:02 - INFO - volta.train_utils -   [NLVR2]: iter 25904 Ep: 4.80 loss 0.033 score 0.182 lr 2.11225e-06 
12/02/2021 19:00:24 - INFO - volta.train_utils -   [NLVR2]: iter 25984 Ep: 4.81 loss 0.033 score 0.182 lr 2.1102e-06 
12/02/2021 19:00:46 - INFO - volta.train_utils -   [NLVR2]: iter 26064 Ep: 4.83 loss 0.033 score 0.184 lr 2.10814e-06 
12/02/2021 19:01:08 - INFO - volta.train_utils -   [NLVR2]: iter 26144 Ep: 4.84 loss 0.028 score 0.193 lr 2.10608e-06 
12/02/2021 19:01:30 - INFO - volta.train_utils -   [NLVR2]: iter 26224 Ep: 4.86 loss 0.030 score 0.186 lr 2.10402e-06 
12/02/2021 19:01:52 - INFO - volta.train_utils -   [NLVR2]: iter 26304 Ep: 4.87 loss 0.029 score 0.187 lr 2.10196e-06 
12/02/2021 19:02:14 - INFO - volta.train_utils -   [NLVR2]: iter 26384 Ep: 4.89 loss 0.033 score 0.184 lr 2.0999e-06 
12/02/2021 19:02:36 - INFO - volta.train_utils -   [NLVR2]: iter 26464 Ep: 4.90 loss 0.031 score 0.191 lr 2.09784e-06 
12/02/2021 19:02:58 - INFO - volta.train_utils -   [NLVR2]: iter 26544 Ep: 4.92 loss 0.030 score 0.187 lr 2.09579e-06 
12/02/2021 19:03:20 - INFO - volta.train_utils -   [NLVR2]: iter 26624 Ep: 4.93 loss 0.030 score 0.194 lr 2.09373e-06 
12/02/2021 19:03:42 - INFO - volta.train_utils -   [NLVR2]: iter 26704 Ep: 4.95 loss 0.032 score 0.186 lr 2.09167e-06 
12/02/2021 19:04:04 - INFO - volta.train_utils -   [NLVR2]: iter 26784 Ep: 4.96 loss 0.031 score 0.192 lr 2.08961e-06 
12/02/2021 19:04:25 - INFO - volta.train_utils -   [NLVR2]: iter 26864 Ep: 4.98 loss 0.031 score 0.187 lr 2.08755e-06 
12/02/2021 19:04:47 - INFO - volta.train_utils -   [NLVR2]: iter 26944 Ep: 4.99 loss 0.031 score 0.183 lr 2.08549e-06 
12/02/2021 19:05:42 - INFO - volta.train_utils -   Eval task TASK12 on iteration 26980 
12/02/2021 19:05:42 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.611 score 68.822 
12/02/2021 19:05:42 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  25%|██▌       | 5/20 [2:09:46<6:29:23, 1557.58s/it]12/02/2021 19:06:43 - INFO - volta.train_utils -   [NLVR2]: iter 27060 Ep: 5.01 loss 0.031 score 0.192 lr 2.08297e-06 
12/02/2021 19:07:05 - INFO - volta.train_utils -   [NLVR2]: iter 27140 Ep: 5.03 loss 0.030 score 0.187 lr 2.08045e-06 
12/02/2021 19:07:26 - INFO - volta.train_utils -   [NLVR2]: iter 27220 Ep: 5.04 loss 0.031 score 0.186 lr 2.07839e-06 
12/02/2021 19:07:48 - INFO - volta.train_utils -   [NLVR2]: iter 27300 Ep: 5.06 loss 0.030 score 0.190 lr 2.07633e-06 
12/02/2021 19:08:10 - INFO - volta.train_utils -   [NLVR2]: iter 27380 Ep: 5.07 loss 0.029 score 0.190 lr 2.07428e-06 
12/02/2021 19:08:32 - INFO - volta.train_utils -   [NLVR2]: iter 27460 Ep: 5.09 loss 0.032 score 0.179 lr 2.07222e-06 
12/02/2021 19:08:54 - INFO - volta.train_utils -   [NLVR2]: iter 27540 Ep: 5.10 loss 0.032 score 0.187 lr 2.07016e-06 
12/02/2021 19:09:16 - INFO - volta.train_utils -   [NLVR2]: iter 27620 Ep: 5.12 loss 0.030 score 0.189 lr 2.0681e-06 
12/02/2021 19:09:38 - INFO - volta.train_utils -   [NLVR2]: iter 27700 Ep: 5.13 loss 0.031 score 0.193 lr 2.06604e-06 
12/02/2021 19:10:00 - INFO - volta.train_utils -   [NLVR2]: iter 27780 Ep: 5.15 loss 0.030 score 0.186 lr 2.06398e-06 
12/02/2021 19:10:22 - INFO - volta.train_utils -   [NLVR2]: iter 27860 Ep: 5.16 loss 0.030 score 0.187 lr 2.06193e-06 
12/02/2021 19:10:44 - INFO - volta.train_utils -   [NLVR2]: iter 27940 Ep: 5.18 loss 0.031 score 0.189 lr 2.05987e-06 
12/02/2021 19:11:06 - INFO - volta.train_utils -   [NLVR2]: iter 28020 Ep: 5.19 loss 0.030 score 0.192 lr 2.05781e-06 
12/02/2021 19:11:28 - INFO - volta.train_utils -   [NLVR2]: iter 28100 Ep: 5.21 loss 0.030 score 0.186 lr 2.05575e-06 
12/02/2021 19:11:50 - INFO - volta.train_utils -   [NLVR2]: iter 28180 Ep: 5.22 loss 0.030 score 0.188 lr 2.05369e-06 
12/02/2021 19:12:12 - INFO - volta.train_utils -   [NLVR2]: iter 28260 Ep: 5.24 loss 0.031 score 0.187 lr 2.05163e-06 
12/02/2021 19:12:33 - INFO - volta.train_utils -   [NLVR2]: iter 28340 Ep: 5.25 loss 0.030 score 0.188 lr 2.04958e-06 
12/02/2021 19:12:55 - INFO - volta.train_utils -   [NLVR2]: iter 28420 Ep: 5.26 loss 0.033 score 0.189 lr 2.04752e-06 
12/02/2021 19:13:17 - INFO - volta.train_utils -   [NLVR2]: iter 28500 Ep: 5.28 loss 0.030 score 0.186 lr 2.04546e-06 
12/02/2021 19:13:39 - INFO - volta.train_utils -   [NLVR2]: iter 28580 Ep: 5.29 loss 0.032 score 0.183 lr 2.0434e-06 
12/02/2021 19:14:01 - INFO - volta.train_utils -   [NLVR2]: iter 28660 Ep: 5.31 loss 0.030 score 0.186 lr 2.04134e-06 
12/02/2021 19:14:22 - INFO - volta.train_utils -   [NLVR2]: iter 28740 Ep: 5.32 loss 0.030 score 0.187 lr 2.03928e-06 
12/02/2021 19:14:44 - INFO - volta.train_utils -   [NLVR2]: iter 28820 Ep: 5.34 loss 0.029 score 0.185 lr 2.03723e-06 
12/02/2021 19:15:06 - INFO - volta.train_utils -   [NLVR2]: iter 28900 Ep: 5.35 loss 0.031 score 0.188 lr 2.03517e-06 
12/02/2021 19:15:28 - INFO - volta.train_utils -   [NLVR2]: iter 28980 Ep: 5.37 loss 0.028 score 0.185 lr 2.03311e-06 
12/02/2021 19:15:50 - INFO - volta.train_utils -   [NLVR2]: iter 29060 Ep: 5.38 loss 0.029 score 0.184 lr 2.03105e-06 
12/02/2021 19:16:12 - INFO - volta.train_utils -   [NLVR2]: iter 29140 Ep: 5.40 loss 0.030 score 0.188 lr 2.02899e-06 
12/02/2021 19:16:34 - INFO - volta.train_utils -   [NLVR2]: iter 29220 Ep: 5.41 loss 0.029 score 0.186 lr 2.02693e-06 
12/02/2021 19:16:56 - INFO - volta.train_utils -   [NLVR2]: iter 29300 Ep: 5.43 loss 0.028 score 0.190 lr 2.02488e-06 
12/02/2021 19:17:18 - INFO - volta.train_utils -   [NLVR2]: iter 29380 Ep: 5.44 loss 0.031 score 0.183 lr 2.02282e-06 
12/02/2021 19:17:40 - INFO - volta.train_utils -   [NLVR2]: iter 29460 Ep: 5.46 loss 0.026 score 0.192 lr 2.02076e-06 
12/02/2021 19:18:02 - INFO - volta.train_utils -   [NLVR2]: iter 29540 Ep: 5.47 loss 0.031 score 0.188 lr 2.0187e-06 
12/02/2021 19:18:24 - INFO - volta.train_utils -   [NLVR2]: iter 29620 Ep: 5.49 loss 0.033 score 0.188 lr 2.01664e-06 
12/02/2021 19:18:46 - INFO - volta.train_utils -   [NLVR2]: iter 29700 Ep: 5.50 loss 0.029 score 0.192 lr 2.01458e-06 
12/02/2021 19:19:08 - INFO - volta.train_utils -   [NLVR2]: iter 29780 Ep: 5.52 loss 0.027 score 0.191 lr 2.01253e-06 
12/02/2021 19:19:30 - INFO - volta.train_utils -   [NLVR2]: iter 29860 Ep: 5.53 loss 0.030 score 0.192 lr 2.01047e-06 
12/02/2021 19:19:52 - INFO - volta.train_utils -   [NLVR2]: iter 29940 Ep: 5.55 loss 0.027 score 0.195 lr 2.00841e-06 
12/02/2021 19:20:14 - INFO - volta.train_utils -   [NLVR2]: iter 30020 Ep: 5.56 loss 0.030 score 0.193 lr 2.00635e-06 
12/02/2021 19:20:36 - INFO - volta.train_utils -   [NLVR2]: iter 30100 Ep: 5.58 loss 0.033 score 0.190 lr 2.00429e-06 
12/02/2021 19:20:58 - INFO - volta.train_utils -   [NLVR2]: iter 30180 Ep: 5.59 loss 0.029 score 0.190 lr 2.00223e-06 
12/02/2021 19:21:20 - INFO - volta.train_utils -   [NLVR2]: iter 30260 Ep: 5.61 loss 0.031 score 0.187 lr 2.00017e-06 
12/02/2021 19:21:41 - INFO - volta.train_utils -   [NLVR2]: iter 30340 Ep: 5.62 loss 0.029 score 0.190 lr 1.99812e-06 
12/02/2021 19:22:03 - INFO - volta.train_utils -   [NLVR2]: iter 30420 Ep: 5.64 loss 0.032 score 0.189 lr 1.99606e-06 
12/02/2021 19:22:25 - INFO - volta.train_utils -   [NLVR2]: iter 30500 Ep: 5.65 loss 0.029 score 0.190 lr 1.994e-06 
12/02/2021 19:22:47 - INFO - volta.train_utils -   [NLVR2]: iter 30580 Ep: 5.67 loss 0.028 score 0.191 lr 1.99194e-06 
12/02/2021 19:23:09 - INFO - volta.train_utils -   [NLVR2]: iter 30660 Ep: 5.68 loss 0.029 score 0.192 lr 1.98988e-06 
12/02/2021 19:23:31 - INFO - volta.train_utils -   [NLVR2]: iter 30740 Ep: 5.69 loss 0.029 score 0.182 lr 1.98782e-06 
12/02/2021 19:23:53 - INFO - volta.train_utils -   [NLVR2]: iter 30820 Ep: 5.71 loss 0.031 score 0.190 lr 1.98577e-06 
12/02/2021 19:24:15 - INFO - volta.train_utils -   [NLVR2]: iter 30900 Ep: 5.72 loss 0.030 score 0.189 lr 1.98371e-06 
12/02/2021 19:24:37 - INFO - volta.train_utils -   [NLVR2]: iter 30980 Ep: 5.74 loss 0.028 score 0.192 lr 1.98165e-06 
12/02/2021 19:24:59 - INFO - volta.train_utils -   [NLVR2]: iter 31060 Ep: 5.75 loss 0.027 score 0.193 lr 1.97959e-06 
12/02/2021 19:25:21 - INFO - volta.train_utils -   [NLVR2]: iter 31140 Ep: 5.77 loss 0.028 score 0.192 lr 1.97753e-06 
12/02/2021 19:25:43 - INFO - volta.train_utils -   [NLVR2]: iter 31220 Ep: 5.78 loss 0.027 score 0.192 lr 1.97547e-06 
12/02/2021 19:26:04 - INFO - volta.train_utils -   [NLVR2]: iter 31300 Ep: 5.80 loss 0.028 score 0.189 lr 1.97342e-06 
12/02/2021 19:26:26 - INFO - volta.train_utils -   [NLVR2]: iter 31380 Ep: 5.81 loss 0.026 score 0.193 lr 1.97136e-06 
12/02/2021 19:26:48 - INFO - volta.train_utils -   [NLVR2]: iter 31460 Ep: 5.83 loss 0.031 score 0.188 lr 1.9693e-06 
12/02/2021 19:27:10 - INFO - volta.train_utils -   [NLVR2]: iter 31540 Ep: 5.84 loss 0.027 score 0.195 lr 1.96724e-06 
12/02/2021 19:27:32 - INFO - volta.train_utils -   [NLVR2]: iter 31620 Ep: 5.86 loss 0.028 score 0.192 lr 1.96518e-06 
12/02/2021 19:27:54 - INFO - volta.train_utils -   [NLVR2]: iter 31700 Ep: 5.87 loss 0.027 score 0.196 lr 1.96312e-06 
12/02/2021 19:28:16 - INFO - volta.train_utils -   [NLVR2]: iter 31780 Ep: 5.89 loss 0.028 score 0.191 lr 1.96107e-06 
12/02/2021 19:28:38 - INFO - volta.train_utils -   [NLVR2]: iter 31860 Ep: 5.90 loss 0.025 score 0.193 lr 1.95901e-06 
12/02/2021 19:29:00 - INFO - volta.train_utils -   [NLVR2]: iter 31940 Ep: 5.92 loss 0.031 score 0.190 lr 1.95695e-06 
12/02/2021 19:29:22 - INFO - volta.train_utils -   [NLVR2]: iter 32020 Ep: 5.93 loss 0.028 score 0.194 lr 1.95489e-06 
12/02/2021 19:29:44 - INFO - volta.train_utils -   [NLVR2]: iter 32100 Ep: 5.95 loss 0.027 score 0.191 lr 1.95283e-06 
12/02/2021 19:30:06 - INFO - volta.train_utils -   [NLVR2]: iter 32180 Ep: 5.96 loss 0.030 score 0.189 lr 1.95077e-06 
12/02/2021 19:30:27 - INFO - volta.train_utils -   [NLVR2]: iter 32260 Ep: 5.98 loss 0.031 score 0.193 lr 1.94872e-06 
12/02/2021 19:30:50 - INFO - volta.train_utils -   [NLVR2]: iter 32340 Ep: 5.99 loss 0.029 score 0.198 lr 1.94666e-06 
12/02/2021 19:31:44 - INFO - volta.train_utils -   Eval task TASK12 on iteration 32376 
12/02/2021 19:31:44 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.634 score 69.280 
12/02/2021 19:31:44 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  30%|███       | 6/20 [2:35:50<6:03:53, 1559.55s/it]12/02/2021 19:32:47 - INFO - volta.train_utils -   [NLVR2]: iter 32456 Ep: 6.01 loss 0.031 score 0.195 lr 1.94414e-06 
12/02/2021 19:33:09 - INFO - volta.train_utils -   [NLVR2]: iter 32536 Ep: 6.03 loss 0.025 score 0.196 lr 1.94161e-06 
12/02/2021 19:33:31 - INFO - volta.train_utils -   [NLVR2]: iter 32616 Ep: 6.04 loss 0.028 score 0.190 lr 1.93956e-06 
12/02/2021 19:33:53 - INFO - volta.train_utils -   [NLVR2]: iter 32696 Ep: 6.06 loss 0.027 score 0.191 lr 1.9375e-06 
12/02/2021 19:34:15 - INFO - volta.train_utils -   [NLVR2]: iter 32776 Ep: 6.07 loss 0.023 score 0.195 lr 1.93544e-06 
12/02/2021 19:34:37 - INFO - volta.train_utils -   [NLVR2]: iter 32856 Ep: 6.09 loss 0.033 score 0.195 lr 1.93338e-06 
12/02/2021 19:34:59 - INFO - volta.train_utils -   [NLVR2]: iter 32936 Ep: 6.10 loss 0.029 score 0.195 lr 1.93132e-06 
12/02/2021 19:35:21 - INFO - volta.train_utils -   [NLVR2]: iter 33016 Ep: 6.12 loss 0.026 score 0.193 lr 1.92926e-06 
12/02/2021 19:35:42 - INFO - volta.train_utils -   [NLVR2]: iter 33096 Ep: 6.13 loss 0.028 score 0.196 lr 1.92721e-06 
12/02/2021 19:36:04 - INFO - volta.train_utils -   [NLVR2]: iter 33176 Ep: 6.15 loss 0.028 score 0.193 lr 1.92515e-06 
12/02/2021 19:36:26 - INFO - volta.train_utils -   [NLVR2]: iter 33256 Ep: 6.16 loss 0.027 score 0.188 lr 1.92309e-06 
12/02/2021 19:36:48 - INFO - volta.train_utils -   [NLVR2]: iter 33336 Ep: 6.18 loss 0.028 score 0.193 lr 1.92103e-06 
12/02/2021 19:37:10 - INFO - volta.train_utils -   [NLVR2]: iter 33416 Ep: 6.19 loss 0.028 score 0.196 lr 1.91897e-06 
12/02/2021 19:37:32 - INFO - volta.train_utils -   [NLVR2]: iter 33496 Ep: 6.21 loss 0.028 score 0.191 lr 1.91691e-06 
12/02/2021 19:37:54 - INFO - volta.train_utils -   [NLVR2]: iter 33576 Ep: 6.22 loss 0.028 score 0.196 lr 1.91486e-06 
12/02/2021 19:38:16 - INFO - volta.train_utils -   [NLVR2]: iter 33656 Ep: 6.23 loss 0.029 score 0.189 lr 1.9128e-06 
12/02/2021 19:38:38 - INFO - volta.train_utils -   [NLVR2]: iter 33736 Ep: 6.25 loss 0.029 score 0.191 lr 1.91074e-06 
12/02/2021 19:39:00 - INFO - volta.train_utils -   [NLVR2]: iter 33816 Ep: 6.26 loss 0.029 score 0.192 lr 1.90868e-06 
12/02/2021 19:39:22 - INFO - volta.train_utils -   [NLVR2]: iter 33896 Ep: 6.28 loss 0.027 score 0.193 lr 1.90662e-06 
12/02/2021 19:39:44 - INFO - volta.train_utils -   [NLVR2]: iter 33976 Ep: 6.29 loss 0.027 score 0.191 lr 1.90456e-06 
12/02/2021 19:40:06 - INFO - volta.train_utils -   [NLVR2]: iter 34056 Ep: 6.31 loss 0.027 score 0.200 lr 1.90251e-06 
12/02/2021 19:40:28 - INFO - volta.train_utils -   [NLVR2]: iter 34136 Ep: 6.32 loss 0.027 score 0.197 lr 1.90045e-06 
12/02/2021 19:40:50 - INFO - volta.train_utils -   [NLVR2]: iter 34216 Ep: 6.34 loss 0.027 score 0.193 lr 1.89839e-06 
12/02/2021 19:41:12 - INFO - volta.train_utils -   [NLVR2]: iter 34296 Ep: 6.35 loss 0.029 score 0.191 lr 1.89633e-06 
12/02/2021 19:41:33 - INFO - volta.train_utils -   [NLVR2]: iter 34376 Ep: 6.37 loss 0.025 score 0.199 lr 1.89427e-06 
12/02/2021 19:41:55 - INFO - volta.train_utils -   [NLVR2]: iter 34456 Ep: 6.38 loss 0.029 score 0.196 lr 1.89221e-06 
12/02/2021 19:42:17 - INFO - volta.train_utils -   [NLVR2]: iter 34536 Ep: 6.40 loss 0.029 score 0.189 lr 1.89015e-06 
12/02/2021 19:42:39 - INFO - volta.train_utils -   [NLVR2]: iter 34616 Ep: 6.41 loss 0.026 score 0.195 lr 1.8881e-06 
12/02/2021 19:43:01 - INFO - volta.train_utils -   [NLVR2]: iter 34696 Ep: 6.43 loss 0.029 score 0.193 lr 1.88604e-06 
12/02/2021 19:43:23 - INFO - volta.train_utils -   [NLVR2]: iter 34776 Ep: 6.44 loss 0.025 score 0.197 lr 1.88398e-06 
12/02/2021 19:43:45 - INFO - volta.train_utils -   [NLVR2]: iter 34856 Ep: 6.46 loss 0.030 score 0.197 lr 1.88192e-06 
12/02/2021 19:44:07 - INFO - volta.train_utils -   [NLVR2]: iter 34936 Ep: 6.47 loss 0.025 score 0.196 lr 1.87986e-06 
12/02/2021 19:44:29 - INFO - volta.train_utils -   [NLVR2]: iter 35016 Ep: 6.49 loss 0.030 score 0.191 lr 1.8778e-06 
12/02/2021 19:44:50 - INFO - volta.train_utils -   [NLVR2]: iter 35096 Ep: 6.50 loss 0.028 score 0.196 lr 1.87575e-06 
12/02/2021 19:45:12 - INFO - volta.train_utils -   [NLVR2]: iter 35176 Ep: 6.52 loss 0.029 score 0.195 lr 1.87369e-06 
12/02/2021 19:45:34 - INFO - volta.train_utils -   [NLVR2]: iter 35256 Ep: 6.53 loss 0.028 score 0.196 lr 1.87163e-06 
12/02/2021 19:45:56 - INFO - volta.train_utils -   [NLVR2]: iter 35336 Ep: 6.55 loss 0.028 score 0.192 lr 1.86957e-06 
12/02/2021 19:46:18 - INFO - volta.train_utils -   [NLVR2]: iter 35416 Ep: 6.56 loss 0.027 score 0.196 lr 1.86751e-06 
12/02/2021 19:46:40 - INFO - volta.train_utils -   [NLVR2]: iter 35496 Ep: 6.58 loss 0.025 score 0.197 lr 1.86545e-06 
12/02/2021 19:47:01 - INFO - volta.train_utils -   [NLVR2]: iter 35576 Ep: 6.59 loss 0.025 score 0.194 lr 1.8634e-06 
12/02/2021 19:47:23 - INFO - volta.train_utils -   [NLVR2]: iter 35656 Ep: 6.61 loss 0.024 score 0.200 lr 1.86134e-06 
12/02/2021 19:47:45 - INFO - volta.train_utils -   [NLVR2]: iter 35736 Ep: 6.62 loss 0.027 score 0.195 lr 1.85928e-06 
12/02/2021 19:48:07 - INFO - volta.train_utils -   [NLVR2]: iter 35816 Ep: 6.64 loss 0.026 score 0.195 lr 1.85722e-06 
12/02/2021 19:48:29 - INFO - volta.train_utils -   [NLVR2]: iter 35896 Ep: 6.65 loss 0.024 score 0.199 lr 1.85516e-06 
12/02/2021 19:48:51 - INFO - volta.train_utils -   [NLVR2]: iter 35976 Ep: 6.66 loss 0.024 score 0.196 lr 1.8531e-06 
12/02/2021 19:49:13 - INFO - volta.train_utils -   [NLVR2]: iter 36056 Ep: 6.68 loss 0.028 score 0.192 lr 1.85105e-06 
12/02/2021 19:49:35 - INFO - volta.train_utils -   [NLVR2]: iter 36136 Ep: 6.69 loss 0.026 score 0.195 lr 1.84899e-06 
12/02/2021 19:49:57 - INFO - volta.train_utils -   [NLVR2]: iter 36216 Ep: 6.71 loss 0.028 score 0.192 lr 1.84693e-06 
12/02/2021 19:50:19 - INFO - volta.train_utils -   [NLVR2]: iter 36296 Ep: 6.72 loss 0.027 score 0.194 lr 1.84487e-06 
12/02/2021 19:50:41 - INFO - volta.train_utils -   [NLVR2]: iter 36376 Ep: 6.74 loss 0.027 score 0.196 lr 1.84281e-06 
12/02/2021 19:51:03 - INFO - volta.train_utils -   [NLVR2]: iter 36456 Ep: 6.75 loss 0.026 score 0.200 lr 1.84075e-06 
12/02/2021 19:51:24 - INFO - volta.train_utils -   [NLVR2]: iter 36536 Ep: 6.77 loss 0.025 score 0.194 lr 1.8387e-06 
12/02/2021 19:51:46 - INFO - volta.train_utils -   [NLVR2]: iter 36616 Ep: 6.78 loss 0.026 score 0.201 lr 1.83664e-06 
12/02/2021 19:52:08 - INFO - volta.train_utils -   [NLVR2]: iter 36696 Ep: 6.80 loss 0.025 score 0.200 lr 1.83458e-06 
12/02/2021 19:52:30 - INFO - volta.train_utils -   [NLVR2]: iter 36776 Ep: 6.81 loss 0.025 score 0.198 lr 1.83252e-06 
12/02/2021 19:52:52 - INFO - volta.train_utils -   [NLVR2]: iter 36856 Ep: 6.83 loss 0.027 score 0.197 lr 1.83046e-06 
12/02/2021 19:53:14 - INFO - volta.train_utils -   [NLVR2]: iter 36936 Ep: 6.84 loss 0.025 score 0.199 lr 1.8284e-06 
12/02/2021 19:53:36 - INFO - volta.train_utils -   [NLVR2]: iter 37016 Ep: 6.86 loss 0.025 score 0.196 lr 1.82635e-06 
12/02/2021 19:53:58 - INFO - volta.train_utils -   [NLVR2]: iter 37096 Ep: 6.87 loss 0.026 score 0.198 lr 1.82429e-06 
12/02/2021 19:54:20 - INFO - volta.train_utils -   [NLVR2]: iter 37176 Ep: 6.89 loss 0.023 score 0.200 lr 1.82223e-06 
12/02/2021 19:54:42 - INFO - volta.train_utils -   [NLVR2]: iter 37256 Ep: 6.90 loss 0.024 score 0.202 lr 1.82017e-06 
12/02/2021 19:55:03 - INFO - volta.train_utils -   [NLVR2]: iter 37336 Ep: 6.92 loss 0.025 score 0.197 lr 1.81811e-06 
12/02/2021 19:55:25 - INFO - volta.train_utils -   [NLVR2]: iter 37416 Ep: 6.93 loss 0.026 score 0.193 lr 1.81605e-06 
12/02/2021 19:55:47 - INFO - volta.train_utils -   [NLVR2]: iter 37496 Ep: 6.95 loss 0.029 score 0.198 lr 1.81399e-06 
12/02/2021 19:56:09 - INFO - volta.train_utils -   [NLVR2]: iter 37576 Ep: 6.96 loss 0.023 score 0.203 lr 1.81194e-06 
12/02/2021 19:56:31 - INFO - volta.train_utils -   [NLVR2]: iter 37656 Ep: 6.98 loss 0.022 score 0.196 lr 1.80988e-06 
12/02/2021 19:56:53 - INFO - volta.train_utils -   [NLVR2]: iter 37736 Ep: 6.99 loss 0.024 score 0.200 lr 1.80782e-06 
12/02/2021 19:57:48 - INFO - volta.train_utils -   Eval task TASK12 on iteration 37772 
12/02/2021 19:57:48 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.663 score 68.979 
Epoch:  35%|███▌      | 7/20 [3:01:14<5:35:35, 1548.85s/it]12/02/2021 19:58:11 - INFO - volta.train_utils -   [NLVR2]: iter 37852 Ep: 7.01 loss 0.027 score 0.203 lr 1.8053e-06 
12/02/2021 19:58:32 - INFO - volta.train_utils -   [NLVR2]: iter 37932 Ep: 7.03 loss 0.024 score 0.200 lr 1.80278e-06 
12/02/2021 19:58:54 - INFO - volta.train_utils -   [NLVR2]: iter 38012 Ep: 7.04 loss 0.027 score 0.195 lr 1.80072e-06 
12/02/2021 19:59:16 - INFO - volta.train_utils -   [NLVR2]: iter 38092 Ep: 7.06 loss 0.024 score 0.198 lr 1.79866e-06 
12/02/2021 19:59:38 - INFO - volta.train_utils -   [NLVR2]: iter 38172 Ep: 7.07 loss 0.027 score 0.199 lr 1.7966e-06 
12/02/2021 20:00:00 - INFO - volta.train_utils -   [NLVR2]: iter 38252 Ep: 7.09 loss 0.026 score 0.196 lr 1.79454e-06 
12/02/2021 20:00:22 - INFO - volta.train_utils -   [NLVR2]: iter 38332 Ep: 7.10 loss 0.026 score 0.197 lr 1.79248e-06 
12/02/2021 20:00:44 - INFO - volta.train_utils -   [NLVR2]: iter 38412 Ep: 7.12 loss 0.026 score 0.196 lr 1.79043e-06 
12/02/2021 20:01:06 - INFO - volta.train_utils -   [NLVR2]: iter 38492 Ep: 7.13 loss 0.024 score 0.202 lr 1.78837e-06 
12/02/2021 20:01:28 - INFO - volta.train_utils -   [NLVR2]: iter 38572 Ep: 7.15 loss 0.025 score 0.200 lr 1.78631e-06 
12/02/2021 20:01:50 - INFO - volta.train_utils -   [NLVR2]: iter 38652 Ep: 7.16 loss 0.023 score 0.198 lr 1.78425e-06 
12/02/2021 20:02:12 - INFO - volta.train_utils -   [NLVR2]: iter 38732 Ep: 7.18 loss 0.027 score 0.195 lr 1.78219e-06 
12/02/2021 20:02:34 - INFO - volta.train_utils -   [NLVR2]: iter 38812 Ep: 7.19 loss 0.025 score 0.197 lr 1.78013e-06 
12/02/2021 20:02:56 - INFO - volta.train_utils -   [NLVR2]: iter 38892 Ep: 7.20 loss 0.025 score 0.196 lr 1.77808e-06 
12/02/2021 20:03:18 - INFO - volta.train_utils -   [NLVR2]: iter 38972 Ep: 7.22 loss 0.027 score 0.196 lr 1.77602e-06 
12/02/2021 20:03:40 - INFO - volta.train_utils -   [NLVR2]: iter 39052 Ep: 7.23 loss 0.027 score 0.200 lr 1.77396e-06 
12/02/2021 20:04:02 - INFO - volta.train_utils -   [NLVR2]: iter 39132 Ep: 7.25 loss 0.025 score 0.197 lr 1.7719e-06 
12/02/2021 20:04:23 - INFO - volta.train_utils -   [NLVR2]: iter 39212 Ep: 7.26 loss 0.027 score 0.195 lr 1.76984e-06 
12/02/2021 20:04:45 - INFO - volta.train_utils -   [NLVR2]: iter 39292 Ep: 7.28 loss 0.026 score 0.199 lr 1.76778e-06 
12/02/2021 20:05:07 - INFO - volta.train_utils -   [NLVR2]: iter 39372 Ep: 7.29 loss 0.028 score 0.198 lr 1.76573e-06 
12/02/2021 20:05:29 - INFO - volta.train_utils -   [NLVR2]: iter 39452 Ep: 7.31 loss 0.029 score 0.203 lr 1.76367e-06 
12/02/2021 20:05:51 - INFO - volta.train_utils -   [NLVR2]: iter 39532 Ep: 7.32 loss 0.024 score 0.201 lr 1.76161e-06 
12/02/2021 20:06:13 - INFO - volta.train_utils -   [NLVR2]: iter 39612 Ep: 7.34 loss 0.024 score 0.203 lr 1.75955e-06 
12/02/2021 20:06:35 - INFO - volta.train_utils -   [NLVR2]: iter 39692 Ep: 7.35 loss 0.024 score 0.199 lr 1.75749e-06 
12/02/2021 20:06:56 - INFO - volta.train_utils -   [NLVR2]: iter 39772 Ep: 7.37 loss 0.025 score 0.196 lr 1.75543e-06 
12/02/2021 20:07:18 - INFO - volta.train_utils -   [NLVR2]: iter 39852 Ep: 7.38 loss 0.025 score 0.201 lr 1.75338e-06 
12/02/2021 20:07:40 - INFO - volta.train_utils -   [NLVR2]: iter 39932 Ep: 7.40 loss 0.024 score 0.202 lr 1.75132e-06 
12/02/2021 20:08:02 - INFO - volta.train_utils -   [NLVR2]: iter 40012 Ep: 7.41 loss 0.027 score 0.196 lr 1.74926e-06 
12/02/2021 20:08:24 - INFO - volta.train_utils -   [NLVR2]: iter 40092 Ep: 7.43 loss 0.026 score 0.195 lr 1.7472e-06 
12/02/2021 20:08:46 - INFO - volta.train_utils -   [NLVR2]: iter 40172 Ep: 7.44 loss 0.024 score 0.204 lr 1.74514e-06 
12/02/2021 20:09:08 - INFO - volta.train_utils -   [NLVR2]: iter 40252 Ep: 7.46 loss 0.029 score 0.199 lr 1.74308e-06 
12/02/2021 20:09:30 - INFO - volta.train_utils -   [NLVR2]: iter 40332 Ep: 7.47 loss 0.025 score 0.198 lr 1.74103e-06 
12/02/2021 20:09:52 - INFO - volta.train_utils -   [NLVR2]: iter 40412 Ep: 7.49 loss 0.026 score 0.199 lr 1.73897e-06 
12/02/2021 20:10:13 - INFO - volta.train_utils -   [NLVR2]: iter 40492 Ep: 7.50 loss 0.027 score 0.195 lr 1.73691e-06 
12/02/2021 20:10:35 - INFO - volta.train_utils -   [NLVR2]: iter 40572 Ep: 7.52 loss 0.022 score 0.202 lr 1.73485e-06 
12/02/2021 20:10:57 - INFO - volta.train_utils -   [NLVR2]: iter 40652 Ep: 7.53 loss 0.027 score 0.203 lr 1.73279e-06 
12/02/2021 20:11:19 - INFO - volta.train_utils -   [NLVR2]: iter 40732 Ep: 7.55 loss 0.024 score 0.199 lr 1.73073e-06 
12/02/2021 20:11:41 - INFO - volta.train_utils -   [NLVR2]: iter 40812 Ep: 7.56 loss 0.025 score 0.197 lr 1.72868e-06 
12/02/2021 20:12:03 - INFO - volta.train_utils -   [NLVR2]: iter 40892 Ep: 7.58 loss 0.026 score 0.200 lr 1.72662e-06 
12/02/2021 20:12:25 - INFO - volta.train_utils -   [NLVR2]: iter 40972 Ep: 7.59 loss 0.024 score 0.197 lr 1.72456e-06 
12/02/2021 20:12:47 - INFO - volta.train_utils -   [NLVR2]: iter 41052 Ep: 7.61 loss 0.025 score 0.203 lr 1.7225e-06 
12/02/2021 20:13:09 - INFO - volta.train_utils -   [NLVR2]: iter 41132 Ep: 7.62 loss 0.025 score 0.205 lr 1.72044e-06 
12/02/2021 20:13:31 - INFO - volta.train_utils -   [NLVR2]: iter 41212 Ep: 7.63 loss 0.027 score 0.201 lr 1.71838e-06 
12/02/2021 20:13:53 - INFO - volta.train_utils -   [NLVR2]: iter 41292 Ep: 7.65 loss 0.027 score 0.199 lr 1.71632e-06 
12/02/2021 20:14:15 - INFO - volta.train_utils -   [NLVR2]: iter 41372 Ep: 7.66 loss 0.025 score 0.204 lr 1.71427e-06 
12/02/2021 20:14:37 - INFO - volta.train_utils -   [NLVR2]: iter 41452 Ep: 7.68 loss 0.023 score 0.202 lr 1.71221e-06 
12/02/2021 20:14:59 - INFO - volta.train_utils -   [NLVR2]: iter 41532 Ep: 7.69 loss 0.025 score 0.200 lr 1.71015e-06 
12/02/2021 20:15:21 - INFO - volta.train_utils -   [NLVR2]: iter 41612 Ep: 7.71 loss 0.026 score 0.202 lr 1.70809e-06 
12/02/2021 20:15:42 - INFO - volta.train_utils -   [NLVR2]: iter 41692 Ep: 7.72 loss 0.022 score 0.203 lr 1.70603e-06 
12/02/2021 20:16:04 - INFO - volta.train_utils -   [NLVR2]: iter 41772 Ep: 7.74 loss 0.027 score 0.201 lr 1.70397e-06 
12/02/2021 20:16:26 - INFO - volta.train_utils -   [NLVR2]: iter 41852 Ep: 7.75 loss 0.025 score 0.197 lr 1.70192e-06 
12/02/2021 20:16:48 - INFO - volta.train_utils -   [NLVR2]: iter 41932 Ep: 7.77 loss 0.025 score 0.204 lr 1.69986e-06 
12/02/2021 20:17:10 - INFO - volta.train_utils -   [NLVR2]: iter 42012 Ep: 7.78 loss 0.028 score 0.193 lr 1.6978e-06 
12/02/2021 20:17:32 - INFO - volta.train_utils -   [NLVR2]: iter 42092 Ep: 7.80 loss 0.025 score 0.202 lr 1.69574e-06 
12/02/2021 20:17:54 - INFO - volta.train_utils -   [NLVR2]: iter 42172 Ep: 7.81 loss 0.024 score 0.199 lr 1.69368e-06 
12/02/2021 20:18:16 - INFO - volta.train_utils -   [NLVR2]: iter 42252 Ep: 7.83 loss 0.025 score 0.203 lr 1.69162e-06 
12/02/2021 20:18:38 - INFO - volta.train_utils -   [NLVR2]: iter 42332 Ep: 7.84 loss 0.023 score 0.204 lr 1.68957e-06 
12/02/2021 20:19:00 - INFO - volta.train_utils -   [NLVR2]: iter 42412 Ep: 7.86 loss 0.024 score 0.201 lr 1.68751e-06 
12/02/2021 20:19:22 - INFO - volta.train_utils -   [NLVR2]: iter 42492 Ep: 7.87 loss 0.021 score 0.203 lr 1.68545e-06 
12/02/2021 20:19:44 - INFO - volta.train_utils -   [NLVR2]: iter 42572 Ep: 7.89 loss 0.023 score 0.198 lr 1.68339e-06 
12/02/2021 20:20:06 - INFO - volta.train_utils -   [NLVR2]: iter 42652 Ep: 7.90 loss 0.025 score 0.204 lr 1.68133e-06 
12/02/2021 20:20:27 - INFO - volta.train_utils -   [NLVR2]: iter 42732 Ep: 7.92 loss 0.024 score 0.205 lr 1.67927e-06 
12/02/2021 20:20:49 - INFO - volta.train_utils -   [NLVR2]: iter 42812 Ep: 7.93 loss 0.022 score 0.209 lr 1.67722e-06 
12/02/2021 20:21:11 - INFO - volta.train_utils -   [NLVR2]: iter 42892 Ep: 7.95 loss 0.025 score 0.202 lr 1.67516e-06 
12/02/2021 20:21:33 - INFO - volta.train_utils -   [NLVR2]: iter 42972 Ep: 7.96 loss 0.024 score 0.202 lr 1.6731e-06 
12/02/2021 20:21:55 - INFO - volta.train_utils -   [NLVR2]: iter 43052 Ep: 7.98 loss 0.023 score 0.205 lr 1.67104e-06 
12/02/2021 20:22:16 - INFO - volta.train_utils -   [NLVR2]: iter 43132 Ep: 7.99 loss 0.025 score 0.208 lr 1.66898e-06 
12/02/2021 20:23:12 - INFO - volta.train_utils -   Eval task TASK12 on iteration 43168 
12/02/2021 20:23:12 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.708 score 69.352 
12/02/2021 20:23:12 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  40%|████      | 8/20 [3:27:13<5:10:25, 1552.13s/it]12/02/2021 20:24:10 - INFO - volta.train_utils -   [NLVR2]: iter 43248 Ep: 8.01 loss 0.024 score 0.210 lr 1.66646e-06 
12/02/2021 20:24:32 - INFO - volta.train_utils -   [NLVR2]: iter 43328 Ep: 8.03 loss 0.024 score 0.203 lr 1.66394e-06 
12/02/2021 20:24:54 - INFO - volta.train_utils -   [NLVR2]: iter 43408 Ep: 8.04 loss 0.026 score 0.204 lr 1.66188e-06 
12/02/2021 20:25:16 - INFO - volta.train_utils -   [NLVR2]: iter 43488 Ep: 8.06 loss 0.023 score 0.205 lr 1.65982e-06 
12/02/2021 20:25:38 - INFO - volta.train_utils -   [NLVR2]: iter 43568 Ep: 8.07 loss 0.023 score 0.205 lr 1.65776e-06 
12/02/2021 20:26:00 - INFO - volta.train_utils -   [NLVR2]: iter 43648 Ep: 8.09 loss 0.027 score 0.197 lr 1.65571e-06 
12/02/2021 20:26:22 - INFO - volta.train_utils -   [NLVR2]: iter 43728 Ep: 8.10 loss 0.026 score 0.201 lr 1.65365e-06 
12/02/2021 20:26:44 - INFO - volta.train_utils -   [NLVR2]: iter 43808 Ep: 8.12 loss 0.023 score 0.204 lr 1.65159e-06 
12/02/2021 20:27:06 - INFO - volta.train_utils -   [NLVR2]: iter 43888 Ep: 8.13 loss 0.025 score 0.205 lr 1.64953e-06 
12/02/2021 20:27:28 - INFO - volta.train_utils -   [NLVR2]: iter 43968 Ep: 8.15 loss 0.025 score 0.202 lr 1.64747e-06 
12/02/2021 20:27:50 - INFO - volta.train_utils -   [NLVR2]: iter 44048 Ep: 8.16 loss 0.021 score 0.200 lr 1.64541e-06 
12/02/2021 20:28:12 - INFO - volta.train_utils -   [NLVR2]: iter 44128 Ep: 8.17 loss 0.024 score 0.203 lr 1.64336e-06 
12/02/2021 20:28:33 - INFO - volta.train_utils -   [NLVR2]: iter 44208 Ep: 8.19 loss 0.021 score 0.205 lr 1.6413e-06 
12/02/2021 20:28:55 - INFO - volta.train_utils -   [NLVR2]: iter 44288 Ep: 8.20 loss 0.024 score 0.206 lr 1.63924e-06 
12/02/2021 20:29:17 - INFO - volta.train_utils -   [NLVR2]: iter 44368 Ep: 8.22 loss 0.024 score 0.200 lr 1.63718e-06 
12/02/2021 20:29:39 - INFO - volta.train_utils -   [NLVR2]: iter 44448 Ep: 8.23 loss 0.023 score 0.204 lr 1.63512e-06 
12/02/2021 20:30:01 - INFO - volta.train_utils -   [NLVR2]: iter 44528 Ep: 8.25 loss 0.025 score 0.204 lr 1.63306e-06 
12/02/2021 20:30:23 - INFO - volta.train_utils -   [NLVR2]: iter 44608 Ep: 8.26 loss 0.023 score 0.203 lr 1.63101e-06 
12/02/2021 20:30:45 - INFO - volta.train_utils -   [NLVR2]: iter 44688 Ep: 8.28 loss 0.025 score 0.204 lr 1.62895e-06 
12/02/2021 20:31:07 - INFO - volta.train_utils -   [NLVR2]: iter 44768 Ep: 8.29 loss 0.024 score 0.206 lr 1.62689e-06 
12/02/2021 20:31:29 - INFO - volta.train_utils -   [NLVR2]: iter 44848 Ep: 8.31 loss 0.026 score 0.204 lr 1.62483e-06 
12/02/2021 20:31:51 - INFO - volta.train_utils -   [NLVR2]: iter 44928 Ep: 8.32 loss 0.027 score 0.202 lr 1.62277e-06 
12/02/2021 20:32:13 - INFO - volta.train_utils -   [NLVR2]: iter 45008 Ep: 8.34 loss 0.020 score 0.204 lr 1.62071e-06 
12/02/2021 20:32:35 - INFO - volta.train_utils -   [NLVR2]: iter 45088 Ep: 8.35 loss 0.023 score 0.206 lr 1.61866e-06 
12/02/2021 20:32:57 - INFO - volta.train_utils -   [NLVR2]: iter 45168 Ep: 8.37 loss 0.024 score 0.200 lr 1.6166e-06 
12/02/2021 20:33:19 - INFO - volta.train_utils -   [NLVR2]: iter 45248 Ep: 8.38 loss 0.025 score 0.204 lr 1.61454e-06 
12/02/2021 20:33:40 - INFO - volta.train_utils -   [NLVR2]: iter 45328 Ep: 8.40 loss 0.024 score 0.206 lr 1.61248e-06 
12/02/2021 20:34:02 - INFO - volta.train_utils -   [NLVR2]: iter 45408 Ep: 8.41 loss 0.023 score 0.206 lr 1.61042e-06 
12/02/2021 20:34:24 - INFO - volta.train_utils -   [NLVR2]: iter 45488 Ep: 8.43 loss 0.024 score 0.204 lr 1.60836e-06 
12/02/2021 20:34:46 - INFO - volta.train_utils -   [NLVR2]: iter 45568 Ep: 8.44 loss 0.024 score 0.201 lr 1.6063e-06 
12/02/2021 20:35:08 - INFO - volta.train_utils -   [NLVR2]: iter 45648 Ep: 8.46 loss 0.023 score 0.203 lr 1.60425e-06 
12/02/2021 20:35:30 - INFO - volta.train_utils -   [NLVR2]: iter 45728 Ep: 8.47 loss 0.022 score 0.204 lr 1.60219e-06 
12/02/2021 20:35:52 - INFO - volta.train_utils -   [NLVR2]: iter 45808 Ep: 8.49 loss 0.027 score 0.205 lr 1.60013e-06 
12/02/2021 20:36:14 - INFO - volta.train_utils -   [NLVR2]: iter 45888 Ep: 8.50 loss 0.020 score 0.207 lr 1.59807e-06 
12/02/2021 20:36:36 - INFO - volta.train_utils -   [NLVR2]: iter 45968 Ep: 8.52 loss 0.024 score 0.207 lr 1.59601e-06 
12/02/2021 20:36:58 - INFO - volta.train_utils -   [NLVR2]: iter 46048 Ep: 8.53 loss 0.025 score 0.200 lr 1.59395e-06 
12/02/2021 20:37:20 - INFO - volta.train_utils -   [NLVR2]: iter 46128 Ep: 8.55 loss 0.023 score 0.207 lr 1.5919e-06 
12/02/2021 20:37:42 - INFO - volta.train_utils -   [NLVR2]: iter 46208 Ep: 8.56 loss 0.026 score 0.204 lr 1.58984e-06 
12/02/2021 20:38:03 - INFO - volta.train_utils -   [NLVR2]: iter 46288 Ep: 8.58 loss 0.020 score 0.209 lr 1.58778e-06 
12/02/2021 20:38:25 - INFO - volta.train_utils -   [NLVR2]: iter 46368 Ep: 8.59 loss 0.025 score 0.202 lr 1.58572e-06 
12/02/2021 20:38:47 - INFO - volta.train_utils -   [NLVR2]: iter 46448 Ep: 8.60 loss 0.024 score 0.205 lr 1.58366e-06 
12/02/2021 20:39:09 - INFO - volta.train_utils -   [NLVR2]: iter 46528 Ep: 8.62 loss 0.022 score 0.209 lr 1.5816e-06 
12/02/2021 20:39:31 - INFO - volta.train_utils -   [NLVR2]: iter 46608 Ep: 8.63 loss 0.023 score 0.205 lr 1.57955e-06 
12/02/2021 20:39:53 - INFO - volta.train_utils -   [NLVR2]: iter 46688 Ep: 8.65 loss 0.024 score 0.201 lr 1.57749e-06 
12/02/2021 20:40:15 - INFO - volta.train_utils -   [NLVR2]: iter 46768 Ep: 8.66 loss 0.026 score 0.202 lr 1.57543e-06 
12/02/2021 20:40:37 - INFO - volta.train_utils -   [NLVR2]: iter 46848 Ep: 8.68 loss 0.024 score 0.203 lr 1.57337e-06 
12/02/2021 20:40:59 - INFO - volta.train_utils -   [NLVR2]: iter 46928 Ep: 8.69 loss 0.023 score 0.200 lr 1.57131e-06 
12/02/2021 20:41:20 - INFO - volta.train_utils -   [NLVR2]: iter 47008 Ep: 8.71 loss 0.023 score 0.206 lr 1.56925e-06 
12/02/2021 20:41:42 - INFO - volta.train_utils -   [NLVR2]: iter 47088 Ep: 8.72 loss 0.025 score 0.203 lr 1.5672e-06 
12/02/2021 20:42:04 - INFO - volta.train_utils -   [NLVR2]: iter 47168 Ep: 8.74 loss 0.020 score 0.203 lr 1.56514e-06 
12/02/2021 20:42:26 - INFO - volta.train_utils -   [NLVR2]: iter 47248 Ep: 8.75 loss 0.020 score 0.209 lr 1.56308e-06 
12/02/2021 20:42:48 - INFO - volta.train_utils -   [NLVR2]: iter 47328 Ep: 8.77 loss 0.022 score 0.203 lr 1.56102e-06 
12/02/2021 20:43:10 - INFO - volta.train_utils -   [NLVR2]: iter 47408 Ep: 8.78 loss 0.022 score 0.204 lr 1.55896e-06 
12/02/2021 20:43:31 - INFO - volta.train_utils -   [NLVR2]: iter 47488 Ep: 8.80 loss 0.025 score 0.206 lr 1.5569e-06 
12/02/2021 20:43:53 - INFO - volta.train_utils -   [NLVR2]: iter 47568 Ep: 8.81 loss 0.023 score 0.203 lr 1.55485e-06 
12/02/2021 20:44:15 - INFO - volta.train_utils -   [NLVR2]: iter 47648 Ep: 8.83 loss 0.022 score 0.205 lr 1.55279e-06 
12/02/2021 20:44:37 - INFO - volta.train_utils -   [NLVR2]: iter 47728 Ep: 8.84 loss 0.022 score 0.209 lr 1.55073e-06 
12/02/2021 20:44:59 - INFO - volta.train_utils -   [NLVR2]: iter 47808 Ep: 8.86 loss 0.020 score 0.209 lr 1.54867e-06 
12/02/2021 20:45:21 - INFO - volta.train_utils -   [NLVR2]: iter 47888 Ep: 8.87 loss 0.020 score 0.208 lr 1.54661e-06 
12/02/2021 20:45:43 - INFO - volta.train_utils -   [NLVR2]: iter 47968 Ep: 8.89 loss 0.021 score 0.210 lr 1.54455e-06 
12/02/2021 20:46:04 - INFO - volta.train_utils -   [NLVR2]: iter 48048 Ep: 8.90 loss 0.020 score 0.208 lr 1.5425e-06 
12/02/2021 20:46:26 - INFO - volta.train_utils -   [NLVR2]: iter 48128 Ep: 8.92 loss 0.022 score 0.207 lr 1.54044e-06 
12/02/2021 20:46:48 - INFO - volta.train_utils -   [NLVR2]: iter 48208 Ep: 8.93 loss 0.023 score 0.209 lr 1.53838e-06 
12/02/2021 20:47:11 - INFO - volta.train_utils -   [NLVR2]: iter 48288 Ep: 8.95 loss 0.025 score 0.202 lr 1.53632e-06 
12/02/2021 20:47:33 - INFO - volta.train_utils -   [NLVR2]: iter 48368 Ep: 8.96 loss 0.023 score 0.204 lr 1.53426e-06 
12/02/2021 20:47:55 - INFO - volta.train_utils -   [NLVR2]: iter 48448 Ep: 8.98 loss 0.024 score 0.207 lr 1.5322e-06 
12/02/2021 20:48:17 - INFO - volta.train_utils -   [NLVR2]: iter 48528 Ep: 8.99 loss 0.021 score 0.213 lr 1.53014e-06 
12/02/2021 20:49:12 - INFO - volta.train_utils -   Eval task TASK12 on iteration 48564 
12/02/2021 20:49:12 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.750 score 69.338 
Epoch:  45%|████▌     | 9/20 [3:52:37<4:42:59, 1543.61s/it]12/02/2021 20:49:34 - INFO - volta.train_utils -   [NLVR2]: iter 48644 Ep: 9.01 loss 0.023 score 0.211 lr 1.52762e-06 
12/02/2021 20:49:56 - INFO - volta.train_utils -   [NLVR2]: iter 48724 Ep: 9.03 loss 0.020 score 0.209 lr 1.5251e-06 
12/02/2021 20:50:18 - INFO - volta.train_utils -   [NLVR2]: iter 48804 Ep: 9.04 loss 0.020 score 0.212 lr 1.52304e-06 
12/02/2021 20:50:40 - INFO - volta.train_utils -   [NLVR2]: iter 48884 Ep: 9.06 loss 0.018 score 0.207 lr 1.52099e-06 
12/02/2021 20:51:01 - INFO - volta.train_utils -   [NLVR2]: iter 48964 Ep: 9.07 loss 0.022 score 0.211 lr 1.51893e-06 
12/02/2021 20:51:23 - INFO - volta.train_utils -   [NLVR2]: iter 49044 Ep: 9.09 loss 0.021 score 0.206 lr 1.51687e-06 
12/02/2021 20:51:45 - INFO - volta.train_utils -   [NLVR2]: iter 49124 Ep: 9.10 loss 0.022 score 0.210 lr 1.51481e-06 
12/02/2021 20:52:07 - INFO - volta.train_utils -   [NLVR2]: iter 49204 Ep: 9.12 loss 0.022 score 0.210 lr 1.51275e-06 
12/02/2021 20:52:29 - INFO - volta.train_utils -   [NLVR2]: iter 49284 Ep: 9.13 loss 0.022 score 0.207 lr 1.51069e-06 
12/02/2021 20:52:51 - INFO - volta.train_utils -   [NLVR2]: iter 49364 Ep: 9.14 loss 0.024 score 0.207 lr 1.50863e-06 
12/02/2021 20:53:12 - INFO - volta.train_utils -   [NLVR2]: iter 49444 Ep: 9.16 loss 0.021 score 0.209 lr 1.50658e-06 
12/02/2021 20:53:34 - INFO - volta.train_utils -   [NLVR2]: iter 49524 Ep: 9.17 loss 0.024 score 0.205 lr 1.50452e-06 
12/02/2021 20:53:56 - INFO - volta.train_utils -   [NLVR2]: iter 49604 Ep: 9.19 loss 0.022 score 0.207 lr 1.50246e-06 
12/02/2021 20:54:18 - INFO - volta.train_utils -   [NLVR2]: iter 49684 Ep: 9.20 loss 0.023 score 0.212 lr 1.5004e-06 
12/02/2021 20:54:40 - INFO - volta.train_utils -   [NLVR2]: iter 49764 Ep: 9.22 loss 0.024 score 0.199 lr 1.49834e-06 
12/02/2021 20:55:02 - INFO - volta.train_utils -   [NLVR2]: iter 49844 Ep: 9.23 loss 0.024 score 0.204 lr 1.49628e-06 
12/02/2021 20:55:24 - INFO - volta.train_utils -   [NLVR2]: iter 49924 Ep: 9.25 loss 0.020 score 0.210 lr 1.49423e-06 
12/02/2021 20:55:46 - INFO - volta.train_utils -   [NLVR2]: iter 50004 Ep: 9.26 loss 0.024 score 0.206 lr 1.49217e-06 
12/02/2021 20:56:08 - INFO - volta.train_utils -   [NLVR2]: iter 50084 Ep: 9.28 loss 0.021 score 0.206 lr 1.49011e-06 
12/02/2021 20:56:30 - INFO - volta.train_utils -   [NLVR2]: iter 50164 Ep: 9.29 loss 0.021 score 0.206 lr 1.48805e-06 
12/02/2021 20:56:51 - INFO - volta.train_utils -   [NLVR2]: iter 50244 Ep: 9.31 loss 0.022 score 0.209 lr 1.48599e-06 
12/02/2021 20:57:13 - INFO - volta.train_utils -   [NLVR2]: iter 50324 Ep: 9.32 loss 0.020 score 0.207 lr 1.48393e-06 
12/02/2021 20:57:35 - INFO - volta.train_utils -   [NLVR2]: iter 50404 Ep: 9.34 loss 0.023 score 0.208 lr 1.48188e-06 
12/02/2021 20:57:57 - INFO - volta.train_utils -   [NLVR2]: iter 50484 Ep: 9.35 loss 0.021 score 0.207 lr 1.47982e-06 
12/02/2021 20:58:19 - INFO - volta.train_utils -   [NLVR2]: iter 50564 Ep: 9.37 loss 0.023 score 0.205 lr 1.47776e-06 
12/02/2021 20:58:41 - INFO - volta.train_utils -   [NLVR2]: iter 50644 Ep: 9.38 loss 0.022 score 0.207 lr 1.4757e-06 
12/02/2021 20:59:03 - INFO - volta.train_utils -   [NLVR2]: iter 50724 Ep: 9.40 loss 0.022 score 0.210 lr 1.47364e-06 
12/02/2021 20:59:25 - INFO - volta.train_utils -   [NLVR2]: iter 50804 Ep: 9.41 loss 0.022 score 0.207 lr 1.47158e-06 
12/02/2021 20:59:47 - INFO - volta.train_utils -   [NLVR2]: iter 50884 Ep: 9.43 loss 0.022 score 0.204 lr 1.46953e-06 
12/02/2021 21:00:09 - INFO - volta.train_utils -   [NLVR2]: iter 50964 Ep: 9.44 loss 0.021 score 0.211 lr 1.46747e-06 
12/02/2021 21:00:31 - INFO - volta.train_utils -   [NLVR2]: iter 51044 Ep: 9.46 loss 0.022 score 0.212 lr 1.46541e-06 
12/02/2021 21:00:53 - INFO - volta.train_utils -   [NLVR2]: iter 51124 Ep: 9.47 loss 0.024 score 0.202 lr 1.46335e-06 
12/02/2021 21:01:15 - INFO - volta.train_utils -   [NLVR2]: iter 51204 Ep: 9.49 loss 0.021 score 0.209 lr 1.46129e-06 
12/02/2021 21:01:37 - INFO - volta.train_utils -   [NLVR2]: iter 51284 Ep: 9.50 loss 0.024 score 0.206 lr 1.45923e-06 
12/02/2021 21:01:59 - INFO - volta.train_utils -   [NLVR2]: iter 51364 Ep: 9.52 loss 0.021 score 0.213 lr 1.45718e-06 
12/02/2021 21:02:21 - INFO - volta.train_utils -   [NLVR2]: iter 51444 Ep: 9.53 loss 0.018 score 0.215 lr 1.45512e-06 
12/02/2021 21:02:43 - INFO - volta.train_utils -   [NLVR2]: iter 51524 Ep: 9.55 loss 0.022 score 0.211 lr 1.45306e-06 
12/02/2021 21:03:04 - INFO - volta.train_utils -   [NLVR2]: iter 51604 Ep: 9.56 loss 0.018 score 0.212 lr 1.451e-06 
12/02/2021 21:03:26 - INFO - volta.train_utils -   [NLVR2]: iter 51684 Ep: 9.57 loss 0.024 score 0.209 lr 1.44894e-06 
12/02/2021 21:03:48 - INFO - volta.train_utils -   [NLVR2]: iter 51764 Ep: 9.59 loss 0.019 score 0.215 lr 1.44688e-06 
12/02/2021 21:04:10 - INFO - volta.train_utils -   [NLVR2]: iter 51844 Ep: 9.60 loss 0.020 score 0.208 lr 1.44483e-06 
12/02/2021 21:04:32 - INFO - volta.train_utils -   [NLVR2]: iter 51924 Ep: 9.62 loss 0.021 score 0.205 lr 1.44277e-06 
12/02/2021 21:04:54 - INFO - volta.train_utils -   [NLVR2]: iter 52004 Ep: 9.63 loss 0.020 score 0.210 lr 1.44071e-06 
12/02/2021 21:05:16 - INFO - volta.train_utils -   [NLVR2]: iter 52084 Ep: 9.65 loss 0.025 score 0.206 lr 1.43865e-06 
12/02/2021 21:05:38 - INFO - volta.train_utils -   [NLVR2]: iter 52164 Ep: 9.66 loss 0.024 score 0.211 lr 1.43659e-06 
12/02/2021 21:06:00 - INFO - volta.train_utils -   [NLVR2]: iter 52244 Ep: 9.68 loss 0.023 score 0.205 lr 1.43453e-06 
12/02/2021 21:06:22 - INFO - volta.train_utils -   [NLVR2]: iter 52324 Ep: 9.69 loss 0.017 score 0.211 lr 1.43247e-06 
12/02/2021 21:06:44 - INFO - volta.train_utils -   [NLVR2]: iter 52404 Ep: 9.71 loss 0.021 score 0.211 lr 1.43042e-06 
12/02/2021 21:07:06 - INFO - volta.train_utils -   [NLVR2]: iter 52484 Ep: 9.72 loss 0.020 score 0.213 lr 1.42836e-06 
12/02/2021 21:07:28 - INFO - volta.train_utils -   [NLVR2]: iter 52564 Ep: 9.74 loss 0.020 score 0.206 lr 1.4263e-06 
12/02/2021 21:07:50 - INFO - volta.train_utils -   [NLVR2]: iter 52644 Ep: 9.75 loss 0.023 score 0.207 lr 1.42424e-06 
12/02/2021 21:08:11 - INFO - volta.train_utils -   [NLVR2]: iter 52724 Ep: 9.77 loss 0.023 score 0.207 lr 1.42218e-06 
12/02/2021 21:08:33 - INFO - volta.train_utils -   [NLVR2]: iter 52804 Ep: 9.78 loss 0.021 score 0.212 lr 1.42012e-06 
12/02/2021 21:08:55 - INFO - volta.train_utils -   [NLVR2]: iter 52884 Ep: 9.80 loss 0.018 score 0.216 lr 1.41807e-06 
12/02/2021 21:09:17 - INFO - volta.train_utils -   [NLVR2]: iter 52964 Ep: 9.81 loss 0.020 score 0.210 lr 1.41601e-06 
12/02/2021 21:09:39 - INFO - volta.train_utils -   [NLVR2]: iter 53044 Ep: 9.83 loss 0.020 score 0.211 lr 1.41395e-06 
12/02/2021 21:10:01 - INFO - volta.train_utils -   [NLVR2]: iter 53124 Ep: 9.84 loss 0.021 score 0.214 lr 1.41189e-06 
12/02/2021 21:10:23 - INFO - volta.train_utils -   [NLVR2]: iter 53204 Ep: 9.86 loss 0.018 score 0.212 lr 1.40983e-06 
12/02/2021 21:10:45 - INFO - volta.train_utils -   [NLVR2]: iter 53284 Ep: 9.87 loss 0.021 score 0.212 lr 1.40777e-06 
12/02/2021 21:11:07 - INFO - volta.train_utils -   [NLVR2]: iter 53364 Ep: 9.89 loss 0.022 score 0.209 lr 1.40572e-06 
12/02/2021 21:11:29 - INFO - volta.train_utils -   [NLVR2]: iter 53444 Ep: 9.90 loss 0.018 score 0.212 lr 1.40366e-06 
12/02/2021 21:11:51 - INFO - volta.train_utils -   [NLVR2]: iter 53524 Ep: 9.92 loss 0.020 score 0.209 lr 1.4016e-06 
12/02/2021 21:12:13 - INFO - volta.train_utils -   [NLVR2]: iter 53604 Ep: 9.93 loss 0.020 score 0.214 lr 1.39954e-06 
12/02/2021 21:12:35 - INFO - volta.train_utils -   [NLVR2]: iter 53684 Ep: 9.95 loss 0.020 score 0.213 lr 1.39748e-06 
12/02/2021 21:12:57 - INFO - volta.train_utils -   [NLVR2]: iter 53764 Ep: 9.96 loss 0.020 score 0.215 lr 1.39542e-06 
12/02/2021 21:13:19 - INFO - volta.train_utils -   [NLVR2]: iter 53844 Ep: 9.97 loss 0.018 score 0.212 lr 1.39337e-06 
12/02/2021 21:13:40 - INFO - volta.train_utils -   [NLVR2]: iter 53924 Ep: 9.99 loss 0.019 score 0.213 lr 1.39131e-06 
12/02/2021 21:14:36 - INFO - volta.train_utils -   Eval task TASK12 on iteration 53960 
12/02/2021 21:14:36 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.775 score 69.323 
Epoch:  50%|█████     | 10/20 [4:18:01<4:16:17, 1537.75s/it]12/02/2021 21:14:58 - INFO - volta.train_utils -   [NLVR2]: iter 54040 Ep: 10.01 loss 0.019 score 0.216 lr 1.38879e-06 
12/02/2021 21:15:20 - INFO - volta.train_utils -   [NLVR2]: iter 54120 Ep: 10.03 loss 0.020 score 0.209 lr 1.38626e-06 
12/02/2021 21:15:42 - INFO - volta.train_utils -   [NLVR2]: iter 54200 Ep: 10.04 loss 0.020 score 0.209 lr 1.38421e-06 
12/02/2021 21:16:04 - INFO - volta.train_utils -   [NLVR2]: iter 54280 Ep: 10.06 loss 0.019 score 0.212 lr 1.38215e-06 
12/02/2021 21:16:26 - INFO - volta.train_utils -   [NLVR2]: iter 54360 Ep: 10.07 loss 0.022 score 0.210 lr 1.38009e-06 
12/02/2021 21:16:48 - INFO - volta.train_utils -   [NLVR2]: iter 54440 Ep: 10.09 loss 0.021 score 0.214 lr 1.37803e-06 
12/02/2021 21:17:10 - INFO - volta.train_utils -   [NLVR2]: iter 54520 Ep: 10.10 loss 0.019 score 0.212 lr 1.37597e-06 
12/02/2021 21:17:32 - INFO - volta.train_utils -   [NLVR2]: iter 54600 Ep: 10.11 loss 0.021 score 0.213 lr 1.37391e-06 
12/02/2021 21:17:54 - INFO - volta.train_utils -   [NLVR2]: iter 54680 Ep: 10.13 loss 0.021 score 0.213 lr 1.37186e-06 
12/02/2021 21:18:16 - INFO - volta.train_utils -   [NLVR2]: iter 54760 Ep: 10.14 loss 0.016 score 0.213 lr 1.3698e-06 
12/02/2021 21:18:38 - INFO - volta.train_utils -   [NLVR2]: iter 54840 Ep: 10.16 loss 0.021 score 0.213 lr 1.36774e-06 
12/02/2021 21:19:00 - INFO - volta.train_utils -   [NLVR2]: iter 54920 Ep: 10.17 loss 0.022 score 0.213 lr 1.36568e-06 
12/02/2021 21:19:22 - INFO - volta.train_utils -   [NLVR2]: iter 55000 Ep: 10.19 loss 0.018 score 0.214 lr 1.36362e-06 
12/02/2021 21:19:44 - INFO - volta.train_utils -   [NLVR2]: iter 55080 Ep: 10.20 loss 0.022 score 0.212 lr 1.36156e-06 
12/02/2021 21:20:05 - INFO - volta.train_utils -   [NLVR2]: iter 55160 Ep: 10.22 loss 0.019 score 0.213 lr 1.35951e-06 
12/02/2021 21:20:28 - INFO - volta.train_utils -   [NLVR2]: iter 55240 Ep: 10.23 loss 0.020 score 0.212 lr 1.35745e-06 
12/02/2021 21:20:50 - INFO - volta.train_utils -   [NLVR2]: iter 55320 Ep: 10.25 loss 0.024 score 0.213 lr 1.35539e-06 
12/02/2021 21:21:11 - INFO - volta.train_utils -   [NLVR2]: iter 55400 Ep: 10.26 loss 0.018 score 0.211 lr 1.35333e-06 
12/02/2021 21:21:33 - INFO - volta.train_utils -   [NLVR2]: iter 55480 Ep: 10.28 loss 0.022 score 0.210 lr 1.35127e-06 
12/02/2021 21:21:55 - INFO - volta.train_utils -   [NLVR2]: iter 55560 Ep: 10.29 loss 0.020 score 0.208 lr 1.34921e-06 
12/02/2021 21:22:17 - INFO - volta.train_utils -   [NLVR2]: iter 55640 Ep: 10.31 loss 0.018 score 0.214 lr 1.34716e-06 
12/02/2021 21:22:39 - INFO - volta.train_utils -   [NLVR2]: iter 55720 Ep: 10.32 loss 0.015 score 0.216 lr 1.3451e-06 
12/02/2021 21:23:01 - INFO - volta.train_utils -   [NLVR2]: iter 55800 Ep: 10.34 loss 0.019 score 0.213 lr 1.34304e-06 
12/02/2021 21:23:23 - INFO - volta.train_utils -   [NLVR2]: iter 55880 Ep: 10.35 loss 0.021 score 0.210 lr 1.34098e-06 
12/02/2021 21:23:45 - INFO - volta.train_utils -   [NLVR2]: iter 55960 Ep: 10.37 loss 0.020 score 0.215 lr 1.33892e-06 
12/02/2021 21:24:07 - INFO - volta.train_utils -   [NLVR2]: iter 56040 Ep: 10.38 loss 0.018 score 0.209 lr 1.33686e-06 
12/02/2021 21:24:28 - INFO - volta.train_utils -   [NLVR2]: iter 56120 Ep: 10.40 loss 0.021 score 0.215 lr 1.33481e-06 
12/02/2021 21:24:50 - INFO - volta.train_utils -   [NLVR2]: iter 56200 Ep: 10.41 loss 0.023 score 0.205 lr 1.33275e-06 
12/02/2021 21:25:12 - INFO - volta.train_utils -   [NLVR2]: iter 56280 Ep: 10.43 loss 0.020 score 0.214 lr 1.33069e-06 
12/02/2021 21:25:34 - INFO - volta.train_utils -   [NLVR2]: iter 56360 Ep: 10.44 loss 0.021 score 0.211 lr 1.32863e-06 
12/02/2021 21:25:56 - INFO - volta.train_utils -   [NLVR2]: iter 56440 Ep: 10.46 loss 0.020 score 0.211 lr 1.32657e-06 
12/02/2021 21:26:18 - INFO - volta.train_utils -   [NLVR2]: iter 56520 Ep: 10.47 loss 0.017 score 0.212 lr 1.32451e-06 
12/02/2021 21:26:40 - INFO - volta.train_utils -   [NLVR2]: iter 56600 Ep: 10.49 loss 0.023 score 0.214 lr 1.32245e-06 
12/02/2021 21:27:02 - INFO - volta.train_utils -   [NLVR2]: iter 56680 Ep: 10.50 loss 0.023 score 0.210 lr 1.3204e-06 
12/02/2021 21:27:24 - INFO - volta.train_utils -   [NLVR2]: iter 56760 Ep: 10.52 loss 0.023 score 0.213 lr 1.31834e-06 
12/02/2021 21:27:46 - INFO - volta.train_utils -   [NLVR2]: iter 56840 Ep: 10.53 loss 0.019 score 0.215 lr 1.31628e-06 
12/02/2021 21:28:08 - INFO - volta.train_utils -   [NLVR2]: iter 56920 Ep: 10.54 loss 0.018 score 0.215 lr 1.31422e-06 
12/02/2021 21:28:30 - INFO - volta.train_utils -   [NLVR2]: iter 57000 Ep: 10.56 loss 0.019 score 0.216 lr 1.31216e-06 
12/02/2021 21:28:52 - INFO - volta.train_utils -   [NLVR2]: iter 57080 Ep: 10.57 loss 0.018 score 0.213 lr 1.3101e-06 
12/02/2021 21:29:14 - INFO - volta.train_utils -   [NLVR2]: iter 57160 Ep: 10.59 loss 0.018 score 0.214 lr 1.30805e-06 
12/02/2021 21:29:35 - INFO - volta.train_utils -   [NLVR2]: iter 57240 Ep: 10.60 loss 0.021 score 0.211 lr 1.30599e-06 
12/02/2021 21:29:58 - INFO - volta.train_utils -   [NLVR2]: iter 57320 Ep: 10.62 loss 0.021 score 0.214 lr 1.30393e-06 
12/02/2021 21:30:19 - INFO - volta.train_utils -   [NLVR2]: iter 57400 Ep: 10.63 loss 0.020 score 0.209 lr 1.30187e-06 
12/02/2021 21:30:41 - INFO - volta.train_utils -   [NLVR2]: iter 57480 Ep: 10.65 loss 0.018 score 0.211 lr 1.29981e-06 
12/02/2021 21:31:03 - INFO - volta.train_utils -   [NLVR2]: iter 57560 Ep: 10.66 loss 0.020 score 0.215 lr 1.29775e-06 
12/02/2021 21:31:25 - INFO - volta.train_utils -   [NLVR2]: iter 57640 Ep: 10.68 loss 0.020 score 0.209 lr 1.2957e-06 
12/02/2021 21:31:47 - INFO - volta.train_utils -   [NLVR2]: iter 57720 Ep: 10.69 loss 0.020 score 0.207 lr 1.29364e-06 
12/02/2021 21:32:09 - INFO - volta.train_utils -   [NLVR2]: iter 57800 Ep: 10.71 loss 0.018 score 0.213 lr 1.29158e-06 
12/02/2021 21:32:31 - INFO - volta.train_utils -   [NLVR2]: iter 57880 Ep: 10.72 loss 0.021 score 0.208 lr 1.28952e-06 
12/02/2021 21:32:53 - INFO - volta.train_utils -   [NLVR2]: iter 57960 Ep: 10.74 loss 0.020 score 0.212 lr 1.28746e-06 
12/02/2021 21:33:14 - INFO - volta.train_utils -   [NLVR2]: iter 58040 Ep: 10.75 loss 0.017 score 0.218 lr 1.2854e-06 
12/02/2021 21:33:36 - INFO - volta.train_utils -   [NLVR2]: iter 58120 Ep: 10.77 loss 0.019 score 0.213 lr 1.28335e-06 
12/02/2021 21:33:58 - INFO - volta.train_utils -   [NLVR2]: iter 58200 Ep: 10.78 loss 0.020 score 0.211 lr 1.28129e-06 
12/02/2021 21:34:20 - INFO - volta.train_utils -   [NLVR2]: iter 58280 Ep: 10.80 loss 0.022 score 0.215 lr 1.27923e-06 
12/02/2021 21:34:42 - INFO - volta.train_utils -   [NLVR2]: iter 58360 Ep: 10.81 loss 0.019 score 0.212 lr 1.27717e-06 
12/02/2021 21:35:04 - INFO - volta.train_utils -   [NLVR2]: iter 58440 Ep: 10.83 loss 0.021 score 0.217 lr 1.27511e-06 
12/02/2021 21:35:25 - INFO - volta.train_utils -   [NLVR2]: iter 58520 Ep: 10.84 loss 0.019 score 0.215 lr 1.27305e-06 
12/02/2021 21:35:47 - INFO - volta.train_utils -   [NLVR2]: iter 58600 Ep: 10.86 loss 0.018 score 0.217 lr 1.271e-06 
12/02/2021 21:36:09 - INFO - volta.train_utils -   [NLVR2]: iter 58680 Ep: 10.87 loss 0.017 score 0.217 lr 1.26894e-06 
12/02/2021 21:36:31 - INFO - volta.train_utils -   [NLVR2]: iter 58760 Ep: 10.89 loss 0.017 score 0.217 lr 1.26688e-06 
12/02/2021 21:36:53 - INFO - volta.train_utils -   [NLVR2]: iter 58840 Ep: 10.90 loss 0.017 score 0.215 lr 1.26482e-06 
12/02/2021 21:37:15 - INFO - volta.train_utils -   [NLVR2]: iter 58920 Ep: 10.92 loss 0.019 score 0.218 lr 1.26276e-06 
12/02/2021 21:37:37 - INFO - volta.train_utils -   [NLVR2]: iter 59000 Ep: 10.93 loss 0.020 score 0.216 lr 1.2607e-06 
12/02/2021 21:37:59 - INFO - volta.train_utils -   [NLVR2]: iter 59080 Ep: 10.94 loss 0.017 score 0.213 lr 1.25865e-06 
12/02/2021 21:38:21 - INFO - volta.train_utils -   [NLVR2]: iter 59160 Ep: 10.96 loss 0.021 score 0.213 lr 1.25659e-06 
12/02/2021 21:38:43 - INFO - volta.train_utils -   [NLVR2]: iter 59240 Ep: 10.97 loss 0.020 score 0.216 lr 1.25453e-06 
12/02/2021 21:39:05 - INFO - volta.train_utils -   [NLVR2]: iter 59320 Ep: 10.99 loss 0.020 score 0.217 lr 1.25247e-06 
12/02/2021 21:40:00 - INFO - volta.train_utils -   Eval task TASK12 on iteration 59356 
12/02/2021 21:40:00 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.831 score 68.621 
Epoch:  55%|█████▌    | 11/20 [4:43:26<3:50:04, 1533.80s/it]12/02/2021 21:40:23 - INFO - volta.train_utils -   [NLVR2]: iter 59436 Ep: 11.01 loss 0.019 score 0.218 lr 1.24995e-06 
12/02/2021 21:40:45 - INFO - volta.train_utils -   [NLVR2]: iter 59516 Ep: 11.03 loss 0.016 score 0.221 lr 1.24743e-06 
12/02/2021 21:41:07 - INFO - volta.train_utils -   [NLVR2]: iter 59596 Ep: 11.04 loss 0.018 score 0.215 lr 1.24537e-06 
12/02/2021 21:41:29 - INFO - volta.train_utils -   [NLVR2]: iter 59676 Ep: 11.06 loss 0.020 score 0.217 lr 1.24331e-06 
12/02/2021 21:41:50 - INFO - volta.train_utils -   [NLVR2]: iter 59756 Ep: 11.07 loss 0.021 score 0.214 lr 1.24125e-06 
12/02/2021 21:42:12 - INFO - volta.train_utils -   [NLVR2]: iter 59836 Ep: 11.08 loss 0.020 score 0.218 lr 1.23919e-06 
12/02/2021 21:42:34 - INFO - volta.train_utils -   [NLVR2]: iter 59916 Ep: 11.10 loss 0.020 score 0.215 lr 1.23714e-06 
12/02/2021 21:42:56 - INFO - volta.train_utils -   [NLVR2]: iter 59996 Ep: 11.11 loss 0.019 score 0.213 lr 1.23508e-06 
12/02/2021 21:43:18 - INFO - volta.train_utils -   [NLVR2]: iter 60076 Ep: 11.13 loss 0.018 score 0.216 lr 1.23302e-06 
12/02/2021 21:43:40 - INFO - volta.train_utils -   [NLVR2]: iter 60156 Ep: 11.14 loss 0.018 score 0.214 lr 1.23096e-06 
12/02/2021 21:44:02 - INFO - volta.train_utils -   [NLVR2]: iter 60236 Ep: 11.16 loss 0.017 score 0.214 lr 1.2289e-06 
12/02/2021 21:44:24 - INFO - volta.train_utils -   [NLVR2]: iter 60316 Ep: 11.17 loss 0.019 score 0.219 lr 1.22684e-06 
12/02/2021 21:44:46 - INFO - volta.train_utils -   [NLVR2]: iter 60396 Ep: 11.19 loss 0.019 score 0.212 lr 1.22478e-06 
12/02/2021 21:45:07 - INFO - volta.train_utils -   [NLVR2]: iter 60476 Ep: 11.20 loss 0.018 score 0.216 lr 1.22273e-06 
12/02/2021 21:45:29 - INFO - volta.train_utils -   [NLVR2]: iter 60556 Ep: 11.22 loss 0.016 score 0.216 lr 1.22067e-06 
12/02/2021 21:45:51 - INFO - volta.train_utils -   [NLVR2]: iter 60636 Ep: 11.23 loss 0.019 score 0.219 lr 1.21861e-06 
12/02/2021 21:46:13 - INFO - volta.train_utils -   [NLVR2]: iter 60716 Ep: 11.25 loss 0.021 score 0.212 lr 1.21655e-06 
12/02/2021 21:46:35 - INFO - volta.train_utils -   [NLVR2]: iter 60796 Ep: 11.26 loss 0.023 score 0.212 lr 1.21449e-06 
12/02/2021 21:46:57 - INFO - volta.train_utils -   [NLVR2]: iter 60876 Ep: 11.28 loss 0.022 score 0.214 lr 1.21243e-06 
12/02/2021 21:47:19 - INFO - volta.train_utils -   [NLVR2]: iter 60956 Ep: 11.29 loss 0.018 score 0.212 lr 1.21038e-06 
12/02/2021 21:47:41 - INFO - volta.train_utils -   [NLVR2]: iter 61036 Ep: 11.31 loss 0.016 score 0.217 lr 1.20832e-06 
12/02/2021 21:48:03 - INFO - volta.train_utils -   [NLVR2]: iter 61116 Ep: 11.32 loss 0.015 score 0.214 lr 1.20626e-06 
12/02/2021 21:48:25 - INFO - volta.train_utils -   [NLVR2]: iter 61196 Ep: 11.34 loss 0.016 score 0.218 lr 1.2042e-06 
12/02/2021 21:48:47 - INFO - volta.train_utils -   [NLVR2]: iter 61276 Ep: 11.35 loss 0.016 score 0.216 lr 1.20214e-06 
12/02/2021 21:49:09 - INFO - volta.train_utils -   [NLVR2]: iter 61356 Ep: 11.37 loss 0.019 score 0.214 lr 1.20008e-06 
12/02/2021 21:49:31 - INFO - volta.train_utils -   [NLVR2]: iter 61436 Ep: 11.38 loss 0.019 score 0.214 lr 1.19803e-06 
12/02/2021 21:49:52 - INFO - volta.train_utils -   [NLVR2]: iter 61516 Ep: 11.40 loss 0.019 score 0.218 lr 1.19597e-06 
12/02/2021 21:50:14 - INFO - volta.train_utils -   [NLVR2]: iter 61596 Ep: 11.41 loss 0.024 score 0.211 lr 1.19391e-06 
12/02/2021 21:50:36 - INFO - volta.train_utils -   [NLVR2]: iter 61676 Ep: 11.43 loss 0.019 score 0.216 lr 1.19185e-06 
12/02/2021 21:50:58 - INFO - volta.train_utils -   [NLVR2]: iter 61756 Ep: 11.44 loss 0.016 score 0.216 lr 1.18979e-06 
12/02/2021 21:51:20 - INFO - volta.train_utils -   [NLVR2]: iter 61836 Ep: 11.46 loss 0.018 score 0.218 lr 1.18773e-06 
12/02/2021 21:51:42 - INFO - volta.train_utils -   [NLVR2]: iter 61916 Ep: 11.47 loss 0.019 score 0.213 lr 1.18568e-06 
12/02/2021 21:52:04 - INFO - volta.train_utils -   [NLVR2]: iter 61996 Ep: 11.48 loss 0.017 score 0.212 lr 1.18362e-06 
12/02/2021 21:52:26 - INFO - volta.train_utils -   [NLVR2]: iter 62076 Ep: 11.50 loss 0.017 score 0.219 lr 1.18156e-06 
12/02/2021 21:52:48 - INFO - volta.train_utils -   [NLVR2]: iter 62156 Ep: 11.51 loss 0.017 score 0.215 lr 1.1795e-06 
12/02/2021 21:53:10 - INFO - volta.train_utils -   [NLVR2]: iter 62236 Ep: 11.53 loss 0.020 score 0.219 lr 1.17744e-06 
12/02/2021 21:53:32 - INFO - volta.train_utils -   [NLVR2]: iter 62316 Ep: 11.54 loss 0.018 score 0.218 lr 1.17538e-06 
12/02/2021 21:53:54 - INFO - volta.train_utils -   [NLVR2]: iter 62396 Ep: 11.56 loss 0.017 score 0.215 lr 1.17333e-06 
12/02/2021 21:54:16 - INFO - volta.train_utils -   [NLVR2]: iter 62476 Ep: 11.57 loss 0.016 score 0.216 lr 1.17127e-06 
12/02/2021 21:54:38 - INFO - volta.train_utils -   [NLVR2]: iter 62556 Ep: 11.59 loss 0.018 score 0.218 lr 1.16921e-06 
12/02/2021 21:55:00 - INFO - volta.train_utils -   [NLVR2]: iter 62636 Ep: 11.60 loss 0.018 score 0.216 lr 1.16715e-06 
12/02/2021 21:55:22 - INFO - volta.train_utils -   [NLVR2]: iter 62716 Ep: 11.62 loss 0.019 score 0.218 lr 1.16509e-06 
12/02/2021 21:55:44 - INFO - volta.train_utils -   [NLVR2]: iter 62796 Ep: 11.63 loss 0.017 score 0.215 lr 1.16303e-06 
12/02/2021 21:56:05 - INFO - volta.train_utils -   [NLVR2]: iter 62876 Ep: 11.65 loss 0.019 score 0.220 lr 1.16098e-06 
12/02/2021 21:56:27 - INFO - volta.train_utils -   [NLVR2]: iter 62956 Ep: 11.66 loss 0.016 score 0.216 lr 1.15892e-06 
12/02/2021 21:56:49 - INFO - volta.train_utils -   [NLVR2]: iter 63036 Ep: 11.68 loss 0.019 score 0.214 lr 1.15686e-06 
12/02/2021 21:57:11 - INFO - volta.train_utils -   [NLVR2]: iter 63116 Ep: 11.69 loss 0.019 score 0.215 lr 1.1548e-06 
12/02/2021 21:57:33 - INFO - volta.train_utils -   [NLVR2]: iter 63196 Ep: 11.71 loss 0.020 score 0.211 lr 1.15274e-06 
12/02/2021 21:57:55 - INFO - volta.train_utils -   [NLVR2]: iter 63276 Ep: 11.72 loss 0.018 score 0.216 lr 1.15068e-06 
12/02/2021 21:58:17 - INFO - volta.train_utils -   [NLVR2]: iter 63356 Ep: 11.74 loss 0.020 score 0.212 lr 1.14863e-06 
12/02/2021 21:58:39 - INFO - volta.train_utils -   [NLVR2]: iter 63436 Ep: 11.75 loss 0.020 score 0.214 lr 1.14657e-06 
12/02/2021 21:59:01 - INFO - volta.train_utils -   [NLVR2]: iter 63516 Ep: 11.77 loss 0.016 score 0.216 lr 1.14451e-06 
12/02/2021 21:59:23 - INFO - volta.train_utils -   [NLVR2]: iter 63596 Ep: 11.78 loss 0.016 score 0.216 lr 1.14245e-06 
12/02/2021 21:59:44 - INFO - volta.train_utils -   [NLVR2]: iter 63676 Ep: 11.80 loss 0.017 score 0.220 lr 1.14039e-06 
12/02/2021 22:00:06 - INFO - volta.train_utils -   [NLVR2]: iter 63756 Ep: 11.81 loss 0.017 score 0.217 lr 1.13833e-06 
12/02/2021 22:00:28 - INFO - volta.train_utils -   [NLVR2]: iter 63836 Ep: 11.83 loss 0.017 score 0.220 lr 1.13627e-06 
12/02/2021 22:00:50 - INFO - volta.train_utils -   [NLVR2]: iter 63916 Ep: 11.84 loss 0.015 score 0.217 lr 1.13422e-06 
12/02/2021 22:01:12 - INFO - volta.train_utils -   [NLVR2]: iter 63996 Ep: 11.86 loss 0.016 score 0.219 lr 1.13216e-06 
12/02/2021 22:01:34 - INFO - volta.train_utils -   [NLVR2]: iter 64076 Ep: 11.87 loss 0.017 score 0.215 lr 1.1301e-06 
12/02/2021 22:01:56 - INFO - volta.train_utils -   [NLVR2]: iter 64156 Ep: 11.89 loss 0.015 score 0.218 lr 1.12804e-06 
12/02/2021 22:02:18 - INFO - volta.train_utils -   [NLVR2]: iter 64236 Ep: 11.90 loss 0.016 score 0.219 lr 1.12598e-06 
12/02/2021 22:02:39 - INFO - volta.train_utils -   [NLVR2]: iter 64316 Ep: 11.91 loss 0.018 score 0.218 lr 1.12392e-06 
12/02/2021 22:03:01 - INFO - volta.train_utils -   [NLVR2]: iter 64396 Ep: 11.93 loss 0.020 score 0.218 lr 1.12187e-06 
12/02/2021 22:03:23 - INFO - volta.train_utils -   [NLVR2]: iter 64476 Ep: 11.94 loss 0.018 score 0.218 lr 1.11981e-06 
12/02/2021 22:03:45 - INFO - volta.train_utils -   [NLVR2]: iter 64556 Ep: 11.96 loss 0.015 score 0.219 lr 1.11775e-06 
12/02/2021 22:04:07 - INFO - volta.train_utils -   [NLVR2]: iter 64636 Ep: 11.97 loss 0.018 score 0.222 lr 1.11569e-06 
12/02/2021 22:04:29 - INFO - volta.train_utils -   [NLVR2]: iter 64716 Ep: 11.99 loss 0.014 score 0.221 lr 1.11363e-06 
12/02/2021 22:05:25 - INFO - volta.train_utils -   Eval task TASK12 on iteration 64752 
12/02/2021 22:05:25 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.847 score 69.510 
12/02/2021 22:05:25 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  60%|██████    | 12/20 [5:09:23<3:25:27, 1540.88s/it]12/02/2021 22:06:20 - INFO - volta.train_utils -   [NLVR2]: iter 64832 Ep: 12.01 loss 0.015 score 0.223 lr 1.11111e-06 
12/02/2021 22:06:42 - INFO - volta.train_utils -   [NLVR2]: iter 64912 Ep: 12.03 loss 0.019 score 0.217 lr 1.10859e-06 
12/02/2021 22:07:04 - INFO - volta.train_utils -   [NLVR2]: iter 64992 Ep: 12.04 loss 0.018 score 0.215 lr 1.10653e-06 
12/02/2021 22:07:26 - INFO - volta.train_utils -   [NLVR2]: iter 65072 Ep: 12.05 loss 0.016 score 0.217 lr 1.10447e-06 
12/02/2021 22:07:48 - INFO - volta.train_utils -   [NLVR2]: iter 65152 Ep: 12.07 loss 0.017 score 0.222 lr 1.10241e-06 
12/02/2021 22:08:10 - INFO - volta.train_utils -   [NLVR2]: iter 65232 Ep: 12.08 loss 0.020 score 0.218 lr 1.10036e-06 
12/02/2021 22:08:32 - INFO - volta.train_utils -   [NLVR2]: iter 65312 Ep: 12.10 loss 0.017 score 0.217 lr 1.0983e-06 
12/02/2021 22:08:54 - INFO - volta.train_utils -   [NLVR2]: iter 65392 Ep: 12.11 loss 0.017 score 0.217 lr 1.09624e-06 
12/02/2021 22:09:16 - INFO - volta.train_utils -   [NLVR2]: iter 65472 Ep: 12.13 loss 0.017 score 0.217 lr 1.09418e-06 
12/02/2021 22:09:37 - INFO - volta.train_utils -   [NLVR2]: iter 65552 Ep: 12.14 loss 0.017 score 0.219 lr 1.09212e-06 
12/02/2021 22:09:59 - INFO - volta.train_utils -   [NLVR2]: iter 65632 Ep: 12.16 loss 0.017 score 0.219 lr 1.09006e-06 
12/02/2021 22:10:21 - INFO - volta.train_utils -   [NLVR2]: iter 65712 Ep: 12.17 loss 0.018 score 0.217 lr 1.08801e-06 
12/02/2021 22:10:43 - INFO - volta.train_utils -   [NLVR2]: iter 65792 Ep: 12.19 loss 0.015 score 0.220 lr 1.08595e-06 
12/02/2021 22:11:05 - INFO - volta.train_utils -   [NLVR2]: iter 65872 Ep: 12.20 loss 0.018 score 0.217 lr 1.08389e-06 
12/02/2021 22:11:27 - INFO - volta.train_utils -   [NLVR2]: iter 65952 Ep: 12.22 loss 0.018 score 0.217 lr 1.08183e-06 
12/02/2021 22:11:48 - INFO - volta.train_utils -   [NLVR2]: iter 66032 Ep: 12.23 loss 0.019 score 0.217 lr 1.07977e-06 
12/02/2021 22:12:10 - INFO - volta.train_utils -   [NLVR2]: iter 66112 Ep: 12.25 loss 0.018 score 0.219 lr 1.07771e-06 
12/02/2021 22:12:33 - INFO - volta.train_utils -   [NLVR2]: iter 66192 Ep: 12.26 loss 0.017 score 0.221 lr 1.07566e-06 
12/02/2021 22:12:54 - INFO - volta.train_utils -   [NLVR2]: iter 66272 Ep: 12.28 loss 0.018 score 0.219 lr 1.0736e-06 
12/02/2021 22:13:16 - INFO - volta.train_utils -   [NLVR2]: iter 66352 Ep: 12.29 loss 0.019 score 0.215 lr 1.07154e-06 
12/02/2021 22:13:38 - INFO - volta.train_utils -   [NLVR2]: iter 66432 Ep: 12.31 loss 0.017 score 0.217 lr 1.06948e-06 
12/02/2021 22:14:00 - INFO - volta.train_utils -   [NLVR2]: iter 66512 Ep: 12.32 loss 0.016 score 0.221 lr 1.06742e-06 
12/02/2021 22:14:22 - INFO - volta.train_utils -   [NLVR2]: iter 66592 Ep: 12.34 loss 0.015 score 0.221 lr 1.06536e-06 
12/02/2021 22:14:44 - INFO - volta.train_utils -   [NLVR2]: iter 66672 Ep: 12.35 loss 0.015 score 0.217 lr 1.06331e-06 
12/02/2021 22:15:06 - INFO - volta.train_utils -   [NLVR2]: iter 66752 Ep: 12.37 loss 0.021 score 0.216 lr 1.06125e-06 
12/02/2021 22:15:28 - INFO - volta.train_utils -   [NLVR2]: iter 66832 Ep: 12.38 loss 0.020 score 0.219 lr 1.05919e-06 
12/02/2021 22:15:50 - INFO - volta.train_utils -   [NLVR2]: iter 66912 Ep: 12.40 loss 0.018 score 0.220 lr 1.05713e-06 
12/02/2021 22:16:12 - INFO - volta.train_utils -   [NLVR2]: iter 66992 Ep: 12.41 loss 0.015 score 0.218 lr 1.05507e-06 
12/02/2021 22:16:33 - INFO - volta.train_utils -   [NLVR2]: iter 67072 Ep: 12.43 loss 0.019 score 0.219 lr 1.05301e-06 
12/02/2021 22:16:55 - INFO - volta.train_utils -   [NLVR2]: iter 67152 Ep: 12.44 loss 0.017 score 0.216 lr 1.05096e-06 
12/02/2021 22:17:17 - INFO - volta.train_utils -   [NLVR2]: iter 67232 Ep: 12.45 loss 0.017 score 0.217 lr 1.0489e-06 
12/02/2021 22:17:39 - INFO - volta.train_utils -   [NLVR2]: iter 67312 Ep: 12.47 loss 0.016 score 0.218 lr 1.04684e-06 
12/02/2021 22:18:01 - INFO - volta.train_utils -   [NLVR2]: iter 67392 Ep: 12.48 loss 0.016 score 0.221 lr 1.04478e-06 
12/02/2021 22:18:23 - INFO - volta.train_utils -   [NLVR2]: iter 67472 Ep: 12.50 loss 0.015 score 0.219 lr 1.04272e-06 
12/02/2021 22:18:45 - INFO - volta.train_utils -   [NLVR2]: iter 67552 Ep: 12.51 loss 0.013 score 0.218 lr 1.04066e-06 
12/02/2021 22:19:07 - INFO - volta.train_utils -   [NLVR2]: iter 67632 Ep: 12.53 loss 0.016 score 0.221 lr 1.0386e-06 
12/02/2021 22:19:29 - INFO - volta.train_utils -   [NLVR2]: iter 67712 Ep: 12.54 loss 0.019 score 0.220 lr 1.03655e-06 
12/02/2021 22:19:51 - INFO - volta.train_utils -   [NLVR2]: iter 67792 Ep: 12.56 loss 0.014 score 0.222 lr 1.03449e-06 
12/02/2021 22:20:13 - INFO - volta.train_utils -   [NLVR2]: iter 67872 Ep: 12.57 loss 0.019 score 0.219 lr 1.03243e-06 
12/02/2021 22:20:35 - INFO - volta.train_utils -   [NLVR2]: iter 67952 Ep: 12.59 loss 0.017 score 0.222 lr 1.03037e-06 
12/02/2021 22:20:57 - INFO - volta.train_utils -   [NLVR2]: iter 68032 Ep: 12.60 loss 0.018 score 0.221 lr 1.02831e-06 
12/02/2021 22:21:18 - INFO - volta.train_utils -   [NLVR2]: iter 68112 Ep: 12.62 loss 0.018 score 0.217 lr 1.02625e-06 
12/02/2021 22:21:40 - INFO - volta.train_utils -   [NLVR2]: iter 68192 Ep: 12.63 loss 0.015 score 0.220 lr 1.0242e-06 
12/02/2021 22:22:02 - INFO - volta.train_utils -   [NLVR2]: iter 68272 Ep: 12.65 loss 0.018 score 0.219 lr 1.02214e-06 
12/02/2021 22:22:24 - INFO - volta.train_utils -   [NLVR2]: iter 68352 Ep: 12.66 loss 0.016 score 0.222 lr 1.02008e-06 
12/02/2021 22:22:46 - INFO - volta.train_utils -   [NLVR2]: iter 68432 Ep: 12.68 loss 0.016 score 0.221 lr 1.01802e-06 
12/02/2021 22:23:08 - INFO - volta.train_utils -   [NLVR2]: iter 68512 Ep: 12.69 loss 0.019 score 0.218 lr 1.01596e-06 
12/02/2021 22:23:30 - INFO - volta.train_utils -   [NLVR2]: iter 68592 Ep: 12.71 loss 0.017 score 0.217 lr 1.0139e-06 
12/02/2021 22:23:52 - INFO - volta.train_utils -   [NLVR2]: iter 68672 Ep: 12.72 loss 0.014 score 0.216 lr 1.01185e-06 
12/02/2021 22:24:14 - INFO - volta.train_utils -   [NLVR2]: iter 68752 Ep: 12.74 loss 0.019 score 0.219 lr 1.00979e-06 
12/02/2021 22:24:35 - INFO - volta.train_utils -   [NLVR2]: iter 68832 Ep: 12.75 loss 0.016 score 0.217 lr 1.00773e-06 
12/02/2021 22:24:57 - INFO - volta.train_utils -   [NLVR2]: iter 68912 Ep: 12.77 loss 0.018 score 0.217 lr 1.00567e-06 
12/02/2021 22:25:19 - INFO - volta.train_utils -   [NLVR2]: iter 68992 Ep: 12.78 loss 0.018 score 0.222 lr 1.00361e-06 
12/02/2021 22:25:41 - INFO - volta.train_utils -   [NLVR2]: iter 69072 Ep: 12.80 loss 0.015 score 0.224 lr 1.00155e-06 
12/02/2021 22:26:03 - INFO - volta.train_utils -   [NLVR2]: iter 69152 Ep: 12.81 loss 0.018 score 0.218 lr 9.99496e-07 
12/02/2021 22:26:25 - INFO - volta.train_utils -   [NLVR2]: iter 69232 Ep: 12.83 loss 0.016 score 0.216 lr 9.97437e-07 
12/02/2021 22:26:47 - INFO - volta.train_utils -   [NLVR2]: iter 69312 Ep: 12.84 loss 0.014 score 0.223 lr 9.95379e-07 
12/02/2021 22:27:09 - INFO - volta.train_utils -   [NLVR2]: iter 69392 Ep: 12.86 loss 0.017 score 0.222 lr 9.93321e-07 
12/02/2021 22:27:31 - INFO - volta.train_utils -   [NLVR2]: iter 69472 Ep: 12.87 loss 0.019 score 0.217 lr 9.91262e-07 
12/02/2021 22:27:53 - INFO - volta.train_utils -   [NLVR2]: iter 69552 Ep: 12.88 loss 0.013 score 0.221 lr 9.89204e-07 
12/02/2021 22:28:15 - INFO - volta.train_utils -   [NLVR2]: iter 69632 Ep: 12.90 loss 0.015 score 0.221 lr 9.87145e-07 
12/02/2021 22:28:37 - INFO - volta.train_utils -   [NLVR2]: iter 69712 Ep: 12.91 loss 0.015 score 0.222 lr 9.85087e-07 
12/02/2021 22:28:58 - INFO - volta.train_utils -   [NLVR2]: iter 69792 Ep: 12.93 loss 0.015 score 0.223 lr 9.83029e-07 
12/02/2021 22:29:20 - INFO - volta.train_utils -   [NLVR2]: iter 69872 Ep: 12.94 loss 0.016 score 0.220 lr 9.8097e-07 
12/02/2021 22:29:42 - INFO - volta.train_utils -   [NLVR2]: iter 69952 Ep: 12.96 loss 0.015 score 0.224 lr 9.78912e-07 
12/02/2021 22:30:04 - INFO - volta.train_utils -   [NLVR2]: iter 70032 Ep: 12.97 loss 0.019 score 0.221 lr 9.76854e-07 
12/02/2021 22:30:26 - INFO - volta.train_utils -   [NLVR2]: iter 70112 Ep: 12.99 loss 0.014 score 0.226 lr 9.74795e-07 
12/02/2021 22:31:22 - INFO - volta.train_utils -   Eval task TASK12 on iteration 70148 
12/02/2021 22:31:22 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.937 score 69.065 
Epoch:  65%|██████▌   | 13/20 [5:34:47<2:59:10, 1535.74s/it]12/02/2021 22:31:44 - INFO - volta.train_utils -   [NLVR2]: iter 70228 Ep: 13.01 loss 0.018 score 0.225 lr 9.72274e-07 
12/02/2021 22:32:06 - INFO - volta.train_utils -   [NLVR2]: iter 70308 Ep: 13.02 loss 0.015 score 0.217 lr 9.69752e-07 
12/02/2021 22:32:27 - INFO - volta.train_utils -   [NLVR2]: iter 70388 Ep: 13.04 loss 0.019 score 0.218 lr 9.67694e-07 
12/02/2021 22:32:49 - INFO - volta.train_utils -   [NLVR2]: iter 70468 Ep: 13.05 loss 0.016 score 0.225 lr 9.65635e-07 
12/02/2021 22:33:11 - INFO - volta.train_utils -   [NLVR2]: iter 70548 Ep: 13.07 loss 0.017 score 0.223 lr 9.63577e-07 
12/02/2021 22:33:33 - INFO - volta.train_utils -   [NLVR2]: iter 70628 Ep: 13.08 loss 0.016 score 0.221 lr 9.61519e-07 
12/02/2021 22:33:55 - INFO - volta.train_utils -   [NLVR2]: iter 70708 Ep: 13.10 loss 0.015 score 0.222 lr 9.5946e-07 
12/02/2021 22:34:17 - INFO - volta.train_utils -   [NLVR2]: iter 70788 Ep: 13.11 loss 0.020 score 0.221 lr 9.57402e-07 
12/02/2021 22:34:39 - INFO - volta.train_utils -   [NLVR2]: iter 70868 Ep: 13.13 loss 0.015 score 0.220 lr 9.55344e-07 
12/02/2021 22:35:01 - INFO - volta.train_utils -   [NLVR2]: iter 70948 Ep: 13.14 loss 0.014 score 0.221 lr 9.53285e-07 
12/02/2021 22:35:22 - INFO - volta.train_utils -   [NLVR2]: iter 71028 Ep: 13.16 loss 0.014 score 0.222 lr 9.51227e-07 
12/02/2021 22:35:44 - INFO - volta.train_utils -   [NLVR2]: iter 71108 Ep: 13.17 loss 0.017 score 0.217 lr 9.49168e-07 
12/02/2021 22:36:06 - INFO - volta.train_utils -   [NLVR2]: iter 71188 Ep: 13.19 loss 0.017 score 0.223 lr 9.4711e-07 
12/02/2021 22:36:28 - INFO - volta.train_utils -   [NLVR2]: iter 71268 Ep: 13.20 loss 0.020 score 0.219 lr 9.45052e-07 
12/02/2021 22:36:50 - INFO - volta.train_utils -   [NLVR2]: iter 71348 Ep: 13.22 loss 0.020 score 0.216 lr 9.42993e-07 
12/02/2021 22:37:12 - INFO - volta.train_utils -   [NLVR2]: iter 71428 Ep: 13.23 loss 0.015 score 0.225 lr 9.40935e-07 
12/02/2021 22:37:34 - INFO - volta.train_utils -   [NLVR2]: iter 71508 Ep: 13.25 loss 0.017 score 0.222 lr 9.38877e-07 
12/02/2021 22:37:56 - INFO - volta.train_utils -   [NLVR2]: iter 71588 Ep: 13.26 loss 0.019 score 0.222 lr 9.36818e-07 
12/02/2021 22:38:18 - INFO - volta.train_utils -   [NLVR2]: iter 71668 Ep: 13.28 loss 0.015 score 0.221 lr 9.3476e-07 
12/02/2021 22:38:39 - INFO - volta.train_utils -   [NLVR2]: iter 71748 Ep: 13.29 loss 0.015 score 0.222 lr 9.32701e-07 
12/02/2021 22:39:01 - INFO - volta.train_utils -   [NLVR2]: iter 71828 Ep: 13.31 loss 0.016 score 0.220 lr 9.30643e-07 
12/02/2021 22:39:23 - INFO - volta.train_utils -   [NLVR2]: iter 71908 Ep: 13.32 loss 0.017 score 0.220 lr 9.28585e-07 
12/02/2021 22:39:46 - INFO - volta.train_utils -   [NLVR2]: iter 71988 Ep: 13.34 loss 0.018 score 0.215 lr 9.26526e-07 
12/02/2021 22:40:08 - INFO - volta.train_utils -   [NLVR2]: iter 72068 Ep: 13.35 loss 0.018 score 0.223 lr 9.24468e-07 
12/02/2021 22:40:29 - INFO - volta.train_utils -   [NLVR2]: iter 72148 Ep: 13.37 loss 0.017 score 0.219 lr 9.2241e-07 
12/02/2021 22:40:51 - INFO - volta.train_utils -   [NLVR2]: iter 72228 Ep: 13.38 loss 0.019 score 0.219 lr 9.20351e-07 
12/02/2021 22:41:13 - INFO - volta.train_utils -   [NLVR2]: iter 72308 Ep: 13.40 loss 0.017 score 0.220 lr 9.18293e-07 
12/02/2021 22:41:35 - INFO - volta.train_utils -   [NLVR2]: iter 72388 Ep: 13.41 loss 0.017 score 0.219 lr 9.16234e-07 
12/02/2021 22:41:57 - INFO - volta.train_utils -   [NLVR2]: iter 72468 Ep: 13.42 loss 0.015 score 0.224 lr 9.14176e-07 
12/02/2021 22:42:19 - INFO - volta.train_utils -   [NLVR2]: iter 72548 Ep: 13.44 loss 0.015 score 0.222 lr 9.12118e-07 
12/02/2021 22:42:41 - INFO - volta.train_utils -   [NLVR2]: iter 72628 Ep: 13.45 loss 0.018 score 0.219 lr 9.10059e-07 
12/02/2021 22:43:03 - INFO - volta.train_utils -   [NLVR2]: iter 72708 Ep: 13.47 loss 0.014 score 0.224 lr 9.08001e-07 
12/02/2021 22:43:24 - INFO - volta.train_utils -   [NLVR2]: iter 72788 Ep: 13.48 loss 0.017 score 0.219 lr 9.05943e-07 
12/02/2021 22:43:47 - INFO - volta.train_utils -   [NLVR2]: iter 72868 Ep: 13.50 loss 0.016 score 0.221 lr 9.03884e-07 
12/02/2021 22:44:08 - INFO - volta.train_utils -   [NLVR2]: iter 72948 Ep: 13.51 loss 0.015 score 0.222 lr 9.01826e-07 
12/02/2021 22:44:30 - INFO - volta.train_utils -   [NLVR2]: iter 73028 Ep: 13.53 loss 0.011 score 0.223 lr 8.99767e-07 
12/02/2021 22:44:52 - INFO - volta.train_utils -   [NLVR2]: iter 73108 Ep: 13.54 loss 0.016 score 0.220 lr 8.97709e-07 
12/02/2021 22:45:14 - INFO - volta.train_utils -   [NLVR2]: iter 73188 Ep: 13.56 loss 0.015 score 0.219 lr 8.95651e-07 
12/02/2021 22:45:36 - INFO - volta.train_utils -   [NLVR2]: iter 73268 Ep: 13.57 loss 0.014 score 0.221 lr 8.93592e-07 
12/02/2021 22:45:58 - INFO - volta.train_utils -   [NLVR2]: iter 73348 Ep: 13.59 loss 0.015 score 0.224 lr 8.91534e-07 
12/02/2021 22:46:20 - INFO - volta.train_utils -   [NLVR2]: iter 73428 Ep: 13.60 loss 0.016 score 0.222 lr 8.89476e-07 
12/02/2021 22:46:42 - INFO - volta.train_utils -   [NLVR2]: iter 73508 Ep: 13.62 loss 0.019 score 0.219 lr 8.87417e-07 
12/02/2021 22:47:04 - INFO - volta.train_utils -   [NLVR2]: iter 73588 Ep: 13.63 loss 0.017 score 0.219 lr 8.85359e-07 
12/02/2021 22:47:26 - INFO - volta.train_utils -   [NLVR2]: iter 73668 Ep: 13.65 loss 0.016 score 0.223 lr 8.833e-07 
12/02/2021 22:47:48 - INFO - volta.train_utils -   [NLVR2]: iter 73748 Ep: 13.66 loss 0.018 score 0.219 lr 8.81242e-07 
12/02/2021 22:48:10 - INFO - volta.train_utils -   [NLVR2]: iter 73828 Ep: 13.68 loss 0.016 score 0.219 lr 8.79184e-07 
12/02/2021 22:48:32 - INFO - volta.train_utils -   [NLVR2]: iter 73908 Ep: 13.69 loss 0.015 score 0.222 lr 8.77125e-07 
12/02/2021 22:48:53 - INFO - volta.train_utils -   [NLVR2]: iter 73988 Ep: 13.71 loss 0.017 score 0.217 lr 8.75067e-07 
12/02/2021 22:49:15 - INFO - volta.train_utils -   [NLVR2]: iter 74068 Ep: 13.72 loss 0.016 score 0.225 lr 8.73009e-07 
12/02/2021 22:49:37 - INFO - volta.train_utils -   [NLVR2]: iter 74148 Ep: 13.74 loss 0.017 score 0.221 lr 8.7095e-07 
12/02/2021 22:49:59 - INFO - volta.train_utils -   [NLVR2]: iter 74228 Ep: 13.75 loss 0.016 score 0.222 lr 8.68892e-07 
12/02/2021 22:50:21 - INFO - volta.train_utils -   [NLVR2]: iter 74308 Ep: 13.77 loss 0.015 score 0.224 lr 8.66833e-07 
12/02/2021 22:50:43 - INFO - volta.train_utils -   [NLVR2]: iter 74388 Ep: 13.78 loss 0.016 score 0.222 lr 8.64775e-07 
12/02/2021 22:51:05 - INFO - volta.train_utils -   [NLVR2]: iter 74468 Ep: 13.80 loss 0.018 score 0.221 lr 8.62717e-07 
12/02/2021 22:51:27 - INFO - volta.train_utils -   [NLVR2]: iter 74548 Ep: 13.81 loss 0.016 score 0.224 lr 8.60658e-07 
12/02/2021 22:51:49 - INFO - volta.train_utils -   [NLVR2]: iter 74628 Ep: 13.83 loss 0.015 score 0.226 lr 8.586e-07 
12/02/2021 22:52:11 - INFO - volta.train_utils -   [NLVR2]: iter 74708 Ep: 13.84 loss 0.016 score 0.221 lr 8.56542e-07 
12/02/2021 22:52:33 - INFO - volta.train_utils -   [NLVR2]: iter 74788 Ep: 13.85 loss 0.014 score 0.223 lr 8.54483e-07 
12/02/2021 22:52:55 - INFO - volta.train_utils -   [NLVR2]: iter 74868 Ep: 13.87 loss 0.019 score 0.219 lr 8.52425e-07 
12/02/2021 22:53:17 - INFO - volta.train_utils -   [NLVR2]: iter 74948 Ep: 13.88 loss 0.015 score 0.220 lr 8.50366e-07 
12/02/2021 22:53:39 - INFO - volta.train_utils -   [NLVR2]: iter 75028 Ep: 13.90 loss 0.013 score 0.227 lr 8.48308e-07 
12/02/2021 22:54:01 - INFO - volta.train_utils -   [NLVR2]: iter 75108 Ep: 13.91 loss 0.015 score 0.225 lr 8.4625e-07 
12/02/2021 22:54:23 - INFO - volta.train_utils -   [NLVR2]: iter 75188 Ep: 13.93 loss 0.012 score 0.225 lr 8.44191e-07 
12/02/2021 22:54:45 - INFO - volta.train_utils -   [NLVR2]: iter 75268 Ep: 13.94 loss 0.016 score 0.223 lr 8.42133e-07 
12/02/2021 22:55:06 - INFO - volta.train_utils -   [NLVR2]: iter 75348 Ep: 13.96 loss 0.014 score 0.224 lr 8.40075e-07 
12/02/2021 22:55:28 - INFO - volta.train_utils -   [NLVR2]: iter 75428 Ep: 13.97 loss 0.013 score 0.222 lr 8.38016e-07 
12/02/2021 22:55:50 - INFO - volta.train_utils -   [NLVR2]: iter 75508 Ep: 13.99 loss 0.015 score 0.223 lr 8.35958e-07 
12/02/2021 22:56:46 - INFO - volta.train_utils -   Eval task TASK12 on iteration 75544 
12/02/2021 22:56:46 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.924 score 68.893 
Epoch:  70%|███████   | 14/20 [6:00:12<2:33:14, 1532.43s/it]12/02/2021 22:57:09 - INFO - volta.train_utils -   [NLVR2]: iter 75624 Ep: 14.01 loss 0.013 score 0.227 lr 8.33436e-07 
12/02/2021 22:57:31 - INFO - volta.train_utils -   [NLVR2]: iter 75704 Ep: 14.02 loss 0.014 score 0.225 lr 8.30915e-07 
12/02/2021 22:57:53 - INFO - volta.train_utils -   [NLVR2]: iter 75784 Ep: 14.04 loss 0.019 score 0.223 lr 8.28856e-07 
12/02/2021 22:58:14 - INFO - volta.train_utils -   [NLVR2]: iter 75864 Ep: 14.05 loss 0.015 score 0.222 lr 8.26798e-07 
12/02/2021 22:58:36 - INFO - volta.train_utils -   [NLVR2]: iter 75944 Ep: 14.07 loss 0.014 score 0.225 lr 8.2474e-07 
12/02/2021 22:58:58 - INFO - volta.train_utils -   [NLVR2]: iter 76024 Ep: 14.08 loss 0.014 score 0.222 lr 8.22681e-07 
12/02/2021 22:59:20 - INFO - volta.train_utils -   [NLVR2]: iter 76104 Ep: 14.10 loss 0.014 score 0.223 lr 8.20623e-07 
12/02/2021 22:59:42 - INFO - volta.train_utils -   [NLVR2]: iter 76184 Ep: 14.11 loss 0.018 score 0.223 lr 8.18564e-07 
12/02/2021 23:00:04 - INFO - volta.train_utils -   [NLVR2]: iter 76264 Ep: 14.13 loss 0.015 score 0.223 lr 8.16506e-07 
12/02/2021 23:00:26 - INFO - volta.train_utils -   [NLVR2]: iter 76344 Ep: 14.14 loss 0.016 score 0.226 lr 8.14448e-07 
12/02/2021 23:00:48 - INFO - volta.train_utils -   [NLVR2]: iter 76424 Ep: 14.16 loss 0.013 score 0.223 lr 8.12389e-07 
12/02/2021 23:01:10 - INFO - volta.train_utils -   [NLVR2]: iter 76504 Ep: 14.17 loss 0.014 score 0.222 lr 8.10331e-07 
12/02/2021 23:01:32 - INFO - volta.train_utils -   [NLVR2]: iter 76584 Ep: 14.19 loss 0.014 score 0.224 lr 8.08273e-07 
12/02/2021 23:01:54 - INFO - volta.train_utils -   [NLVR2]: iter 76664 Ep: 14.20 loss 0.012 score 0.225 lr 8.06214e-07 
12/02/2021 23:02:16 - INFO - volta.train_utils -   [NLVR2]: iter 76744 Ep: 14.22 loss 0.013 score 0.224 lr 8.04156e-07 
12/02/2021 23:02:38 - INFO - volta.train_utils -   [NLVR2]: iter 76824 Ep: 14.23 loss 0.013 score 0.222 lr 8.02097e-07 
12/02/2021 23:03:00 - INFO - volta.train_utils -   [NLVR2]: iter 76904 Ep: 14.25 loss 0.017 score 0.220 lr 8.00039e-07 
12/02/2021 23:03:22 - INFO - volta.train_utils -   [NLVR2]: iter 76984 Ep: 14.26 loss 0.017 score 0.223 lr 7.97981e-07 
12/02/2021 23:03:44 - INFO - volta.train_utils -   [NLVR2]: iter 77064 Ep: 14.28 loss 0.017 score 0.223 lr 7.95922e-07 
12/02/2021 23:04:06 - INFO - volta.train_utils -   [NLVR2]: iter 77144 Ep: 14.29 loss 0.018 score 0.220 lr 7.93864e-07 
12/02/2021 23:04:28 - INFO - volta.train_utils -   [NLVR2]: iter 77224 Ep: 14.31 loss 0.015 score 0.223 lr 7.91806e-07 
12/02/2021 23:04:50 - INFO - volta.train_utils -   [NLVR2]: iter 77304 Ep: 14.32 loss 0.011 score 0.225 lr 7.89747e-07 
12/02/2021 23:05:12 - INFO - volta.train_utils -   [NLVR2]: iter 77384 Ep: 14.34 loss 0.015 score 0.221 lr 7.87689e-07 
12/02/2021 23:05:33 - INFO - volta.train_utils -   [NLVR2]: iter 77464 Ep: 14.35 loss 0.016 score 0.225 lr 7.8563e-07 
12/02/2021 23:05:55 - INFO - volta.train_utils -   [NLVR2]: iter 77544 Ep: 14.37 loss 0.018 score 0.221 lr 7.83572e-07 
12/02/2021 23:06:17 - INFO - volta.train_utils -   [NLVR2]: iter 77624 Ep: 14.38 loss 0.016 score 0.220 lr 7.81514e-07 
12/02/2021 23:06:39 - INFO - volta.train_utils -   [NLVR2]: iter 77704 Ep: 14.39 loss 0.017 score 0.220 lr 7.79455e-07 
12/02/2021 23:07:01 - INFO - volta.train_utils -   [NLVR2]: iter 77784 Ep: 14.41 loss 0.019 score 0.223 lr 7.77397e-07 
12/02/2021 23:07:23 - INFO - volta.train_utils -   [NLVR2]: iter 77864 Ep: 14.42 loss 0.015 score 0.221 lr 7.75339e-07 
12/02/2021 23:07:45 - INFO - volta.train_utils -   [NLVR2]: iter 77944 Ep: 14.44 loss 0.015 score 0.222 lr 7.7328e-07 
12/02/2021 23:08:07 - INFO - volta.train_utils -   [NLVR2]: iter 78024 Ep: 14.45 loss 0.015 score 0.222 lr 7.71222e-07 
12/02/2021 23:08:29 - INFO - volta.train_utils -   [NLVR2]: iter 78104 Ep: 14.47 loss 0.016 score 0.223 lr 7.69163e-07 
12/02/2021 23:08:51 - INFO - volta.train_utils -   [NLVR2]: iter 78184 Ep: 14.48 loss 0.016 score 0.224 lr 7.67105e-07 
12/02/2021 23:09:13 - INFO - volta.train_utils -   [NLVR2]: iter 78264 Ep: 14.50 loss 0.015 score 0.224 lr 7.65047e-07 
12/02/2021 23:09:35 - INFO - volta.train_utils -   [NLVR2]: iter 78344 Ep: 14.51 loss 0.016 score 0.223 lr 7.62988e-07 
12/02/2021 23:09:57 - INFO - volta.train_utils -   [NLVR2]: iter 78424 Ep: 14.53 loss 0.013 score 0.228 lr 7.6093e-07 
12/02/2021 23:10:19 - INFO - volta.train_utils -   [NLVR2]: iter 78504 Ep: 14.54 loss 0.014 score 0.223 lr 7.58872e-07 
12/02/2021 23:10:41 - INFO - volta.train_utils -   [NLVR2]: iter 78584 Ep: 14.56 loss 0.017 score 0.226 lr 7.56813e-07 
12/02/2021 23:11:03 - INFO - volta.train_utils -   [NLVR2]: iter 78664 Ep: 14.57 loss 0.015 score 0.221 lr 7.54755e-07 
12/02/2021 23:11:25 - INFO - volta.train_utils -   [NLVR2]: iter 78744 Ep: 14.59 loss 0.014 score 0.223 lr 7.52696e-07 
12/02/2021 23:11:47 - INFO - volta.train_utils -   [NLVR2]: iter 78824 Ep: 14.60 loss 0.013 score 0.224 lr 7.50638e-07 
12/02/2021 23:12:09 - INFO - volta.train_utils -   [NLVR2]: iter 78904 Ep: 14.62 loss 0.014 score 0.228 lr 7.4858e-07 
12/02/2021 23:12:30 - INFO - volta.train_utils -   [NLVR2]: iter 78984 Ep: 14.63 loss 0.011 score 0.223 lr 7.46521e-07 
12/02/2021 23:12:52 - INFO - volta.train_utils -   [NLVR2]: iter 79064 Ep: 14.65 loss 0.012 score 0.227 lr 7.44463e-07 
12/02/2021 23:13:14 - INFO - volta.train_utils -   [NLVR2]: iter 79144 Ep: 14.66 loss 0.012 score 0.225 lr 7.42405e-07 
12/02/2021 23:13:36 - INFO - volta.train_utils -   [NLVR2]: iter 79224 Ep: 14.68 loss 0.017 score 0.225 lr 7.40346e-07 
12/02/2021 23:13:58 - INFO - volta.train_utils -   [NLVR2]: iter 79304 Ep: 14.69 loss 0.017 score 0.222 lr 7.38288e-07 
12/02/2021 23:14:20 - INFO - volta.train_utils -   [NLVR2]: iter 79384 Ep: 14.71 loss 0.015 score 0.221 lr 7.36229e-07 
12/02/2021 23:14:42 - INFO - volta.train_utils -   [NLVR2]: iter 79464 Ep: 14.72 loss 0.017 score 0.222 lr 7.34171e-07 
12/02/2021 23:15:04 - INFO - volta.train_utils -   [NLVR2]: iter 79544 Ep: 14.74 loss 0.013 score 0.224 lr 7.32113e-07 
12/02/2021 23:15:26 - INFO - volta.train_utils -   [NLVR2]: iter 79624 Ep: 14.75 loss 0.013 score 0.227 lr 7.30054e-07 
12/02/2021 23:15:48 - INFO - volta.train_utils -   [NLVR2]: iter 79704 Ep: 14.77 loss 0.013 score 0.222 lr 7.27996e-07 
12/02/2021 23:16:10 - INFO - volta.train_utils -   [NLVR2]: iter 79784 Ep: 14.78 loss 0.014 score 0.225 lr 7.25938e-07 
12/02/2021 23:16:31 - INFO - volta.train_utils -   [NLVR2]: iter 79864 Ep: 14.80 loss 0.013 score 0.223 lr 7.23879e-07 
12/02/2021 23:16:53 - INFO - volta.train_utils -   [NLVR2]: iter 79944 Ep: 14.81 loss 0.013 score 0.225 lr 7.21821e-07 
12/02/2021 23:17:15 - INFO - volta.train_utils -   [NLVR2]: iter 80024 Ep: 14.82 loss 0.015 score 0.224 lr 7.19762e-07 
12/02/2021 23:17:37 - INFO - volta.train_utils -   [NLVR2]: iter 80104 Ep: 14.84 loss 0.012 score 0.227 lr 7.17704e-07 
12/02/2021 23:17:59 - INFO - volta.train_utils -   [NLVR2]: iter 80184 Ep: 14.85 loss 0.016 score 0.222 lr 7.15646e-07 
12/02/2021 23:18:20 - INFO - volta.train_utils -   [NLVR2]: iter 80264 Ep: 14.87 loss 0.012 score 0.227 lr 7.13587e-07 
12/02/2021 23:18:42 - INFO - volta.train_utils -   [NLVR2]: iter 80344 Ep: 14.88 loss 0.012 score 0.225 lr 7.11529e-07 
12/02/2021 23:19:04 - INFO - volta.train_utils -   [NLVR2]: iter 80424 Ep: 14.90 loss 0.014 score 0.222 lr 7.09471e-07 
12/02/2021 23:19:26 - INFO - volta.train_utils -   [NLVR2]: iter 80504 Ep: 14.91 loss 0.015 score 0.226 lr 7.07412e-07 
12/02/2021 23:19:48 - INFO - volta.train_utils -   [NLVR2]: iter 80584 Ep: 14.93 loss 0.013 score 0.225 lr 7.05354e-07 
12/02/2021 23:20:10 - INFO - volta.train_utils -   [NLVR2]: iter 80664 Ep: 14.94 loss 0.016 score 0.226 lr 7.03295e-07 
12/02/2021 23:20:32 - INFO - volta.train_utils -   [NLVR2]: iter 80744 Ep: 14.96 loss 0.014 score 0.228 lr 7.01237e-07 
12/02/2021 23:20:54 - INFO - volta.train_utils -   [NLVR2]: iter 80824 Ep: 14.97 loss 0.014 score 0.226 lr 6.99179e-07 
12/02/2021 23:21:16 - INFO - volta.train_utils -   [NLVR2]: iter 80904 Ep: 14.99 loss 0.015 score 0.224 lr 6.9712e-07 
12/02/2021 23:22:12 - INFO - volta.train_utils -   Eval task TASK12 on iteration 80940 
12/02/2021 23:22:12 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.964 score 69.080 
Epoch:  75%|███████▌  | 15/20 [6:25:37<2:07:32, 1530.43s/it]12/02/2021 23:22:34 - INFO - volta.train_utils -   [NLVR2]: iter 81020 Ep: 15.01 loss 0.013 score 0.230 lr 6.94599e-07 
12/02/2021 23:22:56 - INFO - volta.train_utils -   [NLVR2]: iter 81100 Ep: 15.02 loss 0.014 score 0.224 lr 6.92077e-07 
12/02/2021 23:23:18 - INFO - volta.train_utils -   [NLVR2]: iter 81180 Ep: 15.04 loss 0.012 score 0.228 lr 6.90019e-07 
12/02/2021 23:23:40 - INFO - volta.train_utils -   [NLVR2]: iter 81260 Ep: 15.05 loss 0.015 score 0.227 lr 6.87961e-07 
12/02/2021 23:24:02 - INFO - volta.train_utils -   [NLVR2]: iter 81340 Ep: 15.07 loss 0.011 score 0.226 lr 6.85902e-07 
12/02/2021 23:24:24 - INFO - volta.train_utils -   [NLVR2]: iter 81420 Ep: 15.08 loss 0.012 score 0.225 lr 6.83844e-07 
12/02/2021 23:24:46 - INFO - volta.train_utils -   [NLVR2]: iter 81500 Ep: 15.10 loss 0.014 score 0.225 lr 6.81785e-07 
12/02/2021 23:25:08 - INFO - volta.train_utils -   [NLVR2]: iter 81580 Ep: 15.11 loss 0.014 score 0.225 lr 6.79727e-07 
12/02/2021 23:25:30 - INFO - volta.train_utils -   [NLVR2]: iter 81660 Ep: 15.13 loss 0.013 score 0.223 lr 6.77669e-07 
12/02/2021 23:25:52 - INFO - volta.train_utils -   [NLVR2]: iter 81740 Ep: 15.14 loss 0.017 score 0.222 lr 6.7561e-07 
12/02/2021 23:26:14 - INFO - volta.train_utils -   [NLVR2]: iter 81820 Ep: 15.16 loss 0.014 score 0.224 lr 6.73552e-07 
12/02/2021 23:26:36 - INFO - volta.train_utils -   [NLVR2]: iter 81900 Ep: 15.17 loss 0.012 score 0.224 lr 6.71494e-07 
12/02/2021 23:26:57 - INFO - volta.train_utils -   [NLVR2]: iter 81980 Ep: 15.19 loss 0.014 score 0.226 lr 6.69435e-07 
12/02/2021 23:27:19 - INFO - volta.train_utils -   [NLVR2]: iter 82060 Ep: 15.20 loss 0.013 score 0.226 lr 6.67377e-07 
12/02/2021 23:27:41 - INFO - volta.train_utils -   [NLVR2]: iter 82140 Ep: 15.22 loss 0.017 score 0.224 lr 6.65318e-07 
12/02/2021 23:28:03 - INFO - volta.train_utils -   [NLVR2]: iter 82220 Ep: 15.23 loss 0.016 score 0.224 lr 6.6326e-07 
12/02/2021 23:28:25 - INFO - volta.train_utils -   [NLVR2]: iter 82300 Ep: 15.25 loss 0.017 score 0.224 lr 6.61202e-07 
12/02/2021 23:28:47 - INFO - volta.train_utils -   [NLVR2]: iter 82380 Ep: 15.26 loss 0.015 score 0.226 lr 6.59143e-07 
12/02/2021 23:29:09 - INFO - volta.train_utils -   [NLVR2]: iter 82460 Ep: 15.28 loss 0.012 score 0.225 lr 6.57085e-07 
12/02/2021 23:29:31 - INFO - volta.train_utils -   [NLVR2]: iter 82540 Ep: 15.29 loss 0.014 score 0.227 lr 6.55027e-07 
12/02/2021 23:29:53 - INFO - volta.train_utils -   [NLVR2]: iter 82620 Ep: 15.31 loss 0.015 score 0.225 lr 6.52968e-07 
12/02/2021 23:30:15 - INFO - volta.train_utils -   [NLVR2]: iter 82700 Ep: 15.32 loss 0.012 score 0.226 lr 6.5091e-07 
12/02/2021 23:30:37 - INFO - volta.train_utils -   [NLVR2]: iter 82780 Ep: 15.34 loss 0.015 score 0.222 lr 6.48851e-07 
12/02/2021 23:30:59 - INFO - volta.train_utils -   [NLVR2]: iter 82860 Ep: 15.35 loss 0.016 score 0.225 lr 6.46793e-07 
12/02/2021 23:31:20 - INFO - volta.train_utils -   [NLVR2]: iter 82940 Ep: 15.36 loss 0.012 score 0.231 lr 6.44735e-07 
12/02/2021 23:31:42 - INFO - volta.train_utils -   [NLVR2]: iter 83020 Ep: 15.38 loss 0.016 score 0.223 lr 6.42676e-07 
12/02/2021 23:32:04 - INFO - volta.train_utils -   [NLVR2]: iter 83100 Ep: 15.39 loss 0.016 score 0.223 lr 6.40618e-07 
12/02/2021 23:32:26 - INFO - volta.train_utils -   [NLVR2]: iter 83180 Ep: 15.41 loss 0.015 score 0.227 lr 6.3856e-07 
12/02/2021 23:32:48 - INFO - volta.train_utils -   [NLVR2]: iter 83260 Ep: 15.42 loss 0.015 score 0.222 lr 6.36501e-07 
12/02/2021 23:33:10 - INFO - volta.train_utils -   [NLVR2]: iter 83340 Ep: 15.44 loss 0.014 score 0.222 lr 6.34443e-07 
12/02/2021 23:33:32 - INFO - volta.train_utils -   [NLVR2]: iter 83420 Ep: 15.45 loss 0.015 score 0.226 lr 6.32384e-07 
12/02/2021 23:33:54 - INFO - volta.train_utils -   [NLVR2]: iter 83500 Ep: 15.47 loss 0.012 score 0.225 lr 6.30326e-07 
12/02/2021 23:34:16 - INFO - volta.train_utils -   [NLVR2]: iter 83580 Ep: 15.48 loss 0.013 score 0.228 lr 6.28268e-07 
12/02/2021 23:34:38 - INFO - volta.train_utils -   [NLVR2]: iter 83660 Ep: 15.50 loss 0.015 score 0.221 lr 6.26209e-07 
12/02/2021 23:35:00 - INFO - volta.train_utils -   [NLVR2]: iter 83740 Ep: 15.51 loss 0.013 score 0.225 lr 6.24151e-07 
12/02/2021 23:35:22 - INFO - volta.train_utils -   [NLVR2]: iter 83820 Ep: 15.53 loss 0.015 score 0.226 lr 6.22093e-07 
12/02/2021 23:35:44 - INFO - volta.train_utils -   [NLVR2]: iter 83900 Ep: 15.54 loss 0.015 score 0.226 lr 6.20034e-07 
12/02/2021 23:36:06 - INFO - volta.train_utils -   [NLVR2]: iter 83980 Ep: 15.56 loss 0.016 score 0.227 lr 6.17976e-07 
12/02/2021 23:36:27 - INFO - volta.train_utils -   [NLVR2]: iter 84060 Ep: 15.57 loss 0.013 score 0.227 lr 6.15917e-07 
12/02/2021 23:36:49 - INFO - volta.train_utils -   [NLVR2]: iter 84140 Ep: 15.59 loss 0.016 score 0.225 lr 6.13859e-07 
12/02/2021 23:37:11 - INFO - volta.train_utils -   [NLVR2]: iter 84220 Ep: 15.60 loss 0.015 score 0.225 lr 6.11801e-07 
12/02/2021 23:37:33 - INFO - volta.train_utils -   [NLVR2]: iter 84300 Ep: 15.62 loss 0.013 score 0.227 lr 6.09742e-07 
12/02/2021 23:37:55 - INFO - volta.train_utils -   [NLVR2]: iter 84380 Ep: 15.63 loss 0.015 score 0.226 lr 6.07684e-07 
12/02/2021 23:38:17 - INFO - volta.train_utils -   [NLVR2]: iter 84460 Ep: 15.65 loss 0.013 score 0.225 lr 6.05626e-07 
12/02/2021 23:38:39 - INFO - volta.train_utils -   [NLVR2]: iter 84540 Ep: 15.66 loss 0.015 score 0.227 lr 6.03567e-07 
12/02/2021 23:39:01 - INFO - volta.train_utils -   [NLVR2]: iter 84620 Ep: 15.68 loss 0.013 score 0.225 lr 6.01509e-07 
12/02/2021 23:39:23 - INFO - volta.train_utils -   [NLVR2]: iter 84700 Ep: 15.69 loss 0.014 score 0.223 lr 5.9945e-07 
12/02/2021 23:39:45 - INFO - volta.train_utils -   [NLVR2]: iter 84780 Ep: 15.71 loss 0.013 score 0.231 lr 5.97392e-07 
12/02/2021 23:40:07 - INFO - volta.train_utils -   [NLVR2]: iter 84860 Ep: 15.72 loss 0.017 score 0.225 lr 5.95334e-07 
12/02/2021 23:40:29 - INFO - volta.train_utils -   [NLVR2]: iter 84940 Ep: 15.74 loss 0.013 score 0.225 lr 5.93275e-07 
12/02/2021 23:40:50 - INFO - volta.train_utils -   [NLVR2]: iter 85020 Ep: 15.75 loss 0.011 score 0.226 lr 5.91217e-07 
12/02/2021 23:41:12 - INFO - volta.train_utils -   [NLVR2]: iter 85100 Ep: 15.77 loss 0.013 score 0.223 lr 5.89159e-07 
12/02/2021 23:41:34 - INFO - volta.train_utils -   [NLVR2]: iter 85180 Ep: 15.78 loss 0.014 score 0.228 lr 5.871e-07 
12/02/2021 23:41:56 - INFO - volta.train_utils -   [NLVR2]: iter 85260 Ep: 15.79 loss 0.019 score 0.221 lr 5.85042e-07 
12/02/2021 23:42:18 - INFO - volta.train_utils -   [NLVR2]: iter 85340 Ep: 15.81 loss 0.013 score 0.225 lr 5.82983e-07 
12/02/2021 23:42:40 - INFO - volta.train_utils -   [NLVR2]: iter 85420 Ep: 15.82 loss 0.012 score 0.228 lr 5.80925e-07 
12/02/2021 23:43:02 - INFO - volta.train_utils -   [NLVR2]: iter 85500 Ep: 15.84 loss 0.011 score 0.232 lr 5.78867e-07 
12/02/2021 23:43:24 - INFO - volta.train_utils -   [NLVR2]: iter 85580 Ep: 15.85 loss 0.013 score 0.228 lr 5.76808e-07 
12/02/2021 23:43:46 - INFO - volta.train_utils -   [NLVR2]: iter 85660 Ep: 15.87 loss 0.014 score 0.228 lr 5.7475e-07 
12/02/2021 23:44:08 - INFO - volta.train_utils -   [NLVR2]: iter 85740 Ep: 15.88 loss 0.011 score 0.226 lr 5.72692e-07 
12/02/2021 23:44:30 - INFO - volta.train_utils -   [NLVR2]: iter 85820 Ep: 15.90 loss 0.014 score 0.229 lr 5.70633e-07 
12/02/2021 23:44:52 - INFO - volta.train_utils -   [NLVR2]: iter 85900 Ep: 15.91 loss 0.017 score 0.226 lr 5.68575e-07 
12/02/2021 23:45:14 - INFO - volta.train_utils -   [NLVR2]: iter 85980 Ep: 15.93 loss 0.013 score 0.227 lr 5.66516e-07 
12/02/2021 23:45:36 - INFO - volta.train_utils -   [NLVR2]: iter 86060 Ep: 15.94 loss 0.013 score 0.229 lr 5.64458e-07 
12/02/2021 23:45:58 - INFO - volta.train_utils -   [NLVR2]: iter 86140 Ep: 15.96 loss 0.013 score 0.229 lr 5.624e-07 
12/02/2021 23:46:20 - INFO - volta.train_utils -   [NLVR2]: iter 86220 Ep: 15.97 loss 0.013 score 0.228 lr 5.60341e-07 
12/02/2021 23:46:42 - INFO - volta.train_utils -   [NLVR2]: iter 86300 Ep: 15.99 loss 0.013 score 0.228 lr 5.58283e-07 
12/02/2021 23:47:37 - INFO - volta.train_utils -   Eval task TASK12 on iteration 86336 
12/02/2021 23:47:37 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.974 score 69.123 
Epoch:  80%|████████  | 16/20 [6:51:03<1:41:55, 1528.85s/it]12/02/2021 23:48:00 - INFO - volta.train_utils -   [NLVR2]: iter 86416 Ep: 16.01 loss 0.011 score 0.235 lr 5.55761e-07 
12/02/2021 23:48:22 - INFO - volta.train_utils -   [NLVR2]: iter 86496 Ep: 16.02 loss 0.012 score 0.228 lr 5.5324e-07 
12/02/2021 23:48:43 - INFO - volta.train_utils -   [NLVR2]: iter 86576 Ep: 16.04 loss 0.013 score 0.230 lr 5.51182e-07 
12/02/2021 23:49:05 - INFO - volta.train_utils -   [NLVR2]: iter 86656 Ep: 16.05 loss 0.010 score 0.228 lr 5.49123e-07 
12/02/2021 23:49:27 - INFO - volta.train_utils -   [NLVR2]: iter 86736 Ep: 16.07 loss 0.012 score 0.228 lr 5.47065e-07 
12/02/2021 23:49:49 - INFO - volta.train_utils -   [NLVR2]: iter 86816 Ep: 16.08 loss 0.014 score 0.227 lr 5.45006e-07 
12/02/2021 23:50:11 - INFO - volta.train_utils -   [NLVR2]: iter 86896 Ep: 16.10 loss 0.013 score 0.222 lr 5.42948e-07 
12/02/2021 23:50:33 - INFO - volta.train_utils -   [NLVR2]: iter 86976 Ep: 16.11 loss 0.012 score 0.228 lr 5.4089e-07 
12/02/2021 23:50:55 - INFO - volta.train_utils -   [NLVR2]: iter 87056 Ep: 16.13 loss 0.013 score 0.225 lr 5.38831e-07 
12/02/2021 23:51:17 - INFO - volta.train_utils -   [NLVR2]: iter 87136 Ep: 16.14 loss 0.015 score 0.226 lr 5.36773e-07 
12/02/2021 23:51:39 - INFO - volta.train_utils -   [NLVR2]: iter 87216 Ep: 16.16 loss 0.014 score 0.224 lr 5.34715e-07 
12/02/2021 23:52:01 - INFO - volta.train_utils -   [NLVR2]: iter 87296 Ep: 16.17 loss 0.014 score 0.226 lr 5.32656e-07 
12/02/2021 23:52:23 - INFO - volta.train_utils -   [NLVR2]: iter 87376 Ep: 16.19 loss 0.014 score 0.224 lr 5.30598e-07 
12/02/2021 23:52:44 - INFO - volta.train_utils -   [NLVR2]: iter 87456 Ep: 16.20 loss 0.015 score 0.226 lr 5.28539e-07 
12/02/2021 23:53:07 - INFO - volta.train_utils -   [NLVR2]: iter 87536 Ep: 16.22 loss 0.014 score 0.225 lr 5.26481e-07 
12/02/2021 23:53:28 - INFO - volta.train_utils -   [NLVR2]: iter 87616 Ep: 16.23 loss 0.016 score 0.222 lr 5.24423e-07 
12/02/2021 23:53:50 - INFO - volta.train_utils -   [NLVR2]: iter 87696 Ep: 16.25 loss 0.012 score 0.225 lr 5.22364e-07 
12/02/2021 23:54:12 - INFO - volta.train_utils -   [NLVR2]: iter 87776 Ep: 16.26 loss 0.013 score 0.226 lr 5.20306e-07 
12/02/2021 23:54:34 - INFO - volta.train_utils -   [NLVR2]: iter 87856 Ep: 16.28 loss 0.011 score 0.228 lr 5.18247e-07 
12/02/2021 23:54:56 - INFO - volta.train_utils -   [NLVR2]: iter 87936 Ep: 16.29 loss 0.014 score 0.227 lr 5.16189e-07 
12/02/2021 23:55:18 - INFO - volta.train_utils -   [NLVR2]: iter 88016 Ep: 16.31 loss 0.016 score 0.227 lr 5.14131e-07 
12/02/2021 23:55:40 - INFO - volta.train_utils -   [NLVR2]: iter 88096 Ep: 16.32 loss 0.013 score 0.227 lr 5.12072e-07 
12/02/2021 23:56:02 - INFO - volta.train_utils -   [NLVR2]: iter 88176 Ep: 16.33 loss 0.010 score 0.229 lr 5.10014e-07 
12/02/2021 23:56:24 - INFO - volta.train_utils -   [NLVR2]: iter 88256 Ep: 16.35 loss 0.013 score 0.226 lr 5.07956e-07 
12/02/2021 23:56:46 - INFO - volta.train_utils -   [NLVR2]: iter 88336 Ep: 16.36 loss 0.016 score 0.224 lr 5.05897e-07 
12/02/2021 23:57:08 - INFO - volta.train_utils -   [NLVR2]: iter 88416 Ep: 16.38 loss 0.012 score 0.229 lr 5.03839e-07 
12/02/2021 23:57:29 - INFO - volta.train_utils -   [NLVR2]: iter 88496 Ep: 16.39 loss 0.010 score 0.231 lr 5.0178e-07 
12/02/2021 23:57:51 - INFO - volta.train_utils -   [NLVR2]: iter 88576 Ep: 16.41 loss 0.013 score 0.225 lr 4.99722e-07 
12/02/2021 23:58:13 - INFO - volta.train_utils -   [NLVR2]: iter 88656 Ep: 16.42 loss 0.013 score 0.228 lr 4.97664e-07 
12/02/2021 23:58:35 - INFO - volta.train_utils -   [NLVR2]: iter 88736 Ep: 16.44 loss 0.015 score 0.227 lr 4.95605e-07 
12/02/2021 23:58:57 - INFO - volta.train_utils -   [NLVR2]: iter 88816 Ep: 16.45 loss 0.016 score 0.227 lr 4.93547e-07 
12/02/2021 23:59:19 - INFO - volta.train_utils -   [NLVR2]: iter 88896 Ep: 16.47 loss 0.014 score 0.229 lr 4.91489e-07 
12/02/2021 23:59:41 - INFO - volta.train_utils -   [NLVR2]: iter 88976 Ep: 16.48 loss 0.013 score 0.225 lr 4.8943e-07 
12/03/2021 00:00:03 - INFO - volta.train_utils -   [NLVR2]: iter 89056 Ep: 16.50 loss 0.014 score 0.229 lr 4.87372e-07 
12/03/2021 00:00:25 - INFO - volta.train_utils -   [NLVR2]: iter 89136 Ep: 16.51 loss 0.015 score 0.228 lr 4.85313e-07 
12/03/2021 00:00:47 - INFO - volta.train_utils -   [NLVR2]: iter 89216 Ep: 16.53 loss 0.011 score 0.229 lr 4.83255e-07 
12/03/2021 00:01:08 - INFO - volta.train_utils -   [NLVR2]: iter 89296 Ep: 16.54 loss 0.013 score 0.230 lr 4.81197e-07 
12/03/2021 00:01:30 - INFO - volta.train_utils -   [NLVR2]: iter 89376 Ep: 16.56 loss 0.014 score 0.226 lr 4.79138e-07 
12/03/2021 00:01:52 - INFO - volta.train_utils -   [NLVR2]: iter 89456 Ep: 16.57 loss 0.013 score 0.228 lr 4.7708e-07 
12/03/2021 00:02:14 - INFO - volta.train_utils -   [NLVR2]: iter 89536 Ep: 16.59 loss 0.013 score 0.227 lr 4.75022e-07 
12/03/2021 00:02:36 - INFO - volta.train_utils -   [NLVR2]: iter 89616 Ep: 16.60 loss 0.014 score 0.225 lr 4.72963e-07 
12/03/2021 00:02:58 - INFO - volta.train_utils -   [NLVR2]: iter 89696 Ep: 16.62 loss 0.013 score 0.228 lr 4.70905e-07 
12/03/2021 00:03:20 - INFO - volta.train_utils -   [NLVR2]: iter 89776 Ep: 16.63 loss 0.012 score 0.228 lr 4.68846e-07 
12/03/2021 00:03:42 - INFO - volta.train_utils -   [NLVR2]: iter 89856 Ep: 16.65 loss 0.014 score 0.226 lr 4.66788e-07 
12/03/2021 00:04:04 - INFO - volta.train_utils -   [NLVR2]: iter 89936 Ep: 16.66 loss 0.014 score 0.228 lr 4.6473e-07 
12/03/2021 00:04:26 - INFO - volta.train_utils -   [NLVR2]: iter 90016 Ep: 16.68 loss 0.015 score 0.225 lr 4.62671e-07 
12/03/2021 00:04:48 - INFO - volta.train_utils -   [NLVR2]: iter 90096 Ep: 16.69 loss 0.014 score 0.224 lr 4.60613e-07 
12/03/2021 00:05:10 - INFO - volta.train_utils -   [NLVR2]: iter 90176 Ep: 16.71 loss 0.013 score 0.228 lr 4.58555e-07 
12/03/2021 00:05:32 - INFO - volta.train_utils -   [NLVR2]: iter 90256 Ep: 16.72 loss 0.012 score 0.225 lr 4.56496e-07 
12/03/2021 00:05:54 - INFO - volta.train_utils -   [NLVR2]: iter 90336 Ep: 16.74 loss 0.015 score 0.228 lr 4.54438e-07 
12/03/2021 00:06:15 - INFO - volta.train_utils -   [NLVR2]: iter 90416 Ep: 16.75 loss 0.012 score 0.230 lr 4.52379e-07 
12/03/2021 00:06:37 - INFO - volta.train_utils -   [NLVR2]: iter 90496 Ep: 16.76 loss 0.012 score 0.225 lr 4.50321e-07 
12/03/2021 00:06:59 - INFO - volta.train_utils -   [NLVR2]: iter 90576 Ep: 16.78 loss 0.012 score 0.227 lr 4.48263e-07 
12/03/2021 00:07:21 - INFO - volta.train_utils -   [NLVR2]: iter 90656 Ep: 16.79 loss 0.012 score 0.228 lr 4.46204e-07 
12/03/2021 00:07:43 - INFO - volta.train_utils -   [NLVR2]: iter 90736 Ep: 16.81 loss 0.014 score 0.228 lr 4.44146e-07 
12/03/2021 00:08:05 - INFO - volta.train_utils -   [NLVR2]: iter 90816 Ep: 16.82 loss 0.013 score 0.227 lr 4.42088e-07 
12/03/2021 00:08:27 - INFO - volta.train_utils -   [NLVR2]: iter 90896 Ep: 16.84 loss 0.010 score 0.230 lr 4.40029e-07 
12/03/2021 00:08:49 - INFO - volta.train_utils -   [NLVR2]: iter 90976 Ep: 16.85 loss 0.011 score 0.230 lr 4.37971e-07 
12/03/2021 00:09:11 - INFO - volta.train_utils -   [NLVR2]: iter 91056 Ep: 16.87 loss 0.011 score 0.229 lr 4.35912e-07 
12/03/2021 00:09:33 - INFO - volta.train_utils -   [NLVR2]: iter 91136 Ep: 16.88 loss 0.011 score 0.230 lr 4.33854e-07 
12/03/2021 00:09:55 - INFO - volta.train_utils -   [NLVR2]: iter 91216 Ep: 16.90 loss 0.015 score 0.227 lr 4.31796e-07 
12/03/2021 00:10:17 - INFO - volta.train_utils -   [NLVR2]: iter 91296 Ep: 16.91 loss 0.012 score 0.229 lr 4.29737e-07 
12/03/2021 00:10:39 - INFO - volta.train_utils -   [NLVR2]: iter 91376 Ep: 16.93 loss 0.011 score 0.229 lr 4.27679e-07 
12/03/2021 00:11:00 - INFO - volta.train_utils -   [NLVR2]: iter 91456 Ep: 16.94 loss 0.011 score 0.231 lr 4.25621e-07 
12/03/2021 00:11:22 - INFO - volta.train_utils -   [NLVR2]: iter 91536 Ep: 16.96 loss 0.013 score 0.228 lr 4.23562e-07 
12/03/2021 00:11:44 - INFO - volta.train_utils -   [NLVR2]: iter 91616 Ep: 16.97 loss 0.013 score 0.227 lr 4.21504e-07 
12/03/2021 00:12:06 - INFO - volta.train_utils -   [NLVR2]: iter 91696 Ep: 16.99 loss 0.012 score 0.231 lr 4.19445e-07 
12/03/2021 00:13:01 - INFO - volta.train_utils -   Eval task TASK12 on iteration 91732 
12/03/2021 00:13:01 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.004 score 69.438 
Epoch:  85%|████████▌ | 17/20 [7:16:26<1:16:21, 1527.33s/it]12/03/2021 00:13:23 - INFO - volta.train_utils -   [NLVR2]: iter 91812 Ep: 17.01 loss 0.012 score 0.233 lr 4.16924e-07 
12/03/2021 00:13:45 - INFO - volta.train_utils -   [NLVR2]: iter 91892 Ep: 17.02 loss 0.011 score 0.229 lr 4.14402e-07 
12/03/2021 00:14:07 - INFO - volta.train_utils -   [NLVR2]: iter 91972 Ep: 17.04 loss 0.016 score 0.226 lr 4.12344e-07 
12/03/2021 00:14:29 - INFO - volta.train_utils -   [NLVR2]: iter 92052 Ep: 17.05 loss 0.015 score 0.227 lr 4.10286e-07 
12/03/2021 00:14:51 - INFO - volta.train_utils -   [NLVR2]: iter 92132 Ep: 17.07 loss 0.013 score 0.224 lr 4.08227e-07 
12/03/2021 00:15:13 - INFO - volta.train_utils -   [NLVR2]: iter 92212 Ep: 17.08 loss 0.011 score 0.232 lr 4.06169e-07 
12/03/2021 00:15:34 - INFO - volta.train_utils -   [NLVR2]: iter 92292 Ep: 17.10 loss 0.013 score 0.228 lr 4.04111e-07 
12/03/2021 00:15:56 - INFO - volta.train_utils -   [NLVR2]: iter 92372 Ep: 17.11 loss 0.011 score 0.229 lr 4.02052e-07 
12/03/2021 00:16:18 - INFO - volta.train_utils -   [NLVR2]: iter 92452 Ep: 17.13 loss 0.013 score 0.229 lr 3.99994e-07 
12/03/2021 00:16:40 - INFO - volta.train_utils -   [NLVR2]: iter 92532 Ep: 17.14 loss 0.011 score 0.229 lr 3.97935e-07 
12/03/2021 00:17:02 - INFO - volta.train_utils -   [NLVR2]: iter 92612 Ep: 17.16 loss 0.011 score 0.230 lr 3.95877e-07 
12/03/2021 00:17:24 - INFO - volta.train_utils -   [NLVR2]: iter 92692 Ep: 17.17 loss 0.011 score 0.227 lr 3.93819e-07 
12/03/2021 00:17:46 - INFO - volta.train_utils -   [NLVR2]: iter 92772 Ep: 17.19 loss 0.012 score 0.226 lr 3.9176e-07 
12/03/2021 00:18:08 - INFO - volta.train_utils -   [NLVR2]: iter 92852 Ep: 17.20 loss 0.013 score 0.227 lr 3.89702e-07 
12/03/2021 00:18:30 - INFO - volta.train_utils -   [NLVR2]: iter 92932 Ep: 17.22 loss 0.012 score 0.229 lr 3.87644e-07 
12/03/2021 00:18:52 - INFO - volta.train_utils -   [NLVR2]: iter 93012 Ep: 17.23 loss 0.012 score 0.229 lr 3.85585e-07 
12/03/2021 00:19:14 - INFO - volta.train_utils -   [NLVR2]: iter 93092 Ep: 17.25 loss 0.015 score 0.228 lr 3.83527e-07 
12/03/2021 00:19:36 - INFO - volta.train_utils -   [NLVR2]: iter 93172 Ep: 17.26 loss 0.015 score 0.225 lr 3.81468e-07 
12/03/2021 00:19:58 - INFO - volta.train_utils -   [NLVR2]: iter 93252 Ep: 17.28 loss 0.012 score 0.230 lr 3.7941e-07 
12/03/2021 00:20:20 - INFO - volta.train_utils -   [NLVR2]: iter 93332 Ep: 17.29 loss 0.011 score 0.227 lr 3.77352e-07 
12/03/2021 00:20:42 - INFO - volta.train_utils -   [NLVR2]: iter 93412 Ep: 17.30 loss 0.011 score 0.232 lr 3.75293e-07 
12/03/2021 00:21:04 - INFO - volta.train_utils -   [NLVR2]: iter 93492 Ep: 17.32 loss 0.011 score 0.229 lr 3.73235e-07 
12/03/2021 00:21:26 - INFO - volta.train_utils -   [NLVR2]: iter 93572 Ep: 17.33 loss 0.011 score 0.231 lr 3.71177e-07 
12/03/2021 00:21:47 - INFO - volta.train_utils -   [NLVR2]: iter 93652 Ep: 17.35 loss 0.013 score 0.226 lr 3.69118e-07 
12/03/2021 00:22:09 - INFO - volta.train_utils -   [NLVR2]: iter 93732 Ep: 17.36 loss 0.014 score 0.227 lr 3.6706e-07 
12/03/2021 00:22:31 - INFO - volta.train_utils -   [NLVR2]: iter 93812 Ep: 17.38 loss 0.009 score 0.227 lr 3.65001e-07 
12/03/2021 00:22:53 - INFO - volta.train_utils -   [NLVR2]: iter 93892 Ep: 17.39 loss 0.013 score 0.223 lr 3.62943e-07 
12/03/2021 00:23:15 - INFO - volta.train_utils -   [NLVR2]: iter 93972 Ep: 17.41 loss 0.014 score 0.225 lr 3.60885e-07 
12/03/2021 00:23:37 - INFO - volta.train_utils -   [NLVR2]: iter 94052 Ep: 17.42 loss 0.015 score 0.226 lr 3.58826e-07 
12/03/2021 00:23:59 - INFO - volta.train_utils -   [NLVR2]: iter 94132 Ep: 17.44 loss 0.012 score 0.229 lr 3.56768e-07 
12/03/2021 00:24:21 - INFO - volta.train_utils -   [NLVR2]: iter 94212 Ep: 17.45 loss 0.013 score 0.225 lr 3.5471e-07 
12/03/2021 00:24:43 - INFO - volta.train_utils -   [NLVR2]: iter 94292 Ep: 17.47 loss 0.014 score 0.229 lr 3.52651e-07 
12/03/2021 00:25:05 - INFO - volta.train_utils -   [NLVR2]: iter 94372 Ep: 17.48 loss 0.014 score 0.229 lr 3.50593e-07 
12/03/2021 00:25:27 - INFO - volta.train_utils -   [NLVR2]: iter 94452 Ep: 17.50 loss 0.012 score 0.229 lr 3.48534e-07 
12/03/2021 00:25:49 - INFO - volta.train_utils -   [NLVR2]: iter 94532 Ep: 17.51 loss 0.012 score 0.230 lr 3.46476e-07 
12/03/2021 00:26:11 - INFO - volta.train_utils -   [NLVR2]: iter 94612 Ep: 17.53 loss 0.013 score 0.229 lr 3.44418e-07 
12/03/2021 00:26:33 - INFO - volta.train_utils -   [NLVR2]: iter 94692 Ep: 17.54 loss 0.013 score 0.228 lr 3.42359e-07 
12/03/2021 00:26:55 - INFO - volta.train_utils -   [NLVR2]: iter 94772 Ep: 17.56 loss 0.012 score 0.228 lr 3.40301e-07 
12/03/2021 00:27:16 - INFO - volta.train_utils -   [NLVR2]: iter 94852 Ep: 17.57 loss 0.013 score 0.227 lr 3.38243e-07 
12/03/2021 00:27:38 - INFO - volta.train_utils -   [NLVR2]: iter 94932 Ep: 17.59 loss 0.009 score 0.228 lr 3.36184e-07 
12/03/2021 00:28:00 - INFO - volta.train_utils -   [NLVR2]: iter 95012 Ep: 17.60 loss 0.015 score 0.228 lr 3.34126e-07 
12/03/2021 00:28:22 - INFO - volta.train_utils -   [NLVR2]: iter 95092 Ep: 17.62 loss 0.011 score 0.228 lr 3.32067e-07 
12/03/2021 00:28:44 - INFO - volta.train_utils -   [NLVR2]: iter 95172 Ep: 17.63 loss 0.014 score 0.221 lr 3.30009e-07 
12/03/2021 00:29:06 - INFO - volta.train_utils -   [NLVR2]: iter 95252 Ep: 17.65 loss 0.010 score 0.233 lr 3.27951e-07 
12/03/2021 00:29:28 - INFO - volta.train_utils -   [NLVR2]: iter 95332 Ep: 17.66 loss 0.012 score 0.232 lr 3.25892e-07 
12/03/2021 00:29:50 - INFO - volta.train_utils -   [NLVR2]: iter 95412 Ep: 17.68 loss 0.011 score 0.229 lr 3.23834e-07 
12/03/2021 00:30:12 - INFO - volta.train_utils -   [NLVR2]: iter 95492 Ep: 17.69 loss 0.011 score 0.227 lr 3.21776e-07 
12/03/2021 00:30:34 - INFO - volta.train_utils -   [NLVR2]: iter 95572 Ep: 17.71 loss 0.015 score 0.228 lr 3.19717e-07 
12/03/2021 00:30:56 - INFO - volta.train_utils -   [NLVR2]: iter 95652 Ep: 17.72 loss 0.013 score 0.227 lr 3.17659e-07 
12/03/2021 00:31:17 - INFO - volta.train_utils -   [NLVR2]: iter 95732 Ep: 17.73 loss 0.013 score 0.228 lr 3.156e-07 
12/03/2021 00:31:39 - INFO - volta.train_utils -   [NLVR2]: iter 95812 Ep: 17.75 loss 0.011 score 0.229 lr 3.13542e-07 
12/03/2021 00:32:01 - INFO - volta.train_utils -   [NLVR2]: iter 95892 Ep: 17.76 loss 0.015 score 0.224 lr 3.11484e-07 
12/03/2021 00:32:23 - INFO - volta.train_utils -   [NLVR2]: iter 95972 Ep: 17.78 loss 0.010 score 0.230 lr 3.09425e-07 
12/03/2021 00:32:45 - INFO - volta.train_utils -   [NLVR2]: iter 96052 Ep: 17.79 loss 0.014 score 0.229 lr 3.07367e-07 
12/03/2021 00:33:07 - INFO - volta.train_utils -   [NLVR2]: iter 96132 Ep: 17.81 loss 0.015 score 0.226 lr 3.05309e-07 
12/03/2021 00:33:29 - INFO - volta.train_utils -   [NLVR2]: iter 96212 Ep: 17.82 loss 0.010 score 0.231 lr 3.0325e-07 
12/03/2021 00:33:51 - INFO - volta.train_utils -   [NLVR2]: iter 96292 Ep: 17.84 loss 0.013 score 0.226 lr 3.01192e-07 
12/03/2021 00:34:13 - INFO - volta.train_utils -   [NLVR2]: iter 96372 Ep: 17.85 loss 0.013 score 0.230 lr 2.99133e-07 
12/03/2021 00:34:35 - INFO - volta.train_utils -   [NLVR2]: iter 96452 Ep: 17.87 loss 0.010 score 0.230 lr 2.97075e-07 
12/03/2021 00:34:57 - INFO - volta.train_utils -   [NLVR2]: iter 96532 Ep: 17.88 loss 0.013 score 0.227 lr 2.95017e-07 
12/03/2021 00:35:19 - INFO - volta.train_utils -   [NLVR2]: iter 96612 Ep: 17.90 loss 0.012 score 0.228 lr 2.92958e-07 
12/03/2021 00:35:41 - INFO - volta.train_utils -   [NLVR2]: iter 96692 Ep: 17.91 loss 0.012 score 0.231 lr 2.909e-07 
12/03/2021 00:36:03 - INFO - volta.train_utils -   [NLVR2]: iter 96772 Ep: 17.93 loss 0.013 score 0.228 lr 2.88842e-07 
12/03/2021 00:36:25 - INFO - volta.train_utils -   [NLVR2]: iter 96852 Ep: 17.94 loss 0.008 score 0.233 lr 2.86783e-07 
12/03/2021 00:36:47 - INFO - volta.train_utils -   [NLVR2]: iter 96932 Ep: 17.96 loss 0.012 score 0.230 lr 2.84725e-07 
12/03/2021 00:37:09 - INFO - volta.train_utils -   [NLVR2]: iter 97012 Ep: 17.97 loss 0.012 score 0.229 lr 2.82666e-07 
12/03/2021 00:37:31 - INFO - volta.train_utils -   [NLVR2]: iter 97092 Ep: 17.99 loss 0.011 score 0.229 lr 2.80608e-07 
12/03/2021 00:38:26 - INFO - volta.train_utils -   Eval task TASK12 on iteration 97128 
12/03/2021 00:38:26 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.018 score 68.908 
Epoch:  90%|█████████ | 18/20 [7:41:51<50:53, 1526.54s/it]  12/03/2021 00:38:48 - INFO - volta.train_utils -   [NLVR2]: iter 97208 Ep: 18.01 loss 0.012 score 0.235 lr 2.78087e-07 
12/03/2021 00:39:10 - INFO - volta.train_utils -   [NLVR2]: iter 97288 Ep: 18.02 loss 0.014 score 0.230 lr 2.75565e-07 
12/03/2021 00:39:31 - INFO - volta.train_utils -   [NLVR2]: iter 97368 Ep: 18.04 loss 0.010 score 0.230 lr 2.73507e-07 
12/03/2021 00:39:54 - INFO - volta.train_utils -   [NLVR2]: iter 97448 Ep: 18.05 loss 0.011 score 0.230 lr 2.71448e-07 
12/03/2021 00:40:15 - INFO - volta.train_utils -   [NLVR2]: iter 97528 Ep: 18.07 loss 0.010 score 0.232 lr 2.6939e-07 
12/03/2021 00:40:37 - INFO - volta.train_utils -   [NLVR2]: iter 97608 Ep: 18.08 loss 0.013 score 0.227 lr 2.67332e-07 
12/03/2021 00:40:59 - INFO - volta.train_utils -   [NLVR2]: iter 97688 Ep: 18.10 loss 0.012 score 0.228 lr 2.65273e-07 
12/03/2021 00:41:21 - INFO - volta.train_utils -   [NLVR2]: iter 97768 Ep: 18.11 loss 0.011 score 0.231 lr 2.63215e-07 
12/03/2021 00:41:43 - INFO - volta.train_utils -   [NLVR2]: iter 97848 Ep: 18.13 loss 0.015 score 0.229 lr 2.61156e-07 
12/03/2021 00:42:05 - INFO - volta.train_utils -   [NLVR2]: iter 97928 Ep: 18.14 loss 0.013 score 0.226 lr 2.59098e-07 
12/03/2021 00:42:27 - INFO - volta.train_utils -   [NLVR2]: iter 98008 Ep: 18.16 loss 0.010 score 0.228 lr 2.5704e-07 
12/03/2021 00:42:49 - INFO - volta.train_utils -   [NLVR2]: iter 98088 Ep: 18.17 loss 0.010 score 0.230 lr 2.54981e-07 
12/03/2021 00:43:11 - INFO - volta.train_utils -   [NLVR2]: iter 98168 Ep: 18.19 loss 0.013 score 0.229 lr 2.52923e-07 
12/03/2021 00:43:33 - INFO - volta.train_utils -   [NLVR2]: iter 98248 Ep: 18.20 loss 0.012 score 0.230 lr 2.50865e-07 
12/03/2021 00:43:55 - INFO - volta.train_utils -   [NLVR2]: iter 98328 Ep: 18.22 loss 0.011 score 0.229 lr 2.48806e-07 
12/03/2021 00:44:17 - INFO - volta.train_utils -   [NLVR2]: iter 98408 Ep: 18.23 loss 0.015 score 0.227 lr 2.46748e-07 
12/03/2021 00:44:39 - INFO - volta.train_utils -   [NLVR2]: iter 98488 Ep: 18.25 loss 0.013 score 0.231 lr 2.44689e-07 
12/03/2021 00:45:00 - INFO - volta.train_utils -   [NLVR2]: iter 98568 Ep: 18.26 loss 0.014 score 0.228 lr 2.42631e-07 
12/03/2021 00:45:22 - INFO - volta.train_utils -   [NLVR2]: iter 98648 Ep: 18.27 loss 0.011 score 0.229 lr 2.40573e-07 
12/03/2021 00:45:45 - INFO - volta.train_utils -   [NLVR2]: iter 98728 Ep: 18.29 loss 0.012 score 0.229 lr 2.38514e-07 
12/03/2021 00:46:06 - INFO - volta.train_utils -   [NLVR2]: iter 98808 Ep: 18.30 loss 0.013 score 0.227 lr 2.36456e-07 
12/03/2021 00:46:28 - INFO - volta.train_utils -   [NLVR2]: iter 98888 Ep: 18.32 loss 0.012 score 0.234 lr 2.34398e-07 
12/03/2021 00:46:50 - INFO - volta.train_utils -   [NLVR2]: iter 98968 Ep: 18.33 loss 0.013 score 0.227 lr 2.32339e-07 
12/03/2021 00:47:12 - INFO - volta.train_utils -   [NLVR2]: iter 99048 Ep: 18.35 loss 0.014 score 0.229 lr 2.30281e-07 
12/03/2021 00:47:34 - INFO - volta.train_utils -   [NLVR2]: iter 99128 Ep: 18.36 loss 0.015 score 0.230 lr 2.28222e-07 
12/03/2021 00:47:56 - INFO - volta.train_utils -   [NLVR2]: iter 99208 Ep: 18.38 loss 0.011 score 0.229 lr 2.26164e-07 
12/03/2021 00:48:18 - INFO - volta.train_utils -   [NLVR2]: iter 99288 Ep: 18.39 loss 0.012 score 0.228 lr 2.24106e-07 
12/03/2021 00:48:40 - INFO - volta.train_utils -   [NLVR2]: iter 99368 Ep: 18.41 loss 0.014 score 0.223 lr 2.22047e-07 
12/03/2021 00:49:02 - INFO - volta.train_utils -   [NLVR2]: iter 99448 Ep: 18.42 loss 0.013 score 0.226 lr 2.19989e-07 
12/03/2021 00:49:24 - INFO - volta.train_utils -   [NLVR2]: iter 99528 Ep: 18.44 loss 0.011 score 0.228 lr 2.17931e-07 
12/03/2021 00:49:46 - INFO - volta.train_utils -   [NLVR2]: iter 99608 Ep: 18.45 loss 0.009 score 0.231 lr 2.15872e-07 
12/03/2021 00:50:08 - INFO - volta.train_utils -   [NLVR2]: iter 99688 Ep: 18.47 loss 0.011 score 0.231 lr 2.13814e-07 
12/03/2021 00:50:30 - INFO - volta.train_utils -   [NLVR2]: iter 99768 Ep: 18.48 loss 0.012 score 0.228 lr 2.11755e-07 
12/03/2021 00:50:51 - INFO - volta.train_utils -   [NLVR2]: iter 99848 Ep: 18.50 loss 0.011 score 0.231 lr 2.09697e-07 
12/03/2021 00:51:13 - INFO - volta.train_utils -   [NLVR2]: iter 99928 Ep: 18.51 loss 0.012 score 0.229 lr 2.07639e-07 
12/03/2021 00:51:35 - INFO - volta.train_utils -   [NLVR2]: iter 100008 Ep: 18.53 loss 0.011 score 0.230 lr 2.0558e-07 
12/03/2021 00:51:57 - INFO - volta.train_utils -   [NLVR2]: iter 100088 Ep: 18.54 loss 0.013 score 0.228 lr 2.03522e-07 
12/03/2021 00:52:19 - INFO - volta.train_utils -   [NLVR2]: iter 100168 Ep: 18.56 loss 0.012 score 0.228 lr 2.01464e-07 
12/03/2021 00:52:41 - INFO - volta.train_utils -   [NLVR2]: iter 100248 Ep: 18.57 loss 0.010 score 0.229 lr 1.99405e-07 
12/03/2021 00:53:03 - INFO - volta.train_utils -   [NLVR2]: iter 100328 Ep: 18.59 loss 0.015 score 0.231 lr 1.97347e-07 
12/03/2021 00:53:25 - INFO - volta.train_utils -   [NLVR2]: iter 100408 Ep: 18.60 loss 0.012 score 0.231 lr 1.95288e-07 
12/03/2021 00:53:47 - INFO - volta.train_utils -   [NLVR2]: iter 100488 Ep: 18.62 loss 0.011 score 0.229 lr 1.9323e-07 
12/03/2021 00:54:09 - INFO - volta.train_utils -   [NLVR2]: iter 100568 Ep: 18.63 loss 0.014 score 0.230 lr 1.91172e-07 
12/03/2021 00:54:31 - INFO - volta.train_utils -   [NLVR2]: iter 100648 Ep: 18.65 loss 0.013 score 0.229 lr 1.89113e-07 
12/03/2021 00:54:53 - INFO - volta.train_utils -   [NLVR2]: iter 100728 Ep: 18.66 loss 0.014 score 0.229 lr 1.87055e-07 
12/03/2021 00:55:15 - INFO - volta.train_utils -   [NLVR2]: iter 100808 Ep: 18.68 loss 0.011 score 0.228 lr 1.84997e-07 
12/03/2021 00:55:37 - INFO - volta.train_utils -   [NLVR2]: iter 100888 Ep: 18.69 loss 0.016 score 0.228 lr 1.82938e-07 
12/03/2021 00:55:59 - INFO - volta.train_utils -   [NLVR2]: iter 100968 Ep: 18.70 loss 0.011 score 0.229 lr 1.8088e-07 
12/03/2021 00:56:21 - INFO - volta.train_utils -   [NLVR2]: iter 101048 Ep: 18.72 loss 0.013 score 0.230 lr 1.78821e-07 
12/03/2021 00:56:43 - INFO - volta.train_utils -   [NLVR2]: iter 101128 Ep: 18.73 loss 0.013 score 0.232 lr 1.76763e-07 
12/03/2021 00:57:05 - INFO - volta.train_utils -   [NLVR2]: iter 101208 Ep: 18.75 loss 0.009 score 0.229 lr 1.74705e-07 
12/03/2021 00:57:27 - INFO - volta.train_utils -   [NLVR2]: iter 101288 Ep: 18.76 loss 0.013 score 0.230 lr 1.72646e-07 
12/03/2021 00:57:48 - INFO - volta.train_utils -   [NLVR2]: iter 101368 Ep: 18.78 loss 0.010 score 0.232 lr 1.70588e-07 
12/03/2021 00:58:10 - INFO - volta.train_utils -   [NLVR2]: iter 101448 Ep: 18.79 loss 0.011 score 0.230 lr 1.68529e-07 
12/03/2021 00:58:32 - INFO - volta.train_utils -   [NLVR2]: iter 101528 Ep: 18.81 loss 0.011 score 0.230 lr 1.66471e-07 
12/03/2021 00:58:54 - INFO - volta.train_utils -   [NLVR2]: iter 101608 Ep: 18.82 loss 0.011 score 0.231 lr 1.64413e-07 
12/03/2021 00:59:16 - INFO - volta.train_utils -   [NLVR2]: iter 101688 Ep: 18.84 loss 0.013 score 0.230 lr 1.62354e-07 
12/03/2021 00:59:38 - INFO - volta.train_utils -   [NLVR2]: iter 101768 Ep: 18.85 loss 0.010 score 0.232 lr 1.60296e-07 
12/03/2021 01:00:00 - INFO - volta.train_utils -   [NLVR2]: iter 101848 Ep: 18.87 loss 0.009 score 0.232 lr 1.58238e-07 
12/03/2021 01:00:22 - INFO - volta.train_utils -   [NLVR2]: iter 101928 Ep: 18.88 loss 0.012 score 0.229 lr 1.56179e-07 
12/03/2021 01:00:44 - INFO - volta.train_utils -   [NLVR2]: iter 102008 Ep: 18.90 loss 0.008 score 0.233 lr 1.54121e-07 
12/03/2021 01:01:06 - INFO - volta.train_utils -   [NLVR2]: iter 102088 Ep: 18.91 loss 0.014 score 0.230 lr 1.52062e-07 
12/03/2021 01:01:28 - INFO - volta.train_utils -   [NLVR2]: iter 102168 Ep: 18.93 loss 0.011 score 0.232 lr 1.50004e-07 
12/03/2021 01:01:50 - INFO - volta.train_utils -   [NLVR2]: iter 102248 Ep: 18.94 loss 0.011 score 0.232 lr 1.47946e-07 
12/03/2021 01:02:12 - INFO - volta.train_utils -   [NLVR2]: iter 102328 Ep: 18.96 loss 0.011 score 0.231 lr 1.45887e-07 
12/03/2021 01:02:34 - INFO - volta.train_utils -   [NLVR2]: iter 102408 Ep: 18.97 loss 0.010 score 0.237 lr 1.43829e-07 
12/03/2021 01:02:56 - INFO - volta.train_utils -   [NLVR2]: iter 102488 Ep: 18.99 loss 0.013 score 0.230 lr 1.41771e-07 
12/03/2021 01:03:51 - INFO - volta.train_utils -   Eval task TASK12 on iteration 102524 
12/03/2021 01:03:51 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.038 score 69.022 
Epoch:  95%|█████████▌| 19/20 [8:07:16<25:26, 1526.07s/it]12/03/2021 01:04:13 - INFO - volta.train_utils -   [NLVR2]: iter 102604 Ep: 19.01 loss 0.012 score 0.233 lr 1.39249e-07 
12/03/2021 01:04:35 - INFO - volta.train_utils -   [NLVR2]: iter 102684 Ep: 19.02 loss 0.010 score 0.231 lr 1.36728e-07 
12/03/2021 01:04:57 - INFO - volta.train_utils -   [NLVR2]: iter 102764 Ep: 19.04 loss 0.014 score 0.229 lr 1.34669e-07 
12/03/2021 01:05:19 - INFO - volta.train_utils -   [NLVR2]: iter 102844 Ep: 19.05 loss 0.012 score 0.230 lr 1.32611e-07 
12/03/2021 01:05:41 - INFO - volta.train_utils -   [NLVR2]: iter 102924 Ep: 19.07 loss 0.014 score 0.232 lr 1.30552e-07 
12/03/2021 01:06:03 - INFO - volta.train_utils -   [NLVR2]: iter 103004 Ep: 19.08 loss 0.015 score 0.227 lr 1.28494e-07 
12/03/2021 01:06:25 - INFO - volta.train_utils -   [NLVR2]: iter 103084 Ep: 19.10 loss 0.011 score 0.229 lr 1.26436e-07 
12/03/2021 01:06:47 - INFO - volta.train_utils -   [NLVR2]: iter 103164 Ep: 19.11 loss 0.013 score 0.229 lr 1.24377e-07 
12/03/2021 01:07:09 - INFO - volta.train_utils -   [NLVR2]: iter 103244 Ep: 19.13 loss 0.010 score 0.230 lr 1.22319e-07 
12/03/2021 01:07:30 - INFO - volta.train_utils -   [NLVR2]: iter 103324 Ep: 19.14 loss 0.012 score 0.229 lr 1.20261e-07 
12/03/2021 01:07:52 - INFO - volta.train_utils -   [NLVR2]: iter 103404 Ep: 19.16 loss 0.013 score 0.230 lr 1.18202e-07 
12/03/2021 01:08:14 - INFO - volta.train_utils -   [NLVR2]: iter 103484 Ep: 19.17 loss 0.011 score 0.229 lr 1.16144e-07 
12/03/2021 01:08:36 - INFO - volta.train_utils -   [NLVR2]: iter 103564 Ep: 19.19 loss 0.010 score 0.231 lr 1.14085e-07 
12/03/2021 01:08:58 - INFO - volta.train_utils -   [NLVR2]: iter 103644 Ep: 19.20 loss 0.010 score 0.229 lr 1.12027e-07 
12/03/2021 01:09:20 - INFO - volta.train_utils -   [NLVR2]: iter 103724 Ep: 19.22 loss 0.012 score 0.234 lr 1.09969e-07 
12/03/2021 01:09:42 - INFO - volta.train_utils -   [NLVR2]: iter 103804 Ep: 19.23 loss 0.013 score 0.227 lr 1.0791e-07 
12/03/2021 01:10:04 - INFO - volta.train_utils -   [NLVR2]: iter 103884 Ep: 19.24 loss 0.013 score 0.229 lr 1.05852e-07 
12/03/2021 01:10:26 - INFO - volta.train_utils -   [NLVR2]: iter 103964 Ep: 19.26 loss 0.012 score 0.230 lr 1.03794e-07 
12/03/2021 01:10:48 - INFO - volta.train_utils -   [NLVR2]: iter 104044 Ep: 19.27 loss 0.011 score 0.231 lr 1.01735e-07 
12/03/2021 01:11:10 - INFO - volta.train_utils -   [NLVR2]: iter 104124 Ep: 19.29 loss 0.012 score 0.231 lr 9.96768e-08 
12/03/2021 01:11:32 - INFO - volta.train_utils -   [NLVR2]: iter 104204 Ep: 19.30 loss 0.011 score 0.227 lr 9.76185e-08 
12/03/2021 01:11:53 - INFO - volta.train_utils -   [NLVR2]: iter 104284 Ep: 19.32 loss 0.012 score 0.230 lr 9.55601e-08 
12/03/2021 01:12:15 - INFO - volta.train_utils -   [NLVR2]: iter 104364 Ep: 19.33 loss 0.012 score 0.231 lr 9.35017e-08 
12/03/2021 01:12:37 - INFO - volta.train_utils -   [NLVR2]: iter 104444 Ep: 19.35 loss 0.011 score 0.230 lr 9.14433e-08 
12/03/2021 01:12:59 - INFO - volta.train_utils -   [NLVR2]: iter 104524 Ep: 19.36 loss 0.012 score 0.229 lr 8.9385e-08 
12/03/2021 01:13:20 - INFO - volta.train_utils -   [NLVR2]: iter 104604 Ep: 19.38 loss 0.011 score 0.230 lr 8.73266e-08 
12/03/2021 01:13:42 - INFO - volta.train_utils -   [NLVR2]: iter 104684 Ep: 19.39 loss 0.012 score 0.232 lr 8.52682e-08 
12/03/2021 01:14:04 - INFO - volta.train_utils -   [NLVR2]: iter 104764 Ep: 19.41 loss 0.012 score 0.229 lr 8.32098e-08 
12/03/2021 01:14:26 - INFO - volta.train_utils -   [NLVR2]: iter 104844 Ep: 19.42 loss 0.013 score 0.229 lr 8.11515e-08 
12/03/2021 01:14:47 - INFO - volta.train_utils -   [NLVR2]: iter 104924 Ep: 19.44 loss 0.010 score 0.233 lr 7.90931e-08 
12/03/2021 01:15:09 - INFO - volta.train_utils -   [NLVR2]: iter 105004 Ep: 19.45 loss 0.009 score 0.231 lr 7.70347e-08 
12/03/2021 01:15:31 - INFO - volta.train_utils -   [NLVR2]: iter 105084 Ep: 19.47 loss 0.013 score 0.227 lr 7.49763e-08 
12/03/2021 01:15:53 - INFO - volta.train_utils -   [NLVR2]: iter 105164 Ep: 19.48 loss 0.012 score 0.232 lr 7.2918e-08 
12/03/2021 01:16:15 - INFO - volta.train_utils -   [NLVR2]: iter 105244 Ep: 19.50 loss 0.014 score 0.229 lr 7.08596e-08 
12/03/2021 01:16:37 - INFO - volta.train_utils -   [NLVR2]: iter 105324 Ep: 19.51 loss 0.010 score 0.231 lr 6.88012e-08 
12/03/2021 01:16:59 - INFO - volta.train_utils -   [NLVR2]: iter 105404 Ep: 19.53 loss 0.010 score 0.229 lr 6.67428e-08 
12/03/2021 01:17:21 - INFO - volta.train_utils -   [NLVR2]: iter 105484 Ep: 19.54 loss 0.016 score 0.229 lr 6.46845e-08 
12/03/2021 01:17:43 - INFO - volta.train_utils -   [NLVR2]: iter 105564 Ep: 19.56 loss 0.011 score 0.232 lr 6.26261e-08 
12/03/2021 01:18:05 - INFO - volta.train_utils -   [NLVR2]: iter 105644 Ep: 19.57 loss 0.011 score 0.233 lr 6.05677e-08 
12/03/2021 01:18:27 - INFO - volta.train_utils -   [NLVR2]: iter 105724 Ep: 19.59 loss 0.011 score 0.229 lr 5.85093e-08 
12/03/2021 01:18:49 - INFO - volta.train_utils -   [NLVR2]: iter 105804 Ep: 19.60 loss 0.013 score 0.229 lr 5.64509e-08 
12/03/2021 01:19:11 - INFO - volta.train_utils -   [NLVR2]: iter 105884 Ep: 19.62 loss 0.011 score 0.231 lr 5.43926e-08 
12/03/2021 01:19:33 - INFO - volta.train_utils -   [NLVR2]: iter 105964 Ep: 19.63 loss 0.013 score 0.230 lr 5.23342e-08 
12/03/2021 01:19:55 - INFO - volta.train_utils -   [NLVR2]: iter 106044 Ep: 19.65 loss 0.013 score 0.231 lr 5.02758e-08 
12/03/2021 01:20:17 - INFO - volta.train_utils -   [NLVR2]: iter 106124 Ep: 19.66 loss 0.014 score 0.227 lr 4.82174e-08 
12/03/2021 01:20:39 - INFO - volta.train_utils -   [NLVR2]: iter 106204 Ep: 19.67 loss 0.009 score 0.230 lr 4.61591e-08 
12/03/2021 01:21:01 - INFO - volta.train_utils -   [NLVR2]: iter 106284 Ep: 19.69 loss 0.009 score 0.232 lr 4.41007e-08 
12/03/2021 01:21:23 - INFO - volta.train_utils -   [NLVR2]: iter 106364 Ep: 19.70 loss 0.013 score 0.226 lr 4.20423e-08 
12/03/2021 01:21:45 - INFO - volta.train_utils -   [NLVR2]: iter 106444 Ep: 19.72 loss 0.010 score 0.229 lr 3.99839e-08 
12/03/2021 01:22:07 - INFO - volta.train_utils -   [NLVR2]: iter 106524 Ep: 19.73 loss 0.011 score 0.231 lr 3.79256e-08 
12/03/2021 01:22:29 - INFO - volta.train_utils -   [NLVR2]: iter 106604 Ep: 19.75 loss 0.012 score 0.232 lr 3.58672e-08 
12/03/2021 01:22:51 - INFO - volta.train_utils -   [NLVR2]: iter 106684 Ep: 19.76 loss 0.011 score 0.229 lr 3.38088e-08 
12/03/2021 01:23:12 - INFO - volta.train_utils -   [NLVR2]: iter 106764 Ep: 19.78 loss 0.012 score 0.228 lr 3.17504e-08 
12/03/2021 01:23:34 - INFO - volta.train_utils -   [NLVR2]: iter 106844 Ep: 19.79 loss 0.013 score 0.229 lr 2.96921e-08 
12/03/2021 01:23:56 - INFO - volta.train_utils -   [NLVR2]: iter 106924 Ep: 19.81 loss 0.010 score 0.233 lr 2.76337e-08 
12/03/2021 01:24:18 - INFO - volta.train_utils -   [NLVR2]: iter 107004 Ep: 19.82 loss 0.012 score 0.233 lr 2.55753e-08 
12/03/2021 01:24:40 - INFO - volta.train_utils -   [NLVR2]: iter 107084 Ep: 19.84 loss 0.011 score 0.231 lr 2.35169e-08 
12/03/2021 01:25:02 - INFO - volta.train_utils -   [NLVR2]: iter 107164 Ep: 19.85 loss 0.010 score 0.230 lr 2.14586e-08 
12/03/2021 01:25:24 - INFO - volta.train_utils -   [NLVR2]: iter 107244 Ep: 19.87 loss 0.010 score 0.233 lr 1.94002e-08 
12/03/2021 01:25:46 - INFO - volta.train_utils -   [NLVR2]: iter 107324 Ep: 19.88 loss 0.012 score 0.231 lr 1.73418e-08 
12/03/2021 01:26:08 - INFO - volta.train_utils -   [NLVR2]: iter 107404 Ep: 19.90 loss 0.011 score 0.233 lr 1.52834e-08 
12/03/2021 01:26:30 - INFO - volta.train_utils -   [NLVR2]: iter 107484 Ep: 19.91 loss 0.011 score 0.230 lr 1.32251e-08 
12/03/2021 01:26:51 - INFO - volta.train_utils -   [NLVR2]: iter 107564 Ep: 19.93 loss 0.010 score 0.233 lr 1.11667e-08 
12/03/2021 01:27:14 - INFO - volta.train_utils -   [NLVR2]: iter 107644 Ep: 19.94 loss 0.012 score 0.231 lr 9.10831e-09 
12/03/2021 01:27:35 - INFO - volta.train_utils -   [NLVR2]: iter 107724 Ep: 19.96 loss 0.013 score 0.229 lr 7.04994e-09 
12/03/2021 01:27:57 - INFO - volta.train_utils -   [NLVR2]: iter 107804 Ep: 19.97 loss 0.010 score 0.232 lr 4.99156e-09 
12/03/2021 01:28:19 - INFO - volta.train_utils -   [NLVR2]: iter 107884 Ep: 19.99 loss 0.011 score 0.230 lr 2.93319e-09 
12/03/2021 01:29:15 - INFO - volta.train_utils -   Eval task TASK12 on iteration 107920 
12/03/2021 01:29:15 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.033 score 68.850 
Epoch: 100%|██████████| 20/20 [8:32:40<00:00, 1525.45s/it]
