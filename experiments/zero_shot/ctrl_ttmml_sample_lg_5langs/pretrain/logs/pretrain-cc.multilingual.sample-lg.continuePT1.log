train_batch_size:256
strategy:sample_lg
WARNING:tensorflow:From /home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

04/19/2022 10:29:45 - INFO - __main__ -   device: cuda n_gpu: 2, distributed training: False
Loading from /science/image/nlp-datasets/emanuele/data/conceptual_captions/resnet101_faster_rcnn_genome_imgfeats/volta/training_feat_all.lmdb
[32m[0419 10:29:51 @format.py:92][0m Found 2777649 entries in /science/image/nlp-datasets/emanuele/data/conceptual_captions/resnet101_faster_rcnn_genome_imgfeats/volta/training_feat_all.lmdb
[32m[0419 10:30:40 @parallel.py:309][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0419 10:30:40 @argtools.py:146][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0419 10:30:40 @argtools.py:146][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
04/19/2022 10:30:41 - INFO - volta.train_utils -   logging file at: /science/image/nlp-datasets/tt-mml/logs/pretrain/ctrl_ttmml_sample_lg/ctrl_xuniter_base/train_batch_size_256/conceptual_captions-sample_lg/ctrl_xuniter_base
04/19/2022 10:30:42 - INFO - volta.utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin from cache at /home/mwp141/.pytorch_pretrained_bert/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267
04/19/2022 10:30:56 - INFO - volta.utils -   
04/19/2022 10:30:57 - INFO - volta.utils -   Weights of BertForVLPreTraining not initialized from pretrained model: ['bert.embeddings.image_embeddings.weight', 'bert.embeddings.image_embeddings.bias', 'bert.embeddings.image_location_embeddings.weight', 'bert.embeddings.image_location_embeddings.bias', 'bert.embeddings.image_token_type_embeddings.weight', 'bert.embeddings.image_layer_norm.weight', 'bert.embeddings.image_layer_norm.bias', 'bert.embeddings.image_location_layer_norm.weight', 'bert.embeddings.image_location_layer_norm.bias', 'bert.embeddings.v_LayerNorm.weight', 'bert.embeddings.v_LayerNorm.bias', 'bert.encoder.layer.0.attention_self.v_query.weight', 'bert.encoder.layer.0.attention_self.v_query.bias', 'bert.encoder.layer.0.attention_self.v_key.weight', 'bert.encoder.layer.0.attention_self.v_key.bias', 'bert.encoder.layer.0.attention_self.v_value.weight', 'bert.encoder.layer.0.attention_self.v_value.bias', 'bert.encoder.layer.0.attention_output.v_dense.weight', 'bert.encoder.layer.0.attention_output.v_dense.bias', 'bert.encoder.layer.0.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.0.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.1.intermediate.v_dense.weight', 'bert.encoder.layer.1.intermediate.v_dense.bias', 'bert.encoder.layer.1.output.v_dense.weight', 'bert.encoder.layer.1.output.v_dense.bias', 'bert.encoder.layer.1.output.v_LayerNorm.weight', 'bert.encoder.layer.1.output.v_LayerNorm.bias', 'bert.encoder.layer.2.attention_self.v_query.weight', 'bert.encoder.layer.2.attention_self.v_query.bias', 'bert.encoder.layer.2.attention_self.v_key.weight', 'bert.encoder.layer.2.attention_self.v_key.bias', 'bert.encoder.layer.2.attention_self.v_value.weight', 'bert.encoder.layer.2.attention_self.v_value.bias', 'bert.encoder.layer.2.attention_output.v_dense.weight', 'bert.encoder.layer.2.attention_output.v_dense.bias', 'bert.encoder.layer.2.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.2.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.3.intermediate.v_dense.weight', 'bert.encoder.layer.3.intermediate.v_dense.bias', 'bert.encoder.layer.3.output.v_dense.weight', 'bert.encoder.layer.3.output.v_dense.bias', 'bert.encoder.layer.3.output.v_LayerNorm.weight', 'bert.encoder.layer.3.output.v_LayerNorm.bias', 'bert.encoder.layer.4.attention_self.v_query.weight', 'bert.encoder.layer.4.attention_self.v_query.bias', 'bert.encoder.layer.4.attention_self.v_key.weight', 'bert.encoder.layer.4.attention_self.v_key.bias', 'bert.encoder.layer.4.attention_self.v_value.weight', 'bert.encoder.layer.4.attention_self.v_value.bias', 'bert.encoder.layer.4.attention_output.v_dense.weight', 'bert.encoder.layer.4.attention_output.v_dense.bias', 'bert.encoder.layer.4.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.4.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.5.intermediate.v_dense.weight', 'bert.encoder.layer.5.intermediate.v_dense.bias', 'bert.encoder.layer.5.output.v_dense.weight', 'bert.encoder.layer.5.output.v_dense.bias', 'bert.encoder.layer.5.output.v_LayerNorm.weight', 'bert.encoder.layer.5.output.v_LayerNorm.bias', 'bert.encoder.layer.6.attention_self.v_query.weight', 'bert.encoder.layer.6.attention_self.v_query.bias', 'bert.encoder.layer.6.attention_self.v_key.weight', 'bert.encoder.layer.6.attention_self.v_key.bias', 'bert.encoder.layer.6.attention_self.v_value.weight', 'bert.encoder.layer.6.attention_self.v_value.bias', 'bert.encoder.layer.6.attention_output.v_dense.weight', 'bert.encoder.layer.6.attention_output.v_dense.bias', 'bert.encoder.layer.6.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.6.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.7.intermediate.v_dense.weight', 'bert.encoder.layer.7.intermediate.v_dense.bias', 'bert.encoder.layer.7.output.v_dense.weight', 'bert.encoder.layer.7.output.v_dense.bias', 'bert.encoder.layer.7.output.v_LayerNorm.weight', 'bert.encoder.layer.7.output.v_LayerNorm.bias', 'bert.encoder.layer.8.attention_self.v_query.weight', 'bert.encoder.layer.8.attention_self.v_query.bias', 'bert.encoder.layer.8.attention_self.v_key.weight', 'bert.encoder.layer.8.attention_self.v_key.bias', 'bert.encoder.layer.8.attention_self.v_value.weight', 'bert.encoder.layer.8.attention_self.v_value.bias', 'bert.encoder.layer.8.attention_output.v_dense.weight', 'bert.encoder.layer.8.attention_output.v_dense.bias', 'bert.encoder.layer.8.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.8.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.9.intermediate.v_dense.weight', 'bert.encoder.layer.9.intermediate.v_dense.bias', 'bert.encoder.layer.9.output.v_dense.weight', 'bert.encoder.layer.9.output.v_dense.bias', 'bert.encoder.layer.9.output.v_LayerNorm.weight', 'bert.encoder.layer.9.output.v_LayerNorm.bias', 'bert.encoder.layer.10.attention_self.v_query.weight', 'bert.encoder.layer.10.attention_self.v_query.bias', 'bert.encoder.layer.10.attention_self.v_key.weight', 'bert.encoder.layer.10.attention_self.v_key.bias', 'bert.encoder.layer.10.attention_self.v_value.weight', 'bert.encoder.layer.10.attention_self.v_value.bias', 'bert.encoder.layer.10.attention_output.v_dense.weight', 'bert.encoder.layer.10.attention_output.v_dense.bias', 'bert.encoder.layer.10.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.10.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.11.intermediate.v_dense.weight', 'bert.encoder.layer.11.intermediate.v_dense.bias', 'bert.encoder.layer.11.output.v_dense.weight', 'bert.encoder.layer.11.output.v_dense.bias', 'bert.encoder.layer.11.output.v_LayerNorm.weight', 'bert.encoder.layer.11.output.v_LayerNorm.bias', 'bert.encoder.layer.12.attention_self.v_query.weight', 'bert.encoder.layer.12.attention_self.v_query.bias', 'bert.encoder.layer.12.attention_self.v_key.weight', 'bert.encoder.layer.12.attention_self.v_key.bias', 'bert.encoder.layer.12.attention_self.v_value.weight', 'bert.encoder.layer.12.attention_self.v_value.bias', 'bert.encoder.layer.12.attention_output.v_dense.weight', 'bert.encoder.layer.12.attention_output.v_dense.bias', 'bert.encoder.layer.12.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.12.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.13.intermediate.v_dense.weight', 'bert.encoder.layer.13.intermediate.v_dense.bias', 'bert.encoder.layer.13.output.v_dense.weight', 'bert.encoder.layer.13.output.v_dense.bias', 'bert.encoder.layer.13.output.v_LayerNorm.weight', 'bert.encoder.layer.13.output.v_LayerNorm.bias', 'bert.encoder.layer.14.attention_self.v_query.weight', 'bert.encoder.layer.14.attention_self.v_query.bias', 'bert.encoder.layer.14.attention_self.v_key.weight', 'bert.encoder.layer.14.attention_self.v_key.bias', 'bert.encoder.layer.14.attention_self.v_value.weight', 'bert.encoder.layer.14.attention_self.v_value.bias', 'bert.encoder.layer.14.attention_output.v_dense.weight', 'bert.encoder.layer.14.attention_output.v_dense.bias', 'bert.encoder.layer.14.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.14.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.15.intermediate.v_dense.weight', 'bert.encoder.layer.15.intermediate.v_dense.bias', 'bert.encoder.layer.15.output.v_dense.weight', 'bert.encoder.layer.15.output.v_dense.bias', 'bert.encoder.layer.15.output.v_LayerNorm.weight', 'bert.encoder.layer.15.output.v_LayerNorm.bias', 'bert.encoder.layer.16.attention_self.v_query.weight', 'bert.encoder.layer.16.attention_self.v_query.bias', 'bert.encoder.layer.16.attention_self.v_key.weight', 'bert.encoder.layer.16.attention_self.v_key.bias', 'bert.encoder.layer.16.attention_self.v_value.weight', 'bert.encoder.layer.16.attention_self.v_value.bias', 'bert.encoder.layer.16.attention_output.v_dense.weight', 'bert.encoder.layer.16.attention_output.v_dense.bias', 'bert.encoder.layer.16.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.16.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.17.intermediate.v_dense.weight', 'bert.encoder.layer.17.intermediate.v_dense.bias', 'bert.encoder.layer.17.output.v_dense.weight', 'bert.encoder.layer.17.output.v_dense.bias', 'bert.encoder.layer.17.output.v_LayerNorm.weight', 'bert.encoder.layer.17.output.v_LayerNorm.bias', 'bert.encoder.layer.18.attention_self.v_query.weight', 'bert.encoder.layer.18.attention_self.v_query.bias', 'bert.encoder.layer.18.attention_self.v_key.weight', 'bert.encoder.layer.18.attention_self.v_key.bias', 'bert.encoder.layer.18.attention_self.v_value.weight', 'bert.encoder.layer.18.attention_self.v_value.bias', 'bert.encoder.layer.18.attention_output.v_dense.weight', 'bert.encoder.layer.18.attention_output.v_dense.bias', 'bert.encoder.layer.18.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.18.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.19.intermediate.v_dense.weight', 'bert.encoder.layer.19.intermediate.v_dense.bias', 'bert.encoder.layer.19.output.v_dense.weight', 'bert.encoder.layer.19.output.v_dense.bias', 'bert.encoder.layer.19.output.v_LayerNorm.weight', 'bert.encoder.layer.19.output.v_LayerNorm.bias', 'bert.encoder.layer.20.attention_self.v_query.weight', 'bert.encoder.layer.20.attention_self.v_query.bias', 'bert.encoder.layer.20.attention_self.v_key.weight', 'bert.encoder.layer.20.attention_self.v_key.bias', 'bert.encoder.layer.20.attention_self.v_value.weight', 'bert.encoder.layer.20.attention_self.v_value.bias', 'bert.encoder.layer.20.attention_output.v_dense.weight', 'bert.encoder.layer.20.attention_output.v_dense.bias', 'bert.encoder.layer.20.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.20.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.21.intermediate.v_dense.weight', 'bert.encoder.layer.21.intermediate.v_dense.bias', 'bert.encoder.layer.21.output.v_dense.weight', 'bert.encoder.layer.21.output.v_dense.bias', 'bert.encoder.layer.21.output.v_LayerNorm.weight', 'bert.encoder.layer.21.output.v_LayerNorm.bias', 'bert.encoder.layer.22.attention_self.v_query.weight', 'bert.encoder.layer.22.attention_self.v_query.bias', 'bert.encoder.layer.22.attention_self.v_key.weight', 'bert.encoder.layer.22.attention_self.v_key.bias', 'bert.encoder.layer.22.attention_self.v_value.weight', 'bert.encoder.layer.22.attention_self.v_value.bias', 'bert.encoder.layer.22.attention_output.v_dense.weight', 'bert.encoder.layer.22.attention_output.v_dense.bias', 'bert.encoder.layer.22.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.22.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.23.intermediate.v_dense.weight', 'bert.encoder.layer.23.intermediate.v_dense.bias', 'bert.encoder.layer.23.output.v_dense.weight', 'bert.encoder.layer.23.output.v_dense.bias', 'bert.encoder.layer.23.output.v_LayerNorm.weight', 'bert.encoder.layer.23.output.v_LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
04/19/2022 10:30:57 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLPreTraining: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
04/19/2022 10:31:37 - INFO - __main__ -   ** ** * Saving model * ** ** 
04/19/2022 10:32:03 - INFO - __main__ -   >> Parameters:
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |Name                                                              |Dtype            |Shape            |#Params      |Trainable|
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                     |torch.float32    |(250002, 768)    |192001536    |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                 |torch.float32    |(514, 768)       |394752       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight               |torch.float32    |(1, 768)         |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)         |3840         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_token_type_embeddings.weight         |torch.float32    |(1, 768)         |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.predictions.bias                                       |torch.float32    |(250002,)        |250002       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                     |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                   |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                             |torch.float32    |(2, 1024)        |2048         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                               |torch.float32    |(2,)             |2            |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                  |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.weight                 |torch.float32    |(1601, 768)      |1229568      |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.bias                   |torch.float32    |(1601,)          |1601         |True    |
04/19/2022 10:32:03 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:32:03 - INFO - __main__ -   >> # TrainableParams:       	283.28	M
04/19/2022 10:32:03 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
04/19/2022 10:32:03 - INFO - __main__ -   >> # TotalParams:           	283.28	M
04/19/2022 10:32:03 - INFO - __main__ -   ***** Running training *****
04/19/2022 10:32:03 - INFO - __main__ -     Num examples = 2777649
04/19/2022 10:32:03 - INFO - __main__ -     Batch size = 64
04/19/2022 10:32:03 - INFO - __main__ -     Num steps = 217000
/home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
04/19/2022 10:33:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240080 Ep: 5.53 masked_t 0.440 masked_v 0.071 NSP 0.045 lr 1.90389e-05
04/19/2022 10:34:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240160 Ep: 5.53 masked_t 0.428 masked_v 0.070 NSP 0.052 lr 1.90358e-05
04/19/2022 10:34:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240240 Ep: 5.54 masked_t 0.421 masked_v 0.064 NSP 0.041 lr 1.90334e-05
04/19/2022 10:35:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240320 Ep: 5.54 masked_t 0.458 masked_v 0.065 NSP 0.046 lr 1.9031e-05
04/19/2022 10:36:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240400 Ep: 5.54 masked_t 0.484 masked_v 0.070 NSP 0.041 lr 1.90286e-05
04/19/2022 10:37:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240480 Ep: 5.54 masked_t 0.423 masked_v 0.069 NSP 0.045 lr 1.90261e-05
04/19/2022 10:38:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240560 Ep: 5.54 masked_t 0.430 masked_v 0.066 NSP 0.044 lr 1.90237e-05
04/19/2022 10:39:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240640 Ep: 5.54 masked_t 0.441 masked_v 0.067 NSP 0.041 lr 1.90213e-05
04/19/2022 10:40:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240720 Ep: 5.55 masked_t 0.434 masked_v 0.071 NSP 0.043 lr 1.90189e-05
04/19/2022 10:41:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240800 Ep: 5.55 masked_t 0.466 masked_v 0.065 NSP 0.045 lr 1.90164e-05
04/19/2022 10:42:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240880 Ep: 5.55 masked_t 0.444 masked_v 0.071 NSP 0.039 lr 1.9014e-05
04/19/2022 10:43:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240960 Ep: 5.55 masked_t 0.424 masked_v 0.070 NSP 0.040 lr 1.90116e-05
04/19/2022 10:44:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241040 Ep: 5.55 masked_t 0.457 masked_v 0.066 NSP 0.046 lr 1.90092e-05
04/19/2022 10:45:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241120 Ep: 5.56 masked_t 0.421 masked_v 0.070 NSP 0.043 lr 1.90067e-05
04/19/2022 10:46:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241200 Ep: 5.56 masked_t 0.413 masked_v 0.068 NSP 0.037 lr 1.90043e-05
04/19/2022 10:47:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241280 Ep: 5.56 masked_t 0.430 masked_v 0.070 NSP 0.043 lr 1.90019e-05
04/19/2022 10:48:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241360 Ep: 5.56 masked_t 0.404 masked_v 0.066 NSP 0.052 lr 1.89995e-05
04/19/2022 10:49:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241440 Ep: 5.56 masked_t 0.427 masked_v 0.064 NSP 0.040 lr 1.8997e-05
04/19/2022 10:50:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241520 Ep: 5.56 masked_t 0.435 masked_v 0.069 NSP 0.044 lr 1.89946e-05
04/19/2022 10:51:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241600 Ep: 5.57 masked_t 0.472 masked_v 0.067 NSP 0.039 lr 1.89922e-05
04/19/2022 10:52:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241680 Ep: 5.57 masked_t 0.393 masked_v 0.071 NSP 0.047 lr 1.89898e-05
04/19/2022 10:53:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241760 Ep: 5.57 masked_t 0.443 masked_v 0.069 NSP 0.041 lr 1.89873e-05
04/19/2022 10:54:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241840 Ep: 5.57 masked_t 0.456 masked_v 0.064 NSP 0.048 lr 1.89849e-05
04/19/2022 10:55:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 241920 Ep: 5.57 masked_t 0.431 masked_v 0.070 NSP 0.048 lr 1.89825e-05
04/19/2022 10:56:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242000 Ep: 5.58 masked_t 0.466 masked_v 0.070 NSP 0.040 lr 1.89801e-05
04/19/2022 10:57:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242080 Ep: 5.58 masked_t 0.446 masked_v 0.071 NSP 0.038 lr 1.89776e-05
04/19/2022 10:58:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242160 Ep: 5.58 masked_t 0.410 masked_v 0.066 NSP 0.037 lr 1.89752e-05
04/19/2022 10:58:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242240 Ep: 5.58 masked_t 0.402 masked_v 0.070 NSP 0.043 lr 1.89728e-05
04/19/2022 10:59:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242320 Ep: 5.58 masked_t 0.426 masked_v 0.064 NSP 0.042 lr 1.89703e-05
04/19/2022 11:00:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242400 Ep: 5.59 masked_t 0.440 masked_v 0.068 NSP 0.046 lr 1.89679e-05
04/19/2022 11:01:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242480 Ep: 5.59 masked_t 0.455 masked_v 0.070 NSP 0.043 lr 1.89655e-05
04/19/2022 11:02:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242560 Ep: 5.59 masked_t 0.388 masked_v 0.068 NSP 0.046 lr 1.89631e-05
04/19/2022 11:03:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242640 Ep: 5.59 masked_t 0.459 masked_v 0.066 NSP 0.044 lr 1.89606e-05
04/19/2022 11:04:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242720 Ep: 5.59 masked_t 0.408 masked_v 0.068 NSP 0.042 lr 1.89582e-05
04/19/2022 11:05:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242800 Ep: 5.59 masked_t 0.412 masked_v 0.066 NSP 0.040 lr 1.89558e-05
04/19/2022 11:06:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242880 Ep: 5.60 masked_t 0.424 masked_v 0.070 NSP 0.044 lr 1.89534e-05
04/19/2022 11:07:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 242960 Ep: 5.60 masked_t 0.410 masked_v 0.064 NSP 0.042 lr 1.89509e-05
04/19/2022 11:08:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243040 Ep: 5.60 masked_t 0.429 masked_v 0.066 NSP 0.042 lr 1.89485e-05
04/19/2022 11:09:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243120 Ep: 5.60 masked_t 0.441 masked_v 0.070 NSP 0.048 lr 1.89461e-05
04/19/2022 11:10:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243200 Ep: 5.60 masked_t 0.456 masked_v 0.068 NSP 0.044 lr 1.89437e-05
04/19/2022 11:11:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243280 Ep: 5.61 masked_t 0.418 masked_v 0.070 NSP 0.047 lr 1.89412e-05
04/19/2022 11:12:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243360 Ep: 5.61 masked_t 0.424 masked_v 0.070 NSP 0.047 lr 1.89388e-05
04/19/2022 11:13:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243440 Ep: 5.61 masked_t 0.434 masked_v 0.068 NSP 0.041 lr 1.89364e-05
04/19/2022 11:14:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243520 Ep: 5.61 masked_t 0.378 masked_v 0.066 NSP 0.041 lr 1.8934e-05
04/19/2022 11:15:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243600 Ep: 5.61 masked_t 0.427 masked_v 0.067 NSP 0.043 lr 1.89315e-05
04/19/2022 11:16:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243680 Ep: 5.61 masked_t 0.429 masked_v 0.069 NSP 0.044 lr 1.89291e-05
04/19/2022 11:17:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243760 Ep: 5.62 masked_t 0.418 masked_v 0.066 NSP 0.045 lr 1.89267e-05
04/19/2022 11:18:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243840 Ep: 5.62 masked_t 0.432 masked_v 0.067 NSP 0.039 lr 1.89243e-05
04/19/2022 11:19:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 243920 Ep: 5.62 masked_t 0.441 masked_v 0.066 NSP 0.047 lr 1.89218e-05
04/19/2022 11:20:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244000 Ep: 5.62 masked_t 0.429 masked_v 0.072 NSP 0.043 lr 1.89194e-05
04/19/2022 11:21:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244080 Ep: 5.62 masked_t 0.409 masked_v 0.066 NSP 0.047 lr 1.8917e-05
04/19/2022 11:22:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244160 Ep: 5.63 masked_t 0.433 masked_v 0.070 NSP 0.046 lr 1.89146e-05
04/19/2022 11:23:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244240 Ep: 5.63 masked_t 0.416 masked_v 0.071 NSP 0.047 lr 1.89121e-05
04/19/2022 11:24:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244320 Ep: 5.63 masked_t 0.443 masked_v 0.070 NSP 0.040 lr 1.89097e-05
04/19/2022 11:24:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244400 Ep: 5.63 masked_t 0.439 masked_v 0.069 NSP 0.051 lr 1.89073e-05
04/19/2022 11:25:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244480 Ep: 5.63 masked_t 0.425 masked_v 0.072 NSP 0.042 lr 1.89049e-05
04/19/2022 11:26:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244560 Ep: 5.63 masked_t 0.430 masked_v 0.068 NSP 0.041 lr 1.89024e-05
04/19/2022 11:27:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244640 Ep: 5.64 masked_t 0.416 masked_v 0.063 NSP 0.041 lr 1.89e-05
04/19/2022 11:28:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244720 Ep: 5.64 masked_t 0.459 masked_v 0.070 NSP 0.045 lr 1.88976e-05
04/19/2022 11:29:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244800 Ep: 5.64 masked_t 0.439 masked_v 0.071 NSP 0.037 lr 1.88952e-05
04/19/2022 11:30:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244880 Ep: 5.64 masked_t 0.478 masked_v 0.067 NSP 0.050 lr 1.88927e-05
04/19/2022 11:31:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 244960 Ep: 5.64 masked_t 0.437 masked_v 0.068 NSP 0.047 lr 1.88903e-05
04/19/2022 11:32:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245040 Ep: 5.65 masked_t 0.443 masked_v 0.068 NSP 0.043 lr 1.88879e-05
04/19/2022 11:33:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245120 Ep: 5.65 masked_t 0.425 masked_v 0.067 NSP 0.041 lr 1.88855e-05
04/19/2022 11:34:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245200 Ep: 5.65 masked_t 0.446 masked_v 0.068 NSP 0.046 lr 1.8883e-05
04/19/2022 11:35:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245280 Ep: 5.65 masked_t 0.424 masked_v 0.070 NSP 0.042 lr 1.88806e-05
04/19/2022 11:36:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245360 Ep: 5.65 masked_t 0.422 masked_v 0.067 NSP 0.051 lr 1.88782e-05
04/19/2022 11:37:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245440 Ep: 5.66 masked_t 0.433 masked_v 0.074 NSP 0.049 lr 1.88758e-05
04/19/2022 11:38:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245520 Ep: 5.66 masked_t 0.453 masked_v 0.068 NSP 0.047 lr 1.88733e-05
04/19/2022 11:39:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245600 Ep: 5.66 masked_t 0.423 masked_v 0.067 NSP 0.043 lr 1.88709e-05
04/19/2022 11:40:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245680 Ep: 5.66 masked_t 0.437 masked_v 0.068 NSP 0.046 lr 1.88685e-05
04/19/2022 11:41:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245760 Ep: 5.66 masked_t 0.434 masked_v 0.065 NSP 0.046 lr 1.88661e-05
04/19/2022 11:42:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245840 Ep: 5.66 masked_t 0.419 masked_v 0.071 NSP 0.048 lr 1.88636e-05
04/19/2022 11:43:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 245920 Ep: 5.67 masked_t 0.458 masked_v 0.071 NSP 0.047 lr 1.88612e-05
04/19/2022 11:44:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246000 Ep: 5.67 masked_t 0.425 masked_v 0.067 NSP 0.047 lr 1.88588e-05
04/19/2022 11:45:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246080 Ep: 5.67 masked_t 0.457 masked_v 0.070 NSP 0.040 lr 1.88564e-05
04/19/2022 11:46:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246160 Ep: 5.67 masked_t 0.390 masked_v 0.069 NSP 0.044 lr 1.88539e-05
04/19/2022 11:47:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246240 Ep: 5.67 masked_t 0.439 masked_v 0.067 NSP 0.048 lr 1.88515e-05
04/19/2022 11:48:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246320 Ep: 5.68 masked_t 0.427 masked_v 0.066 NSP 0.039 lr 1.88491e-05
04/19/2022 11:49:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246400 Ep: 5.68 masked_t 0.434 masked_v 0.068 NSP 0.058 lr 1.88467e-05
04/19/2022 11:49:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246480 Ep: 5.68 masked_t 0.429 masked_v 0.065 NSP 0.041 lr 1.88442e-05
04/19/2022 11:50:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246560 Ep: 5.68 masked_t 0.432 masked_v 0.071 NSP 0.037 lr 1.88418e-05
04/19/2022 11:51:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246640 Ep: 5.68 masked_t 0.424 masked_v 0.064 NSP 0.041 lr 1.88394e-05
04/19/2022 11:52:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246720 Ep: 5.68 masked_t 0.429 masked_v 0.068 NSP 0.043 lr 1.8837e-05
04/19/2022 11:53:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246800 Ep: 5.69 masked_t 0.464 masked_v 0.064 NSP 0.046 lr 1.88345e-05
04/19/2022 11:54:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246880 Ep: 5.69 masked_t 0.428 masked_v 0.068 NSP 0.041 lr 1.88321e-05
04/19/2022 11:55:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 246960 Ep: 5.69 masked_t 0.427 masked_v 0.067 NSP 0.042 lr 1.88297e-05
04/19/2022 11:56:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247040 Ep: 5.69 masked_t 0.451 masked_v 0.066 NSP 0.035 lr 1.88272e-05
04/19/2022 11:57:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247120 Ep: 5.69 masked_t 0.438 masked_v 0.069 NSP 0.043 lr 1.88248e-05
04/19/2022 11:58:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247200 Ep: 5.70 masked_t 0.422 masked_v 0.069 NSP 0.044 lr 1.88224e-05
04/19/2022 11:59:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247280 Ep: 5.70 masked_t 0.459 masked_v 0.068 NSP 0.044 lr 1.882e-05
04/19/2022 12:00:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247360 Ep: 5.70 masked_t 0.412 masked_v 0.067 NSP 0.042 lr 1.88175e-05
04/19/2022 12:01:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247440 Ep: 5.70 masked_t 0.435 masked_v 0.065 NSP 0.044 lr 1.88151e-05
04/19/2022 12:02:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247520 Ep: 5.70 masked_t 0.449 masked_v 0.069 NSP 0.044 lr 1.88127e-05
04/19/2022 12:03:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247600 Ep: 5.70 masked_t 0.425 masked_v 0.068 NSP 0.038 lr 1.88103e-05
04/19/2022 12:04:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247680 Ep: 5.71 masked_t 0.406 masked_v 0.067 NSP 0.041 lr 1.88078e-05
04/19/2022 12:05:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247760 Ep: 5.71 masked_t 0.425 masked_v 0.072 NSP 0.042 lr 1.88054e-05
04/19/2022 12:06:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247840 Ep: 5.71 masked_t 0.462 masked_v 0.068 NSP 0.041 lr 1.8803e-05
04/19/2022 12:07:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 247920 Ep: 5.71 masked_t 0.450 masked_v 0.067 NSP 0.051 lr 1.88006e-05
04/19/2022 12:08:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248000 Ep: 5.71 masked_t 0.430 masked_v 0.071 NSP 0.046 lr 1.87981e-05
04/19/2022 12:09:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248080 Ep: 5.72 masked_t 0.426 masked_v 0.065 NSP 0.043 lr 1.87957e-05
04/19/2022 12:10:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248160 Ep: 5.72 masked_t 0.464 masked_v 0.068 NSP 0.042 lr 1.87933e-05
04/19/2022 12:11:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248240 Ep: 5.72 masked_t 0.416 masked_v 0.068 NSP 0.044 lr 1.87909e-05
04/19/2022 12:12:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248320 Ep: 5.72 masked_t 0.432 masked_v 0.068 NSP 0.043 lr 1.87884e-05
04/19/2022 12:13:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248400 Ep: 5.72 masked_t 0.447 masked_v 0.067 NSP 0.045 lr 1.8786e-05
04/19/2022 12:14:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248480 Ep: 5.73 masked_t 0.424 masked_v 0.063 NSP 0.038 lr 1.87836e-05
04/19/2022 12:15:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248560 Ep: 5.73 masked_t 0.400 masked_v 0.070 NSP 0.040 lr 1.87812e-05
04/19/2022 12:15:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248640 Ep: 5.73 masked_t 0.447 masked_v 0.067 NSP 0.046 lr 1.87787e-05
04/19/2022 12:16:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248720 Ep: 5.73 masked_t 0.425 masked_v 0.065 NSP 0.043 lr 1.87763e-05
04/19/2022 12:17:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248800 Ep: 5.73 masked_t 0.406 masked_v 0.069 NSP 0.043 lr 1.87739e-05
04/19/2022 12:18:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248880 Ep: 5.73 masked_t 0.467 masked_v 0.069 NSP 0.041 lr 1.87715e-05
04/19/2022 12:19:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 248960 Ep: 5.74 masked_t 0.426 masked_v 0.066 NSP 0.045 lr 1.8769e-05
04/19/2022 12:20:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249040 Ep: 5.74 masked_t 0.405 masked_v 0.069 NSP 0.043 lr 1.87666e-05
04/19/2022 12:21:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249120 Ep: 5.74 masked_t 0.413 masked_v 0.069 NSP 0.044 lr 1.87642e-05
04/19/2022 12:22:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249200 Ep: 5.74 masked_t 0.428 masked_v 0.066 NSP 0.051 lr 1.87618e-05
04/19/2022 12:23:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249280 Ep: 5.74 masked_t 0.424 masked_v 0.069 NSP 0.038 lr 1.87593e-05
04/19/2022 12:24:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249360 Ep: 5.75 masked_t 0.453 masked_v 0.070 NSP 0.042 lr 1.87569e-05
04/19/2022 12:25:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249440 Ep: 5.75 masked_t 0.377 masked_v 0.063 NSP 0.044 lr 1.87545e-05
04/19/2022 12:26:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249520 Ep: 5.75 masked_t 0.439 masked_v 0.068 NSP 0.050 lr 1.87521e-05
04/19/2022 12:27:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249600 Ep: 5.75 masked_t 0.441 masked_v 0.065 NSP 0.046 lr 1.87496e-05
04/19/2022 12:28:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249680 Ep: 5.75 masked_t 0.403 masked_v 0.066 NSP 0.048 lr 1.87472e-05
04/19/2022 12:29:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249760 Ep: 5.75 masked_t 0.424 masked_v 0.070 NSP 0.043 lr 1.87448e-05
04/19/2022 12:30:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249840 Ep: 5.76 masked_t 0.439 masked_v 0.068 NSP 0.040 lr 1.87424e-05
04/19/2022 12:31:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 249920 Ep: 5.76 masked_t 0.470 masked_v 0.066 NSP 0.043 lr 1.87399e-05
04/19/2022 12:32:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250000 Ep: 5.76 masked_t 0.422 masked_v 0.070 NSP 0.044 lr 1.87375e-05
04/19/2022 12:33:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250080 Ep: 5.76 masked_t 0.450 masked_v 0.066 NSP 0.042 lr 1.87351e-05
04/19/2022 12:34:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250160 Ep: 5.76 masked_t 0.427 masked_v 0.072 NSP 0.041 lr 1.87327e-05
04/19/2022 12:35:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250240 Ep: 5.77 masked_t 0.400 masked_v 0.066 NSP 0.045 lr 1.87302e-05
04/19/2022 12:36:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250320 Ep: 5.77 masked_t 0.493 masked_v 0.071 NSP 0.045 lr 1.87278e-05
04/19/2022 12:37:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250400 Ep: 5.77 masked_t 0.422 masked_v 0.068 NSP 0.050 lr 1.87254e-05
04/19/2022 12:38:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250480 Ep: 5.77 masked_t 0.438 masked_v 0.072 NSP 0.037 lr 1.8723e-05
04/19/2022 12:39:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250560 Ep: 5.77 masked_t 0.445 masked_v 0.065 NSP 0.044 lr 1.87205e-05
04/19/2022 12:40:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250640 Ep: 5.78 masked_t 0.403 masked_v 0.066 NSP 0.045 lr 1.87181e-05
04/19/2022 12:40:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250720 Ep: 5.78 masked_t 0.416 masked_v 0.069 NSP 0.046 lr 1.87157e-05
04/19/2022 12:41:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250800 Ep: 5.78 masked_t 0.406 masked_v 0.070 NSP 0.048 lr 1.87133e-05
04/19/2022 12:42:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250880 Ep: 5.78 masked_t 0.437 masked_v 0.068 NSP 0.042 lr 1.87108e-05
04/19/2022 12:43:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 250960 Ep: 5.78 masked_t 0.398 masked_v 0.068 NSP 0.045 lr 1.87084e-05
04/19/2022 12:44:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251040 Ep: 5.78 masked_t 0.436 masked_v 0.065 NSP 0.040 lr 1.8706e-05
04/19/2022 12:45:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251120 Ep: 5.79 masked_t 0.422 masked_v 0.064 NSP 0.042 lr 1.87036e-05
04/19/2022 12:46:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251200 Ep: 5.79 masked_t 0.441 masked_v 0.069 NSP 0.050 lr 1.87011e-05
04/19/2022 12:47:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251280 Ep: 5.79 masked_t 0.494 masked_v 0.067 NSP 0.055 lr 1.86987e-05
04/19/2022 12:48:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251360 Ep: 5.79 masked_t 0.435 masked_v 0.069 NSP 0.043 lr 1.86963e-05
04/19/2022 12:49:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251440 Ep: 5.79 masked_t 0.446 masked_v 0.065 NSP 0.039 lr 1.86939e-05
04/19/2022 12:50:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251520 Ep: 5.80 masked_t 0.416 masked_v 0.070 NSP 0.043 lr 1.86914e-05
04/19/2022 12:51:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251600 Ep: 5.80 masked_t 0.446 masked_v 0.068 NSP 0.046 lr 1.8689e-05
04/19/2022 12:52:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251680 Ep: 5.80 masked_t 0.412 masked_v 0.069 NSP 0.038 lr 1.86866e-05
04/19/2022 12:53:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251760 Ep: 5.80 masked_t 0.426 masked_v 0.068 NSP 0.046 lr 1.86841e-05
04/19/2022 12:54:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251840 Ep: 5.80 masked_t 0.438 masked_v 0.066 NSP 0.043 lr 1.86817e-05
04/19/2022 12:55:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 251920 Ep: 5.80 masked_t 0.503 masked_v 0.065 NSP 0.040 lr 1.86793e-05
04/19/2022 12:56:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252000 Ep: 5.81 masked_t 0.435 masked_v 0.066 NSP 0.044 lr 1.86769e-05
04/19/2022 12:57:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252080 Ep: 5.81 masked_t 0.440 masked_v 0.068 NSP 0.039 lr 1.86744e-05
04/19/2022 12:58:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252160 Ep: 5.81 masked_t 0.448 masked_v 0.065 NSP 0.045 lr 1.8672e-05
04/19/2022 12:59:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252240 Ep: 5.81 masked_t 0.412 masked_v 0.069 NSP 0.040 lr 1.86696e-05
04/19/2022 13:00:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252320 Ep: 5.81 masked_t 0.437 masked_v 0.065 NSP 0.043 lr 1.86672e-05
04/19/2022 13:01:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252400 Ep: 5.82 masked_t 0.412 masked_v 0.066 NSP 0.042 lr 1.86647e-05
04/19/2022 13:02:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252480 Ep: 5.82 masked_t 0.415 masked_v 0.068 NSP 0.043 lr 1.86623e-05
04/19/2022 13:03:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252560 Ep: 5.82 masked_t 0.440 masked_v 0.066 NSP 0.043 lr 1.86599e-05
04/19/2022 13:04:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252640 Ep: 5.82 masked_t 0.424 masked_v 0.068 NSP 0.038 lr 1.86575e-05
04/19/2022 13:05:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252720 Ep: 5.82 masked_t 0.402 masked_v 0.067 NSP 0.043 lr 1.8655e-05
04/19/2022 13:06:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252800 Ep: 5.82 masked_t 0.394 masked_v 0.070 NSP 0.043 lr 1.86526e-05
04/19/2022 13:06:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252880 Ep: 5.83 masked_t 0.397 masked_v 0.066 NSP 0.049 lr 1.86502e-05
04/19/2022 13:07:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 252960 Ep: 5.83 masked_t 0.403 masked_v 0.063 NSP 0.045 lr 1.86478e-05
04/19/2022 13:08:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253040 Ep: 5.83 masked_t 0.421 masked_v 0.072 NSP 0.044 lr 1.86453e-05
04/19/2022 13:09:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253120 Ep: 5.83 masked_t 0.421 masked_v 0.070 NSP 0.042 lr 1.86429e-05
04/19/2022 13:10:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253200 Ep: 5.83 masked_t 0.443 masked_v 0.068 NSP 0.044 lr 1.86405e-05
04/19/2022 13:11:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253280 Ep: 5.84 masked_t 0.434 masked_v 0.065 NSP 0.041 lr 1.86381e-05
04/19/2022 13:12:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253360 Ep: 5.84 masked_t 0.413 masked_v 0.066 NSP 0.038 lr 1.86356e-05
04/19/2022 13:13:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253440 Ep: 5.84 masked_t 0.443 masked_v 0.068 NSP 0.047 lr 1.86332e-05
04/19/2022 13:14:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253520 Ep: 5.84 masked_t 0.409 masked_v 0.066 NSP 0.044 lr 1.86308e-05
04/19/2022 13:15:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253600 Ep: 5.84 masked_t 0.426 masked_v 0.066 NSP 0.041 lr 1.86284e-05
04/19/2022 13:16:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253680 Ep: 5.85 masked_t 0.436 masked_v 0.068 NSP 0.036 lr 1.86259e-05
04/19/2022 13:17:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253760 Ep: 5.85 masked_t 0.484 masked_v 0.068 NSP 0.041 lr 1.86235e-05
04/19/2022 13:18:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253840 Ep: 5.85 masked_t 0.423 masked_v 0.066 NSP 0.040 lr 1.86211e-05
04/19/2022 13:19:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 253920 Ep: 5.85 masked_t 0.451 masked_v 0.067 NSP 0.043 lr 1.86187e-05
04/19/2022 13:20:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254000 Ep: 5.85 masked_t 0.430 masked_v 0.068 NSP 0.046 lr 1.86162e-05
04/19/2022 13:21:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254080 Ep: 5.85 masked_t 0.410 masked_v 0.070 NSP 0.043 lr 1.86138e-05
04/19/2022 13:22:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254160 Ep: 5.86 masked_t 0.423 masked_v 0.067 NSP 0.040 lr 1.86114e-05
04/19/2022 13:23:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254240 Ep: 5.86 masked_t 0.429 masked_v 0.069 NSP 0.051 lr 1.8609e-05
04/19/2022 13:24:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254320 Ep: 5.86 masked_t 0.424 masked_v 0.069 NSP 0.041 lr 1.86065e-05
04/19/2022 13:25:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254400 Ep: 5.86 masked_t 0.435 masked_v 0.067 NSP 0.043 lr 1.86041e-05
04/19/2022 13:26:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254480 Ep: 5.86 masked_t 0.463 masked_v 0.066 NSP 0.043 lr 1.86017e-05
04/19/2022 13:27:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254560 Ep: 5.87 masked_t 0.447 masked_v 0.063 NSP 0.042 lr 1.85993e-05
04/19/2022 13:28:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254640 Ep: 5.87 masked_t 0.420 masked_v 0.067 NSP 0.043 lr 1.85968e-05
04/19/2022 13:29:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254720 Ep: 5.87 masked_t 0.448 masked_v 0.067 NSP 0.044 lr 1.85944e-05
04/19/2022 13:30:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254800 Ep: 5.87 masked_t 0.455 masked_v 0.067 NSP 0.041 lr 1.8592e-05
04/19/2022 13:31:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254880 Ep: 5.87 masked_t 0.385 masked_v 0.069 NSP 0.038 lr 1.85896e-05
04/19/2022 13:31:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 254960 Ep: 5.87 masked_t 0.411 masked_v 0.068 NSP 0.043 lr 1.85871e-05
04/19/2022 13:32:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255040 Ep: 5.88 masked_t 0.422 masked_v 0.070 NSP 0.043 lr 1.85847e-05
04/19/2022 13:33:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255120 Ep: 5.88 masked_t 0.411 masked_v 0.069 NSP 0.045 lr 1.85823e-05
04/19/2022 13:34:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255200 Ep: 5.88 masked_t 0.427 masked_v 0.068 NSP 0.047 lr 1.85799e-05
04/19/2022 13:35:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255280 Ep: 5.88 masked_t 0.429 masked_v 0.069 NSP 0.039 lr 1.85774e-05
04/19/2022 13:36:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255360 Ep: 5.88 masked_t 0.451 masked_v 0.065 NSP 0.035 lr 1.8575e-05
04/19/2022 13:37:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255440 Ep: 5.89 masked_t 0.440 masked_v 0.066 NSP 0.050 lr 1.85726e-05
04/19/2022 13:38:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255520 Ep: 5.89 masked_t 0.462 masked_v 0.070 NSP 0.045 lr 1.85702e-05
04/19/2022 13:39:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255600 Ep: 5.89 masked_t 0.440 masked_v 0.065 NSP 0.041 lr 1.85677e-05
04/19/2022 13:40:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255680 Ep: 5.89 masked_t 0.392 masked_v 0.066 NSP 0.045 lr 1.85653e-05
04/19/2022 13:41:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255760 Ep: 5.89 masked_t 0.486 masked_v 0.070 NSP 0.048 lr 1.85629e-05
04/19/2022 13:42:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255840 Ep: 5.89 masked_t 0.434 masked_v 0.066 NSP 0.038 lr 1.85605e-05
04/19/2022 13:43:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 255920 Ep: 5.90 masked_t 0.404 masked_v 0.067 NSP 0.037 lr 1.8558e-05
04/19/2022 13:44:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256000 Ep: 5.90 masked_t 0.468 masked_v 0.068 NSP 0.037 lr 1.85556e-05
04/19/2022 13:45:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256080 Ep: 5.90 masked_t 0.416 masked_v 0.069 NSP 0.046 lr 1.85532e-05
04/19/2022 13:46:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256160 Ep: 5.90 masked_t 0.431 masked_v 0.068 NSP 0.041 lr 1.85508e-05
04/19/2022 13:47:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256240 Ep: 5.90 masked_t 0.441 masked_v 0.065 NSP 0.041 lr 1.85483e-05
04/19/2022 13:48:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256320 Ep: 5.91 masked_t 0.403 masked_v 0.068 NSP 0.044 lr 1.85459e-05
04/19/2022 13:49:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256400 Ep: 5.91 masked_t 0.417 masked_v 0.065 NSP 0.037 lr 1.85435e-05
04/19/2022 13:50:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256480 Ep: 5.91 masked_t 0.446 masked_v 0.068 NSP 0.044 lr 1.85411e-05
04/19/2022 13:51:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256560 Ep: 5.91 masked_t 0.418 masked_v 0.067 NSP 0.052 lr 1.85386e-05
04/19/2022 13:52:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256640 Ep: 5.91 masked_t 0.406 masked_v 0.063 NSP 0.040 lr 1.85362e-05
04/19/2022 13:53:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256720 Ep: 5.92 masked_t 0.431 masked_v 0.067 NSP 0.040 lr 1.85338e-05
04/19/2022 13:54:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256800 Ep: 5.92 masked_t 0.433 masked_v 0.065 NSP 0.046 lr 1.85313e-05
04/19/2022 13:55:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256880 Ep: 5.92 masked_t 0.417 masked_v 0.066 NSP 0.043 lr 1.85289e-05
04/19/2022 13:56:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 256960 Ep: 5.92 masked_t 0.446 masked_v 0.068 NSP 0.036 lr 1.85265e-05
04/19/2022 13:57:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257040 Ep: 5.92 masked_t 0.468 masked_v 0.065 NSP 0.045 lr 1.85241e-05
04/19/2022 13:57:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257120 Ep: 5.92 masked_t 0.434 masked_v 0.064 NSP 0.037 lr 1.85216e-05
04/19/2022 13:58:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257200 Ep: 5.93 masked_t 0.416 masked_v 0.069 NSP 0.050 lr 1.85192e-05
04/19/2022 13:59:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257280 Ep: 5.93 masked_t 0.430 masked_v 0.069 NSP 0.044 lr 1.85168e-05
04/19/2022 14:00:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257360 Ep: 5.93 masked_t 0.438 masked_v 0.067 NSP 0.042 lr 1.85144e-05
04/19/2022 14:01:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257440 Ep: 5.93 masked_t 0.418 masked_v 0.069 NSP 0.037 lr 1.85119e-05
04/19/2022 14:02:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257520 Ep: 5.93 masked_t 0.426 masked_v 0.066 NSP 0.044 lr 1.85095e-05
04/19/2022 14:03:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257600 Ep: 5.94 masked_t 0.456 masked_v 0.069 NSP 0.042 lr 1.85071e-05
04/19/2022 14:04:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257680 Ep: 5.94 masked_t 0.435 masked_v 0.067 NSP 0.044 lr 1.85047e-05
04/19/2022 14:05:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257760 Ep: 5.94 masked_t 0.426 masked_v 0.073 NSP 0.045 lr 1.85022e-05
04/19/2022 14:06:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257840 Ep: 5.94 masked_t 0.443 masked_v 0.068 NSP 0.044 lr 1.84998e-05
04/19/2022 14:07:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 257920 Ep: 5.94 masked_t 0.419 masked_v 0.065 NSP 0.043 lr 1.84974e-05
04/19/2022 14:08:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258000 Ep: 5.94 masked_t 0.424 masked_v 0.070 NSP 0.036 lr 1.8495e-05
04/19/2022 14:09:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258080 Ep: 5.95 masked_t 0.439 masked_v 0.066 NSP 0.040 lr 1.84925e-05
04/19/2022 14:10:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258160 Ep: 5.95 masked_t 0.467 masked_v 0.064 NSP 0.044 lr 1.84901e-05
04/19/2022 14:11:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258240 Ep: 5.95 masked_t 0.430 masked_v 0.064 NSP 0.047 lr 1.84877e-05
04/19/2022 14:12:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258320 Ep: 5.95 masked_t 0.408 masked_v 0.069 NSP 0.044 lr 1.84853e-05
04/19/2022 14:13:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258400 Ep: 5.95 masked_t 0.443 masked_v 0.068 NSP 0.047 lr 1.84828e-05
04/19/2022 14:14:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258480 Ep: 5.96 masked_t 0.443 masked_v 0.068 NSP 0.044 lr 1.84804e-05
04/19/2022 14:15:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258560 Ep: 5.96 masked_t 0.442 masked_v 0.064 NSP 0.040 lr 1.8478e-05
04/19/2022 14:16:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258640 Ep: 5.96 masked_t 0.415 masked_v 0.066 NSP 0.044 lr 1.84756e-05
04/19/2022 14:17:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258720 Ep: 5.96 masked_t 0.422 masked_v 0.066 NSP 0.046 lr 1.84731e-05
04/19/2022 14:18:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258800 Ep: 5.96 masked_t 0.429 masked_v 0.069 NSP 0.039 lr 1.84707e-05
04/19/2022 14:19:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258880 Ep: 5.96 masked_t 0.457 masked_v 0.066 NSP 0.048 lr 1.84683e-05
04/19/2022 14:20:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 258960 Ep: 5.97 masked_t 0.419 masked_v 0.063 NSP 0.045 lr 1.84659e-05
04/19/2022 14:21:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259040 Ep: 5.97 masked_t 0.442 masked_v 0.068 NSP 0.039 lr 1.84634e-05
04/19/2022 14:22:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259120 Ep: 5.97 masked_t 0.426 masked_v 0.064 NSP 0.039 lr 1.8461e-05
04/19/2022 14:23:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259200 Ep: 5.97 masked_t 0.449 masked_v 0.066 NSP 0.043 lr 1.84586e-05
04/19/2022 14:23:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259280 Ep: 5.97 masked_t 0.411 masked_v 0.066 NSP 0.039 lr 1.84562e-05
04/19/2022 14:24:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259360 Ep: 5.98 masked_t 0.475 masked_v 0.066 NSP 0.048 lr 1.84537e-05
04/19/2022 14:25:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259440 Ep: 5.98 masked_t 0.402 masked_v 0.066 NSP 0.041 lr 1.84513e-05
04/19/2022 14:26:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259520 Ep: 5.98 masked_t 0.431 masked_v 0.068 NSP 0.047 lr 1.84489e-05
04/19/2022 14:27:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259600 Ep: 5.98 masked_t 0.425 masked_v 0.069 NSP 0.040 lr 1.84465e-05
04/19/2022 14:28:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259680 Ep: 5.98 masked_t 0.417 masked_v 0.065 NSP 0.041 lr 1.8444e-05
04/19/2022 14:29:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259760 Ep: 5.99 masked_t 0.422 masked_v 0.068 NSP 0.038 lr 1.84416e-05
04/19/2022 14:30:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259840 Ep: 5.99 masked_t 0.418 masked_v 0.065 NSP 0.045 lr 1.84392e-05
04/19/2022 14:31:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 259920 Ep: 5.99 masked_t 0.419 masked_v 0.064 NSP 0.039 lr 1.84368e-05
04/19/2022 14:32:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260000 Ep: 5.99 masked_t 0.411 masked_v 0.066 NSP 0.046 lr 1.84343e-05
04/19/2022 14:33:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260080 Ep: 5.99 masked_t 0.389 masked_v 0.065 NSP 0.048 lr 1.84319e-05
04/19/2022 14:34:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260160 Ep: 5.99 masked_t 0.427 masked_v 0.065 NSP 0.042 lr 1.84295e-05
04/19/2022 14:35:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260240 Ep: 6.00 masked_t 0.481 masked_v 0.064 NSP 0.041 lr 1.84271e-05
04/19/2022 14:36:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260320 Ep: 6.00 masked_t 0.452 masked_v 0.067 NSP 0.045 lr 1.84246e-05
04/19/2022 14:37:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260400 Ep: 6.00 masked_t 0.434 masked_v 0.065 NSP 0.044 lr 1.84222e-05
04/19/2022 14:38:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260480 Ep: 6.00 masked_t 0.429 masked_v 0.065 NSP 0.046 lr 1.84198e-05
04/19/2022 14:39:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260560 Ep: 6.00 masked_t 0.426 masked_v 0.067 NSP 0.043 lr 1.84174e-05
04/19/2022 14:40:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260640 Ep: 6.01 masked_t 0.455 masked_v 0.067 NSP 0.049 lr 1.84149e-05
04/19/2022 14:41:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260720 Ep: 6.01 masked_t 0.384 masked_v 0.068 NSP 0.043 lr 1.84125e-05
04/19/2022 14:42:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260800 Ep: 6.01 masked_t 0.429 masked_v 0.070 NSP 0.039 lr 1.84101e-05
04/19/2022 14:43:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260880 Ep: 6.01 masked_t 0.419 masked_v 0.067 NSP 0.043 lr 1.84077e-05
04/19/2022 14:44:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 260960 Ep: 6.01 masked_t 0.431 masked_v 0.063 NSP 0.047 lr 1.84052e-05
04/19/2022 14:45:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261040 Ep: 6.01 masked_t 0.401 masked_v 0.070 NSP 0.042 lr 1.84028e-05
04/19/2022 14:46:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261120 Ep: 6.02 masked_t 0.464 masked_v 0.066 NSP 0.041 lr 1.84004e-05
04/19/2022 14:47:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261200 Ep: 6.02 masked_t 0.432 masked_v 0.065 NSP 0.047 lr 1.8398e-05
04/19/2022 14:48:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261280 Ep: 6.02 masked_t 0.426 masked_v 0.064 NSP 0.038 lr 1.83955e-05
04/19/2022 14:49:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261360 Ep: 6.02 masked_t 0.441 masked_v 0.066 NSP 0.038 lr 1.83931e-05
04/19/2022 14:49:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261440 Ep: 6.02 masked_t 0.470 masked_v 0.066 NSP 0.048 lr 1.83907e-05
04/19/2022 14:50:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261520 Ep: 6.03 masked_t 0.461 masked_v 0.069 NSP 0.044 lr 1.83882e-05
04/19/2022 14:51:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261600 Ep: 6.03 masked_t 0.439 masked_v 0.065 NSP 0.048 lr 1.83858e-05
04/19/2022 14:52:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261680 Ep: 6.03 masked_t 0.427 masked_v 0.070 NSP 0.041 lr 1.83834e-05
04/19/2022 14:53:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261760 Ep: 6.03 masked_t 0.430 masked_v 0.064 NSP 0.044 lr 1.8381e-05
04/19/2022 14:54:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261840 Ep: 6.03 masked_t 0.420 masked_v 0.062 NSP 0.040 lr 1.83785e-05
04/19/2022 14:55:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 261920 Ep: 6.03 masked_t 0.430 masked_v 0.068 NSP 0.043 lr 1.83761e-05
04/19/2022 14:56:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262000 Ep: 6.04 masked_t 0.425 masked_v 0.068 NSP 0.045 lr 1.83737e-05
04/19/2022 14:57:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262080 Ep: 6.04 masked_t 0.411 masked_v 0.065 NSP 0.041 lr 1.83713e-05
04/19/2022 14:58:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262160 Ep: 6.04 masked_t 0.426 masked_v 0.069 NSP 0.046 lr 1.83688e-05
04/19/2022 14:59:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262240 Ep: 6.04 masked_t 0.460 masked_v 0.065 NSP 0.045 lr 1.83664e-05
04/19/2022 15:00:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262320 Ep: 6.04 masked_t 0.443 masked_v 0.064 NSP 0.041 lr 1.8364e-05
04/19/2022 15:01:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262400 Ep: 6.05 masked_t 0.404 masked_v 0.064 NSP 0.036 lr 1.83616e-05
04/19/2022 15:02:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262480 Ep: 6.05 masked_t 0.402 masked_v 0.067 NSP 0.046 lr 1.83591e-05
04/19/2022 15:03:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262560 Ep: 6.05 masked_t 0.392 masked_v 0.064 NSP 0.044 lr 1.83567e-05
04/19/2022 15:04:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262640 Ep: 6.05 masked_t 0.392 masked_v 0.066 NSP 0.047 lr 1.83543e-05
04/19/2022 15:05:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262720 Ep: 6.05 masked_t 0.467 masked_v 0.064 NSP 0.041 lr 1.83519e-05
04/19/2022 15:06:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262800 Ep: 6.06 masked_t 0.422 masked_v 0.066 NSP 0.038 lr 1.83494e-05
04/19/2022 15:07:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262880 Ep: 6.06 masked_t 0.410 masked_v 0.068 NSP 0.036 lr 1.8347e-05
04/19/2022 15:08:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 262960 Ep: 6.06 masked_t 0.407 masked_v 0.070 NSP 0.045 lr 1.83446e-05
04/19/2022 15:09:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263040 Ep: 6.06 masked_t 0.431 masked_v 0.067 NSP 0.041 lr 1.83422e-05
04/19/2022 15:10:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263120 Ep: 6.06 masked_t 0.349 masked_v 0.066 NSP 0.045 lr 1.83397e-05
04/19/2022 15:11:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263200 Ep: 6.06 masked_t 0.443 masked_v 0.066 NSP 0.039 lr 1.83373e-05
04/19/2022 15:12:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263280 Ep: 6.07 masked_t 0.426 masked_v 0.068 NSP 0.039 lr 1.83349e-05
04/19/2022 15:13:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263360 Ep: 6.07 masked_t 0.399 masked_v 0.068 NSP 0.039 lr 1.83325e-05
04/19/2022 15:14:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263440 Ep: 6.07 masked_t 0.435 masked_v 0.066 NSP 0.045 lr 1.833e-05
04/19/2022 15:15:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263520 Ep: 6.07 masked_t 0.425 masked_v 0.069 NSP 0.041 lr 1.83276e-05
04/19/2022 15:15:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263600 Ep: 6.07 masked_t 0.443 masked_v 0.067 NSP 0.039 lr 1.83252e-05
04/19/2022 15:16:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263680 Ep: 6.08 masked_t 0.417 masked_v 0.067 NSP 0.042 lr 1.83228e-05
04/19/2022 15:17:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263760 Ep: 6.08 masked_t 0.406 masked_v 0.070 NSP 0.033 lr 1.83203e-05
04/19/2022 15:18:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263840 Ep: 6.08 masked_t 0.413 masked_v 0.065 NSP 0.051 lr 1.83179e-05
04/19/2022 15:19:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 263920 Ep: 6.08 masked_t 0.441 masked_v 0.069 NSP 0.043 lr 1.83155e-05
04/19/2022 15:20:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264000 Ep: 6.08 masked_t 0.445 masked_v 0.066 NSP 0.043 lr 1.83131e-05
04/19/2022 15:21:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264080 Ep: 6.08 masked_t 0.429 masked_v 0.070 NSP 0.044 lr 1.83106e-05
04/19/2022 15:22:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264160 Ep: 6.09 masked_t 0.410 masked_v 0.066 NSP 0.041 lr 1.83082e-05
04/19/2022 15:23:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264240 Ep: 6.09 masked_t 0.417 masked_v 0.063 NSP 0.040 lr 1.83058e-05
04/19/2022 15:24:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264320 Ep: 6.09 masked_t 0.399 masked_v 0.070 NSP 0.043 lr 1.83034e-05
04/19/2022 15:25:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264400 Ep: 6.09 masked_t 0.433 masked_v 0.066 NSP 0.046 lr 1.83009e-05
04/19/2022 15:26:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264480 Ep: 6.09 masked_t 0.427 masked_v 0.067 NSP 0.044 lr 1.82985e-05
04/19/2022 15:27:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264560 Ep: 6.10 masked_t 0.396 masked_v 0.070 NSP 0.043 lr 1.82961e-05
04/19/2022 15:28:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264640 Ep: 6.10 masked_t 0.409 masked_v 0.065 NSP 0.048 lr 1.82937e-05
04/19/2022 15:29:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264720 Ep: 6.10 masked_t 0.418 masked_v 0.068 NSP 0.043 lr 1.82912e-05
04/19/2022 15:30:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264800 Ep: 6.10 masked_t 0.426 masked_v 0.066 NSP 0.042 lr 1.82888e-05
04/19/2022 15:31:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264880 Ep: 6.10 masked_t 0.418 masked_v 0.066 NSP 0.040 lr 1.82864e-05
04/19/2022 15:32:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 264960 Ep: 6.10 masked_t 0.452 masked_v 0.065 NSP 0.044 lr 1.8284e-05
04/19/2022 15:33:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265040 Ep: 6.11 masked_t 0.404 masked_v 0.065 NSP 0.048 lr 1.82815e-05
04/19/2022 15:34:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265120 Ep: 6.11 masked_t 0.463 masked_v 0.068 NSP 0.048 lr 1.82791e-05
04/19/2022 15:35:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265200 Ep: 6.11 masked_t 0.436 masked_v 0.067 NSP 0.045 lr 1.82767e-05
04/19/2022 15:36:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265280 Ep: 6.11 masked_t 0.436 masked_v 0.066 NSP 0.042 lr 1.82743e-05
04/19/2022 15:37:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265360 Ep: 6.11 masked_t 0.448 masked_v 0.067 NSP 0.048 lr 1.82718e-05
04/19/2022 15:38:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265440 Ep: 6.12 masked_t 0.422 masked_v 0.066 NSP 0.043 lr 1.82694e-05
04/19/2022 15:39:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265520 Ep: 6.12 masked_t 0.439 masked_v 0.073 NSP 0.043 lr 1.8267e-05
04/19/2022 15:40:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265600 Ep: 6.12 masked_t 0.393 masked_v 0.063 NSP 0.043 lr 1.82646e-05
04/19/2022 15:41:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265680 Ep: 6.12 masked_t 0.443 masked_v 0.070 NSP 0.036 lr 1.82621e-05
04/19/2022 15:41:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265760 Ep: 6.12 masked_t 0.427 masked_v 0.067 NSP 0.040 lr 1.82597e-05
04/19/2022 15:42:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265840 Ep: 6.13 masked_t 0.434 masked_v 0.066 NSP 0.037 lr 1.82573e-05
04/19/2022 15:43:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 265920 Ep: 6.13 masked_t 0.435 masked_v 0.068 NSP 0.044 lr 1.82549e-05
04/19/2022 15:44:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266000 Ep: 6.13 masked_t 0.445 masked_v 0.064 NSP 0.042 lr 1.82524e-05
04/19/2022 15:45:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266080 Ep: 6.13 masked_t 0.449 masked_v 0.064 NSP 0.037 lr 1.825e-05
04/19/2022 15:46:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266160 Ep: 6.13 masked_t 0.437 masked_v 0.066 NSP 0.046 lr 1.82476e-05
04/19/2022 15:47:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266240 Ep: 6.13 masked_t 0.459 masked_v 0.068 NSP 0.046 lr 1.82451e-05
04/19/2022 15:48:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266320 Ep: 6.14 masked_t 0.430 masked_v 0.066 NSP 0.046 lr 1.82427e-05
04/19/2022 15:49:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266400 Ep: 6.14 masked_t 0.442 masked_v 0.065 NSP 0.035 lr 1.82403e-05
04/19/2022 15:50:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266480 Ep: 6.14 masked_t 0.448 masked_v 0.066 NSP 0.043 lr 1.82379e-05
04/19/2022 15:51:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266560 Ep: 6.14 masked_t 0.432 masked_v 0.068 NSP 0.039 lr 1.82354e-05
04/19/2022 15:52:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266640 Ep: 6.14 masked_t 0.453 masked_v 0.068 NSP 0.048 lr 1.8233e-05
04/19/2022 15:53:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266720 Ep: 6.15 masked_t 0.422 masked_v 0.065 NSP 0.044 lr 1.82306e-05
04/19/2022 15:54:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266800 Ep: 6.15 masked_t 0.413 masked_v 0.067 NSP 0.041 lr 1.82282e-05
04/19/2022 15:55:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266880 Ep: 6.15 masked_t 0.432 masked_v 0.066 NSP 0.041 lr 1.82257e-05
04/19/2022 15:56:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 266960 Ep: 6.15 masked_t 0.409 masked_v 0.065 NSP 0.042 lr 1.82233e-05
04/19/2022 15:57:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267040 Ep: 6.15 masked_t 0.439 masked_v 0.063 NSP 0.051 lr 1.82209e-05
04/19/2022 15:58:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267120 Ep: 6.15 masked_t 0.397 masked_v 0.067 NSP 0.043 lr 1.82185e-05
04/19/2022 15:59:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267200 Ep: 6.16 masked_t 0.387 masked_v 0.065 NSP 0.049 lr 1.8216e-05
04/19/2022 16:00:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267280 Ep: 6.16 masked_t 0.436 masked_v 0.065 NSP 0.033 lr 1.82136e-05
04/19/2022 16:01:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267360 Ep: 6.16 masked_t 0.417 masked_v 0.065 NSP 0.039 lr 1.82112e-05
04/19/2022 16:02:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267440 Ep: 6.16 masked_t 0.421 masked_v 0.064 NSP 0.041 lr 1.82088e-05
04/19/2022 16:03:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267520 Ep: 6.16 masked_t 0.466 masked_v 0.065 NSP 0.041 lr 1.82063e-05
04/19/2022 16:04:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267600 Ep: 6.17 masked_t 0.402 masked_v 0.065 NSP 0.049 lr 1.82039e-05
04/19/2022 16:05:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267680 Ep: 6.17 masked_t 0.437 masked_v 0.068 NSP 0.045 lr 1.82015e-05
04/19/2022 16:06:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267760 Ep: 6.17 masked_t 0.421 masked_v 0.064 NSP 0.038 lr 1.81991e-05
04/19/2022 16:07:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267840 Ep: 6.17 masked_t 0.404 masked_v 0.067 NSP 0.043 lr 1.81966e-05
04/19/2022 16:07:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 267920 Ep: 6.17 masked_t 0.437 masked_v 0.067 NSP 0.041 lr 1.81942e-05
04/19/2022 16:08:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268000 Ep: 6.18 masked_t 0.427 masked_v 0.066 NSP 0.040 lr 1.81918e-05
04/19/2022 16:09:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268080 Ep: 6.18 masked_t 0.439 masked_v 0.063 NSP 0.042 lr 1.81894e-05
04/19/2022 16:10:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268160 Ep: 6.18 masked_t 0.416 masked_v 0.068 NSP 0.038 lr 1.81869e-05
04/19/2022 16:11:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268240 Ep: 6.18 masked_t 0.469 masked_v 0.069 NSP 0.041 lr 1.81845e-05
04/19/2022 16:12:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268320 Ep: 6.18 masked_t 0.427 masked_v 0.067 NSP 0.041 lr 1.81821e-05
04/19/2022 16:13:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268400 Ep: 6.18 masked_t 0.465 masked_v 0.067 NSP 0.040 lr 1.81797e-05
04/19/2022 16:14:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268480 Ep: 6.19 masked_t 0.391 masked_v 0.066 NSP 0.037 lr 1.81772e-05
04/19/2022 16:15:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268560 Ep: 6.19 masked_t 0.404 masked_v 0.067 NSP 0.042 lr 1.81748e-05
04/19/2022 16:16:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268640 Ep: 6.19 masked_t 0.418 masked_v 0.066 NSP 0.042 lr 1.81724e-05
04/19/2022 16:17:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268720 Ep: 6.19 masked_t 0.427 masked_v 0.067 NSP 0.042 lr 1.817e-05
04/19/2022 16:18:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268800 Ep: 6.19 masked_t 0.461 masked_v 0.068 NSP 0.044 lr 1.81675e-05
04/19/2022 16:19:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268880 Ep: 6.20 masked_t 0.462 masked_v 0.068 NSP 0.051 lr 1.81651e-05
04/19/2022 16:20:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 268960 Ep: 6.20 masked_t 0.389 masked_v 0.064 NSP 0.041 lr 1.81627e-05
04/19/2022 16:21:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269040 Ep: 6.20 masked_t 0.395 masked_v 0.067 NSP 0.041 lr 1.81603e-05
04/19/2022 16:22:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269120 Ep: 6.20 masked_t 0.427 masked_v 0.067 NSP 0.042 lr 1.81578e-05
04/19/2022 16:23:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269200 Ep: 6.20 masked_t 0.435 masked_v 0.065 NSP 0.047 lr 1.81554e-05
04/19/2022 16:24:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269280 Ep: 6.20 masked_t 0.458 masked_v 0.067 NSP 0.041 lr 1.8153e-05
04/19/2022 16:25:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269360 Ep: 6.21 masked_t 0.399 masked_v 0.068 NSP 0.040 lr 1.81506e-05
04/19/2022 16:26:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269440 Ep: 6.21 masked_t 0.414 masked_v 0.069 NSP 0.049 lr 1.81481e-05
04/19/2022 16:27:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269520 Ep: 6.21 masked_t 0.446 masked_v 0.067 NSP 0.044 lr 1.81457e-05
04/19/2022 16:28:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269600 Ep: 6.21 masked_t 0.421 masked_v 0.070 NSP 0.049 lr 1.81433e-05
04/19/2022 16:29:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269680 Ep: 6.21 masked_t 0.428 masked_v 0.066 NSP 0.041 lr 1.81409e-05
04/19/2022 16:30:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269760 Ep: 6.22 masked_t 0.423 masked_v 0.066 NSP 0.045 lr 1.81384e-05
04/19/2022 16:31:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269840 Ep: 6.22 masked_t 0.402 masked_v 0.065 NSP 0.037 lr 1.8136e-05
04/19/2022 16:32:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 269920 Ep: 6.22 masked_t 0.452 masked_v 0.069 NSP 0.045 lr 1.81336e-05
04/19/2022 16:32:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270000 Ep: 6.22 masked_t 0.414 masked_v 0.065 NSP 0.046 lr 1.81312e-05
04/19/2022 16:33:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270080 Ep: 6.22 masked_t 0.395 masked_v 0.066 NSP 0.043 lr 1.81287e-05
04/19/2022 16:34:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270160 Ep: 6.22 masked_t 0.447 masked_v 0.063 NSP 0.043 lr 1.81263e-05
04/19/2022 16:35:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270240 Ep: 6.23 masked_t 0.479 masked_v 0.067 NSP 0.039 lr 1.81239e-05
04/19/2022 16:36:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270320 Ep: 6.23 masked_t 0.422 masked_v 0.064 NSP 0.041 lr 1.81215e-05
04/19/2022 16:37:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270400 Ep: 6.23 masked_t 0.411 masked_v 0.069 NSP 0.043 lr 1.8119e-05
04/19/2022 16:38:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270480 Ep: 6.23 masked_t 0.446 masked_v 0.068 NSP 0.047 lr 1.81166e-05
04/19/2022 16:39:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270560 Ep: 6.23 masked_t 0.376 masked_v 0.070 NSP 0.040 lr 1.81142e-05
04/19/2022 16:40:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270640 Ep: 6.24 masked_t 0.452 masked_v 0.069 NSP 0.040 lr 1.81118e-05
04/19/2022 16:41:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270720 Ep: 6.24 masked_t 0.440 masked_v 0.066 NSP 0.038 lr 1.81093e-05
04/19/2022 16:42:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270800 Ep: 6.24 masked_t 0.418 masked_v 0.069 NSP 0.042 lr 1.81069e-05
04/19/2022 16:43:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270880 Ep: 6.24 masked_t 0.404 masked_v 0.066 NSP 0.041 lr 1.81045e-05
04/19/2022 16:44:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 270960 Ep: 6.24 masked_t 0.432 masked_v 0.067 NSP 0.046 lr 1.8102e-05
04/19/2022 16:45:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271040 Ep: 6.25 masked_t 0.427 masked_v 0.064 NSP 0.042 lr 1.80996e-05
04/19/2022 16:46:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271120 Ep: 6.25 masked_t 0.408 masked_v 0.067 NSP 0.040 lr 1.80972e-05
04/19/2022 16:47:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271200 Ep: 6.25 masked_t 0.426 masked_v 0.066 NSP 0.048 lr 1.80948e-05
04/19/2022 16:48:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271280 Ep: 6.25 masked_t 0.424 masked_v 0.067 NSP 0.043 lr 1.80923e-05
04/19/2022 16:49:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271360 Ep: 6.25 masked_t 0.449 masked_v 0.067 NSP 0.043 lr 1.80899e-05
04/19/2022 16:50:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271440 Ep: 6.25 masked_t 0.394 masked_v 0.065 NSP 0.041 lr 1.80875e-05
04/19/2022 16:51:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271520 Ep: 6.26 masked_t 0.435 masked_v 0.068 NSP 0.044 lr 1.80851e-05
04/19/2022 16:52:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271600 Ep: 6.26 masked_t 0.401 masked_v 0.065 NSP 0.041 lr 1.80826e-05
04/19/2022 16:53:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271680 Ep: 6.26 masked_t 0.445 masked_v 0.065 NSP 0.042 lr 1.80802e-05
04/19/2022 16:54:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271760 Ep: 6.26 masked_t 0.462 masked_v 0.069 NSP 0.048 lr 1.80778e-05
04/19/2022 16:55:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271840 Ep: 6.26 masked_t 0.435 masked_v 0.065 NSP 0.034 lr 1.80754e-05
04/19/2022 16:56:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 271920 Ep: 6.27 masked_t 0.422 masked_v 0.065 NSP 0.040 lr 1.80729e-05
04/19/2022 16:57:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272000 Ep: 6.27 masked_t 0.425 masked_v 0.068 NSP 0.038 lr 1.80705e-05
04/19/2022 16:58:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272080 Ep: 6.27 masked_t 0.429 masked_v 0.066 NSP 0.039 lr 1.80681e-05
04/19/2022 16:58:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272160 Ep: 6.27 masked_t 0.365 masked_v 0.070 NSP 0.043 lr 1.80657e-05
04/19/2022 16:59:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272240 Ep: 6.27 masked_t 0.419 masked_v 0.066 NSP 0.043 lr 1.80632e-05
04/19/2022 17:00:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272320 Ep: 6.27 masked_t 0.434 masked_v 0.067 NSP 0.041 lr 1.80608e-05
04/19/2022 17:01:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272400 Ep: 6.28 masked_t 0.404 masked_v 0.066 NSP 0.040 lr 1.80584e-05
04/19/2022 17:02:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272480 Ep: 6.28 masked_t 0.424 masked_v 0.070 NSP 0.041 lr 1.8056e-05
04/19/2022 17:03:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272560 Ep: 6.28 masked_t 0.433 masked_v 0.067 NSP 0.042 lr 1.80535e-05
04/19/2022 17:04:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272640 Ep: 6.28 masked_t 0.419 masked_v 0.069 NSP 0.043 lr 1.80511e-05
04/19/2022 17:05:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272720 Ep: 6.28 masked_t 0.412 masked_v 0.067 NSP 0.040 lr 1.80487e-05
04/19/2022 17:06:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272800 Ep: 6.29 masked_t 0.425 masked_v 0.069 NSP 0.050 lr 1.80463e-05
04/19/2022 17:07:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272880 Ep: 6.29 masked_t 0.437 masked_v 0.064 NSP 0.043 lr 1.80438e-05
04/19/2022 17:08:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 272960 Ep: 6.29 masked_t 0.387 masked_v 0.065 NSP 0.041 lr 1.80414e-05
04/19/2022 17:09:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273040 Ep: 6.29 masked_t 0.460 masked_v 0.067 NSP 0.032 lr 1.8039e-05
04/19/2022 17:10:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273120 Ep: 6.29 masked_t 0.426 masked_v 0.064 NSP 0.046 lr 1.80366e-05
04/19/2022 17:11:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273200 Ep: 6.29 masked_t 0.431 masked_v 0.065 NSP 0.038 lr 1.80341e-05
04/19/2022 17:12:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273280 Ep: 6.30 masked_t 0.417 masked_v 0.070 NSP 0.045 lr 1.80317e-05
04/19/2022 17:13:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273360 Ep: 6.30 masked_t 0.438 masked_v 0.069 NSP 0.047 lr 1.80293e-05
04/19/2022 17:14:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273440 Ep: 6.30 masked_t 0.443 masked_v 0.067 NSP 0.039 lr 1.80269e-05
04/19/2022 17:15:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273520 Ep: 6.30 masked_t 0.453 masked_v 0.069 NSP 0.041 lr 1.80244e-05
04/19/2022 17:16:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273600 Ep: 6.30 masked_t 0.431 masked_v 0.067 NSP 0.046 lr 1.8022e-05
04/19/2022 17:17:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273680 Ep: 6.31 masked_t 0.434 masked_v 0.064 NSP 0.041 lr 1.80196e-05
04/19/2022 17:18:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273760 Ep: 6.31 masked_t 0.439 masked_v 0.065 NSP 0.045 lr 1.80172e-05
04/19/2022 17:19:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273840 Ep: 6.31 masked_t 0.426 masked_v 0.068 NSP 0.038 lr 1.80147e-05
04/19/2022 17:20:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 273920 Ep: 6.31 masked_t 0.408 masked_v 0.068 NSP 0.037 lr 1.80123e-05
04/19/2022 17:21:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274000 Ep: 6.31 masked_t 0.441 masked_v 0.070 NSP 0.043 lr 1.80099e-05
04/19/2022 17:22:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274080 Ep: 6.32 masked_t 0.430 masked_v 0.061 NSP 0.043 lr 1.80075e-05
04/19/2022 17:23:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274160 Ep: 6.32 masked_t 0.394 masked_v 0.069 NSP 0.048 lr 1.8005e-05
04/19/2022 17:23:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274240 Ep: 6.32 masked_t 0.459 masked_v 0.061 NSP 0.043 lr 1.80026e-05
04/19/2022 17:24:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274320 Ep: 6.32 masked_t 0.430 masked_v 0.065 NSP 0.037 lr 1.80002e-05
04/19/2022 17:25:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274400 Ep: 6.32 masked_t 0.419 masked_v 0.067 NSP 0.041 lr 1.79978e-05
04/19/2022 17:26:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274480 Ep: 6.32 masked_t 0.417 masked_v 0.064 NSP 0.046 lr 1.79953e-05
04/19/2022 17:27:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274560 Ep: 6.33 masked_t 0.393 masked_v 0.064 NSP 0.038 lr 1.79929e-05
04/19/2022 17:28:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274640 Ep: 6.33 masked_t 0.460 masked_v 0.066 NSP 0.040 lr 1.79905e-05
04/19/2022 17:29:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274720 Ep: 6.33 masked_t 0.464 masked_v 0.067 NSP 0.040 lr 1.79881e-05
04/19/2022 17:30:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274800 Ep: 6.33 masked_t 0.417 masked_v 0.065 NSP 0.040 lr 1.79856e-05
04/19/2022 17:31:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274880 Ep: 6.33 masked_t 0.416 masked_v 0.066 NSP 0.043 lr 1.79832e-05
04/19/2022 17:32:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 274960 Ep: 6.34 masked_t 0.410 masked_v 0.064 NSP 0.037 lr 1.79808e-05
04/19/2022 17:33:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275040 Ep: 6.34 masked_t 0.449 masked_v 0.065 NSP 0.045 lr 1.79784e-05
04/19/2022 17:34:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275120 Ep: 6.34 masked_t 0.426 masked_v 0.065 NSP 0.045 lr 1.79759e-05
04/19/2022 17:35:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275200 Ep: 6.34 masked_t 0.430 masked_v 0.069 NSP 0.035 lr 1.79735e-05
04/19/2022 17:36:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275280 Ep: 6.34 masked_t 0.413 masked_v 0.065 NSP 0.045 lr 1.79711e-05
04/19/2022 17:37:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275360 Ep: 6.34 masked_t 0.421 masked_v 0.067 NSP 0.039 lr 1.79687e-05
04/19/2022 17:38:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275440 Ep: 6.35 masked_t 0.434 masked_v 0.065 NSP 0.043 lr 1.79662e-05
04/19/2022 17:39:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275520 Ep: 6.35 masked_t 0.435 masked_v 0.066 NSP 0.042 lr 1.79638e-05
04/19/2022 17:40:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275600 Ep: 6.35 masked_t 0.436 masked_v 0.068 NSP 0.045 lr 1.79614e-05
04/19/2022 17:41:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275680 Ep: 6.35 masked_t 0.384 masked_v 0.064 NSP 0.049 lr 1.79589e-05
04/19/2022 17:42:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275760 Ep: 6.35 masked_t 0.430 masked_v 0.066 NSP 0.039 lr 1.79565e-05
04/19/2022 17:43:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275840 Ep: 6.36 masked_t 0.427 masked_v 0.066 NSP 0.047 lr 1.79541e-05
04/19/2022 17:44:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 275920 Ep: 6.36 masked_t 0.436 masked_v 0.069 NSP 0.046 lr 1.79517e-05
04/19/2022 17:45:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276000 Ep: 6.36 masked_t 0.427 masked_v 0.067 NSP 0.042 lr 1.79492e-05
04/19/2022 17:46:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276080 Ep: 6.36 masked_t 0.422 masked_v 0.065 NSP 0.045 lr 1.79468e-05
04/19/2022 17:47:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276160 Ep: 6.36 masked_t 0.460 masked_v 0.067 NSP 0.044 lr 1.79444e-05
04/19/2022 17:48:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276240 Ep: 6.36 masked_t 0.432 masked_v 0.065 NSP 0.046 lr 1.7942e-05
04/19/2022 17:49:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276320 Ep: 6.37 masked_t 0.459 masked_v 0.067 NSP 0.046 lr 1.79395e-05
04/19/2022 17:49:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276400 Ep: 6.37 masked_t 0.428 masked_v 0.072 NSP 0.048 lr 1.79371e-05
04/19/2022 17:50:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276480 Ep: 6.37 masked_t 0.410 masked_v 0.073 NSP 0.038 lr 1.79347e-05
04/19/2022 17:51:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276560 Ep: 6.37 masked_t 0.413 masked_v 0.066 NSP 0.035 lr 1.79323e-05
04/19/2022 17:52:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276640 Ep: 6.37 masked_t 0.455 masked_v 0.064 NSP 0.038 lr 1.79298e-05
04/19/2022 17:53:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276720 Ep: 6.38 masked_t 0.416 masked_v 0.070 NSP 0.042 lr 1.79274e-05
04/19/2022 17:54:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276800 Ep: 6.38 masked_t 0.445 masked_v 0.069 NSP 0.045 lr 1.7925e-05
04/19/2022 17:55:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276880 Ep: 6.38 masked_t 0.448 masked_v 0.068 NSP 0.042 lr 1.79226e-05
04/19/2022 17:56:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 276960 Ep: 6.38 masked_t 0.439 masked_v 0.063 NSP 0.037 lr 1.79201e-05
04/19/2022 17:57:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277040 Ep: 6.38 masked_t 0.416 masked_v 0.066 NSP 0.037 lr 1.79177e-05
04/19/2022 17:58:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277120 Ep: 6.39 masked_t 0.440 masked_v 0.063 NSP 0.039 lr 1.79153e-05
04/19/2022 17:59:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277200 Ep: 6.39 masked_t 0.416 masked_v 0.067 NSP 0.040 lr 1.79129e-05
04/19/2022 18:00:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277280 Ep: 6.39 masked_t 0.439 masked_v 0.067 NSP 0.038 lr 1.79104e-05
04/19/2022 18:01:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277360 Ep: 6.39 masked_t 0.407 masked_v 0.064 NSP 0.032 lr 1.7908e-05
04/19/2022 18:02:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277440 Ep: 6.39 masked_t 0.418 masked_v 0.062 NSP 0.040 lr 1.79056e-05
04/19/2022 18:03:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277520 Ep: 6.39 masked_t 0.418 masked_v 0.066 NSP 0.042 lr 1.79032e-05
04/19/2022 18:04:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277600 Ep: 6.40 masked_t 0.432 masked_v 0.069 NSP 0.044 lr 1.79007e-05
04/19/2022 18:05:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277680 Ep: 6.40 masked_t 0.429 masked_v 0.067 NSP 0.042 lr 1.78983e-05
04/19/2022 18:06:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277760 Ep: 6.40 masked_t 0.421 masked_v 0.066 NSP 0.044 lr 1.78959e-05
04/19/2022 18:07:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277840 Ep: 6.40 masked_t 0.444 masked_v 0.064 NSP 0.043 lr 1.78935e-05
04/19/2022 18:08:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 277920 Ep: 6.40 masked_t 0.409 masked_v 0.066 NSP 0.039 lr 1.7891e-05
04/19/2022 18:09:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278000 Ep: 6.41 masked_t 0.461 masked_v 0.064 NSP 0.044 lr 1.78886e-05
04/19/2022 18:10:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278080 Ep: 6.41 masked_t 0.426 masked_v 0.072 NSP 0.041 lr 1.78862e-05
04/19/2022 18:11:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278160 Ep: 6.41 masked_t 0.409 masked_v 0.063 NSP 0.042 lr 1.78838e-05
04/19/2022 18:12:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278240 Ep: 6.41 masked_t 0.426 masked_v 0.067 NSP 0.035 lr 1.78813e-05
04/19/2022 18:13:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278320 Ep: 6.41 masked_t 0.439 masked_v 0.065 NSP 0.052 lr 1.78789e-05
04/19/2022 18:14:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278400 Ep: 6.41 masked_t 0.451 masked_v 0.065 NSP 0.037 lr 1.78765e-05
04/19/2022 18:15:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278480 Ep: 6.42 masked_t 0.400 masked_v 0.067 NSP 0.043 lr 1.78741e-05
04/19/2022 18:15:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278560 Ep: 6.42 masked_t 0.405 masked_v 0.066 NSP 0.039 lr 1.78716e-05
04/19/2022 18:16:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278640 Ep: 6.42 masked_t 0.441 masked_v 0.070 NSP 0.040 lr 1.78692e-05
04/19/2022 18:17:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278720 Ep: 6.42 masked_t 0.420 masked_v 0.067 NSP 0.045 lr 1.78668e-05
04/19/2022 18:18:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278800 Ep: 6.42 masked_t 0.390 masked_v 0.069 NSP 0.038 lr 1.78644e-05
04/19/2022 18:19:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278880 Ep: 6.43 masked_t 0.414 masked_v 0.067 NSP 0.045 lr 1.78619e-05
04/19/2022 18:20:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 278960 Ep: 6.43 masked_t 0.416 masked_v 0.067 NSP 0.041 lr 1.78595e-05
04/19/2022 18:21:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279040 Ep: 6.43 masked_t 0.429 masked_v 0.068 NSP 0.044 lr 1.78571e-05
04/19/2022 18:22:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279120 Ep: 6.43 masked_t 0.440 masked_v 0.068 NSP 0.038 lr 1.78547e-05
04/19/2022 18:23:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279200 Ep: 6.43 masked_t 0.423 masked_v 0.069 NSP 0.041 lr 1.78522e-05
04/19/2022 18:24:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279280 Ep: 6.43 masked_t 0.431 masked_v 0.065 NSP 0.040 lr 1.78498e-05
04/19/2022 18:25:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279360 Ep: 6.44 masked_t 0.437 masked_v 0.065 NSP 0.039 lr 1.78474e-05
04/19/2022 18:26:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279440 Ep: 6.44 masked_t 0.434 masked_v 0.065 NSP 0.041 lr 1.7845e-05
04/19/2022 18:27:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279520 Ep: 6.44 masked_t 0.466 masked_v 0.068 NSP 0.051 lr 1.78425e-05
04/19/2022 18:28:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279600 Ep: 6.44 masked_t 0.434 masked_v 0.066 NSP 0.039 lr 1.78401e-05
04/19/2022 18:29:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279680 Ep: 6.44 masked_t 0.439 masked_v 0.067 NSP 0.037 lr 1.78377e-05
04/19/2022 18:30:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279760 Ep: 6.45 masked_t 0.408 masked_v 0.067 NSP 0.036 lr 1.78353e-05
04/19/2022 18:31:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279840 Ep: 6.45 masked_t 0.450 masked_v 0.066 NSP 0.041 lr 1.78328e-05
04/19/2022 18:32:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 279920 Ep: 6.45 masked_t 0.428 masked_v 0.065 NSP 0.049 lr 1.78304e-05
04/19/2022 18:33:16 - INFO - __main__ -   ** ** * Saving model * ** ** 
04/19/2022 18:33:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280000 Ep: 6.45 masked_t 0.442 masked_v 0.063 NSP 0.045 lr 1.7828e-05
04/19/2022 18:34:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280080 Ep: 6.45 masked_t 0.460 masked_v 0.065 NSP 0.049 lr 1.78256e-05
04/19/2022 18:35:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280160 Ep: 6.46 masked_t 0.483 masked_v 0.066 NSP 0.039 lr 1.78231e-05
04/19/2022 18:36:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280240 Ep: 6.46 masked_t 0.429 masked_v 0.065 NSP 0.038 lr 1.78207e-05
04/19/2022 18:37:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280320 Ep: 6.46 masked_t 0.399 masked_v 0.070 NSP 0.040 lr 1.78183e-05
04/19/2022 18:38:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280400 Ep: 6.46 masked_t 0.405 masked_v 0.069 NSP 0.038 lr 1.78159e-05
04/19/2022 18:39:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280480 Ep: 6.46 masked_t 0.431 masked_v 0.065 NSP 0.038 lr 1.78134e-05
04/19/2022 18:40:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280560 Ep: 6.46 masked_t 0.420 masked_v 0.067 NSP 0.047 lr 1.7811e-05
04/19/2022 18:41:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280640 Ep: 6.47 masked_t 0.474 masked_v 0.064 NSP 0.043 lr 1.78086e-05
04/19/2022 18:42:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280720 Ep: 6.47 masked_t 0.442 masked_v 0.069 NSP 0.044 lr 1.78061e-05
04/19/2022 18:43:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280800 Ep: 6.47 masked_t 0.403 masked_v 0.064 NSP 0.042 lr 1.78037e-05
04/19/2022 18:44:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280880 Ep: 6.47 masked_t 0.445 masked_v 0.065 NSP 0.047 lr 1.78013e-05
04/19/2022 18:45:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 280960 Ep: 6.47 masked_t 0.422 masked_v 0.069 NSP 0.040 lr 1.77989e-05
04/19/2022 18:46:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281040 Ep: 6.48 masked_t 0.446 masked_v 0.065 NSP 0.041 lr 1.77964e-05
04/19/2022 18:47:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281120 Ep: 6.48 masked_t 0.423 masked_v 0.063 NSP 0.039 lr 1.7794e-05
04/19/2022 18:48:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281200 Ep: 6.48 masked_t 0.414 masked_v 0.068 NSP 0.048 lr 1.77916e-05
04/19/2022 18:49:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281280 Ep: 6.48 masked_t 0.412 masked_v 0.070 NSP 0.035 lr 1.77892e-05
04/19/2022 18:50:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281360 Ep: 6.48 masked_t 0.430 masked_v 0.068 NSP 0.046 lr 1.77867e-05
04/19/2022 18:51:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281440 Ep: 6.48 masked_t 0.429 masked_v 0.067 NSP 0.043 lr 1.77843e-05
04/19/2022 18:52:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281520 Ep: 6.49 masked_t 0.463 masked_v 0.063 NSP 0.041 lr 1.77819e-05
04/19/2022 18:53:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281600 Ep: 6.49 masked_t 0.396 masked_v 0.064 NSP 0.041 lr 1.77795e-05
04/19/2022 18:53:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281680 Ep: 6.49 masked_t 0.387 masked_v 0.064 NSP 0.044 lr 1.7777e-05
04/19/2022 18:54:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281760 Ep: 6.49 masked_t 0.372 masked_v 0.065 NSP 0.035 lr 1.77746e-05
04/19/2022 18:55:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281840 Ep: 6.49 masked_t 0.412 masked_v 0.064 NSP 0.046 lr 1.77722e-05
04/19/2022 18:56:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 281920 Ep: 6.50 masked_t 0.424 masked_v 0.063 NSP 0.047 lr 1.77698e-05
04/19/2022 18:57:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282000 Ep: 6.50 masked_t 0.435 masked_v 0.065 NSP 0.043 lr 1.77673e-05
04/19/2022 18:58:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282080 Ep: 6.50 masked_t 0.421 masked_v 0.068 NSP 0.041 lr 1.77649e-05
04/19/2022 18:59:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282160 Ep: 6.50 masked_t 0.411 masked_v 0.066 NSP 0.039 lr 1.77625e-05
04/19/2022 19:00:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282240 Ep: 6.50 masked_t 0.426 masked_v 0.064 NSP 0.045 lr 1.77601e-05
04/19/2022 19:01:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282320 Ep: 6.50 masked_t 0.435 masked_v 0.065 NSP 0.032 lr 1.77576e-05
04/19/2022 19:02:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282400 Ep: 6.51 masked_t 0.424 masked_v 0.070 NSP 0.042 lr 1.77552e-05
04/19/2022 19:03:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282480 Ep: 6.51 masked_t 0.415 masked_v 0.066 NSP 0.037 lr 1.77528e-05
04/19/2022 19:04:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282560 Ep: 6.51 masked_t 0.395 masked_v 0.065 NSP 0.037 lr 1.77504e-05
04/19/2022 19:05:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282640 Ep: 6.51 masked_t 0.413 masked_v 0.067 NSP 0.044 lr 1.77479e-05
04/19/2022 19:06:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282720 Ep: 6.51 masked_t 0.415 masked_v 0.069 NSP 0.043 lr 1.77455e-05
04/19/2022 19:07:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282800 Ep: 6.52 masked_t 0.437 masked_v 0.071 NSP 0.041 lr 1.77431e-05
04/19/2022 19:08:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282880 Ep: 6.52 masked_t 0.413 masked_v 0.067 NSP 0.038 lr 1.77407e-05
04/19/2022 19:09:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 282960 Ep: 6.52 masked_t 0.422 masked_v 0.062 NSP 0.043 lr 1.77382e-05
04/19/2022 19:10:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283040 Ep: 6.52 masked_t 0.419 masked_v 0.067 NSP 0.038 lr 1.77358e-05
04/19/2022 19:11:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283120 Ep: 6.52 masked_t 0.422 masked_v 0.065 NSP 0.040 lr 1.77334e-05
04/19/2022 19:12:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283200 Ep: 6.53 masked_t 0.434 masked_v 0.069 NSP 0.044 lr 1.7731e-05
04/19/2022 19:13:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283280 Ep: 6.53 masked_t 0.408 masked_v 0.067 NSP 0.037 lr 1.77285e-05
04/19/2022 19:14:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283360 Ep: 6.53 masked_t 0.433 masked_v 0.064 NSP 0.041 lr 1.77261e-05
04/19/2022 19:15:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283480 Ep: 6.53 masked_t 0.435 masked_v 0.069 NSP 0.045 lr 1.77231e-05
04/19/2022 19:16:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283560 Ep: 6.53 masked_t 0.399 masked_v 0.064 NSP 0.043 lr 1.772e-05
04/19/2022 19:17:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283640 Ep: 6.54 masked_t 0.449 masked_v 0.066 NSP 0.040 lr 1.77176e-05
04/19/2022 19:18:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283720 Ep: 6.54 masked_t 0.425 masked_v 0.064 NSP 0.040 lr 1.77152e-05
04/19/2022 19:19:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283800 Ep: 6.54 masked_t 0.410 masked_v 0.066 NSP 0.043 lr 1.77128e-05
04/19/2022 19:20:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283880 Ep: 6.54 masked_t 0.392 masked_v 0.067 NSP 0.038 lr 1.77103e-05
04/19/2022 19:21:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 283960 Ep: 6.54 masked_t 0.434 masked_v 0.068 NSP 0.044 lr 1.77079e-05
04/19/2022 19:22:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284040 Ep: 6.54 masked_t 0.386 masked_v 0.063 NSP 0.041 lr 1.77055e-05
04/19/2022 19:23:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284120 Ep: 6.55 masked_t 0.432 masked_v 0.062 NSP 0.046 lr 1.77031e-05
04/19/2022 19:24:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284200 Ep: 6.55 masked_t 0.438 masked_v 0.062 NSP 0.042 lr 1.77006e-05
04/19/2022 19:25:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284280 Ep: 6.55 masked_t 0.396 masked_v 0.064 NSP 0.038 lr 1.76982e-05
04/19/2022 19:26:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284360 Ep: 6.55 masked_t 0.426 masked_v 0.066 NSP 0.037 lr 1.76958e-05
04/19/2022 19:27:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284440 Ep: 6.55 masked_t 0.437 masked_v 0.069 NSP 0.043 lr 1.76934e-05
04/19/2022 19:28:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284520 Ep: 6.56 masked_t 0.446 masked_v 0.070 NSP 0.043 lr 1.76909e-05
04/19/2022 19:29:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284600 Ep: 6.56 masked_t 0.389 masked_v 0.064 NSP 0.048 lr 1.76885e-05
04/19/2022 19:30:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284680 Ep: 6.56 masked_t 0.419 masked_v 0.070 NSP 0.044 lr 1.76861e-05
04/19/2022 19:31:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284760 Ep: 6.56 masked_t 0.404 masked_v 0.068 NSP 0.040 lr 1.76837e-05
04/19/2022 19:31:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284840 Ep: 6.56 masked_t 0.438 masked_v 0.065 NSP 0.038 lr 1.76812e-05
04/19/2022 19:32:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 284920 Ep: 6.56 masked_t 0.414 masked_v 0.064 NSP 0.038 lr 1.76788e-05
04/19/2022 19:33:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285000 Ep: 6.57 masked_t 0.458 masked_v 0.064 NSP 0.043 lr 1.76764e-05
04/19/2022 19:34:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285080 Ep: 6.57 masked_t 0.434 masked_v 0.067 NSP 0.046 lr 1.7674e-05
04/19/2022 19:35:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285160 Ep: 6.57 masked_t 0.393 masked_v 0.066 NSP 0.036 lr 1.76715e-05
04/19/2022 19:36:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285240 Ep: 6.57 masked_t 0.396 masked_v 0.064 NSP 0.046 lr 1.76691e-05
04/19/2022 19:37:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285320 Ep: 6.57 masked_t 0.424 masked_v 0.067 NSP 0.044 lr 1.76667e-05
04/19/2022 19:38:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285400 Ep: 6.58 masked_t 0.421 masked_v 0.070 NSP 0.041 lr 1.76643e-05
04/19/2022 19:39:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285480 Ep: 6.58 masked_t 0.390 masked_v 0.066 NSP 0.049 lr 1.76618e-05
04/19/2022 19:40:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285560 Ep: 6.58 masked_t 0.394 masked_v 0.069 NSP 0.041 lr 1.76594e-05
04/19/2022 19:41:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285640 Ep: 6.58 masked_t 0.423 masked_v 0.068 NSP 0.040 lr 1.7657e-05
04/19/2022 19:42:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285720 Ep: 6.58 masked_t 0.440 masked_v 0.066 NSP 0.041 lr 1.76546e-05
04/19/2022 19:43:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285800 Ep: 6.59 masked_t 0.436 masked_v 0.067 NSP 0.037 lr 1.76521e-05
04/19/2022 19:44:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285880 Ep: 6.59 masked_t 0.398 masked_v 0.070 NSP 0.032 lr 1.76497e-05
04/19/2022 19:45:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 285960 Ep: 6.59 masked_t 0.419 masked_v 0.066 NSP 0.040 lr 1.76473e-05
04/19/2022 19:46:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286040 Ep: 6.59 masked_t 0.393 masked_v 0.065 NSP 0.043 lr 1.76449e-05
04/19/2022 19:47:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286120 Ep: 6.59 masked_t 0.439 masked_v 0.067 NSP 0.039 lr 1.76424e-05
04/19/2022 19:48:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286200 Ep: 6.59 masked_t 0.405 masked_v 0.066 NSP 0.045 lr 1.764e-05
04/19/2022 19:49:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286280 Ep: 6.60 masked_t 0.440 masked_v 0.063 NSP 0.045 lr 1.76376e-05
04/19/2022 19:50:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286360 Ep: 6.60 masked_t 0.424 masked_v 0.066 NSP 0.038 lr 1.76352e-05
04/19/2022 19:51:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286440 Ep: 6.60 masked_t 0.432 masked_v 0.067 NSP 0.043 lr 1.76327e-05
04/19/2022 19:52:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286520 Ep: 6.60 masked_t 0.420 masked_v 0.066 NSP 0.040 lr 1.76303e-05
04/19/2022 19:53:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286600 Ep: 6.60 masked_t 0.423 masked_v 0.063 NSP 0.046 lr 1.76279e-05
04/19/2022 19:54:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286680 Ep: 6.61 masked_t 0.428 masked_v 0.066 NSP 0.039 lr 1.76255e-05
04/19/2022 19:55:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286760 Ep: 6.61 masked_t 0.400 masked_v 0.066 NSP 0.043 lr 1.7623e-05
04/19/2022 19:56:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286840 Ep: 6.61 masked_t 0.443 masked_v 0.066 NSP 0.036 lr 1.76206e-05
04/19/2022 19:56:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 286920 Ep: 6.61 masked_t 0.427 masked_v 0.065 NSP 0.048 lr 1.76182e-05
04/19/2022 19:57:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287000 Ep: 6.61 masked_t 0.414 masked_v 0.065 NSP 0.036 lr 1.76158e-05
04/19/2022 19:58:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287080 Ep: 6.61 masked_t 0.432 masked_v 0.066 NSP 0.041 lr 1.76133e-05
04/19/2022 19:59:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287160 Ep: 6.62 masked_t 0.419 masked_v 0.066 NSP 0.041 lr 1.76109e-05
04/19/2022 20:00:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287240 Ep: 6.62 masked_t 0.460 masked_v 0.067 NSP 0.041 lr 1.76085e-05
04/19/2022 20:01:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287320 Ep: 6.62 masked_t 0.419 masked_v 0.065 NSP 0.046 lr 1.76061e-05
04/19/2022 20:02:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287400 Ep: 6.62 masked_t 0.431 masked_v 0.066 NSP 0.044 lr 1.76036e-05
04/19/2022 20:03:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287480 Ep: 6.62 masked_t 0.435 masked_v 0.067 NSP 0.042 lr 1.76012e-05
04/19/2022 20:04:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287560 Ep: 6.63 masked_t 0.409 masked_v 0.069 NSP 0.044 lr 1.75988e-05
04/19/2022 20:05:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287640 Ep: 6.63 masked_t 0.428 masked_v 0.066 NSP 0.038 lr 1.75963e-05
04/19/2022 20:06:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287720 Ep: 6.63 masked_t 0.418 masked_v 0.065 NSP 0.039 lr 1.75939e-05
04/19/2022 20:07:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287800 Ep: 6.63 masked_t 0.411 masked_v 0.066 NSP 0.045 lr 1.75915e-05
04/19/2022 20:08:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287880 Ep: 6.63 masked_t 0.422 masked_v 0.065 NSP 0.036 lr 1.75891e-05
04/19/2022 20:09:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 287960 Ep: 6.63 masked_t 0.449 masked_v 0.066 NSP 0.040 lr 1.75866e-05
04/19/2022 20:10:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288040 Ep: 6.64 masked_t 0.456 masked_v 0.071 NSP 0.039 lr 1.75842e-05
04/19/2022 20:11:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288120 Ep: 6.64 masked_t 0.414 masked_v 0.068 NSP 0.041 lr 1.75818e-05
04/19/2022 20:12:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288200 Ep: 6.64 masked_t 0.398 masked_v 0.066 NSP 0.041 lr 1.75794e-05
04/19/2022 20:13:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288280 Ep: 6.64 masked_t 0.414 masked_v 0.066 NSP 0.038 lr 1.75769e-05
04/19/2022 20:14:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288360 Ep: 6.64 masked_t 0.422 masked_v 0.067 NSP 0.047 lr 1.75745e-05
04/19/2022 20:15:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288440 Ep: 6.65 masked_t 0.425 masked_v 0.067 NSP 0.044 lr 1.75721e-05
04/19/2022 20:16:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288520 Ep: 6.65 masked_t 0.413 masked_v 0.066 NSP 0.048 lr 1.75697e-05
04/19/2022 20:17:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288600 Ep: 6.65 masked_t 0.433 masked_v 0.067 NSP 0.048 lr 1.75672e-05
04/19/2022 20:18:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288680 Ep: 6.65 masked_t 0.431 masked_v 0.065 NSP 0.042 lr 1.75648e-05
04/19/2022 20:19:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288760 Ep: 6.65 masked_t 0.419 masked_v 0.064 NSP 0.041 lr 1.75624e-05
04/19/2022 20:20:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288840 Ep: 6.66 masked_t 0.383 masked_v 0.066 NSP 0.043 lr 1.756e-05
04/19/2022 20:21:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 288920 Ep: 6.66 masked_t 0.431 masked_v 0.066 NSP 0.042 lr 1.75575e-05
04/19/2022 20:21:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289000 Ep: 6.66 masked_t 0.444 masked_v 0.063 NSP 0.040 lr 1.75551e-05
04/19/2022 20:22:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289080 Ep: 6.66 masked_t 0.407 masked_v 0.065 NSP 0.043 lr 1.75527e-05
04/19/2022 20:23:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289160 Ep: 6.66 masked_t 0.424 masked_v 0.062 NSP 0.040 lr 1.75503e-05
04/19/2022 20:24:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289240 Ep: 6.66 masked_t 0.441 masked_v 0.065 NSP 0.050 lr 1.75478e-05
04/19/2022 20:25:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289320 Ep: 6.67 masked_t 0.415 masked_v 0.066 NSP 0.037 lr 1.75454e-05
04/19/2022 20:26:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289400 Ep: 6.67 masked_t 0.406 masked_v 0.065 NSP 0.052 lr 1.7543e-05
04/19/2022 20:27:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289480 Ep: 6.67 masked_t 0.371 masked_v 0.068 NSP 0.046 lr 1.75406e-05
04/19/2022 20:28:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289560 Ep: 6.67 masked_t 0.412 masked_v 0.066 NSP 0.047 lr 1.75381e-05
04/19/2022 20:29:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289640 Ep: 6.67 masked_t 0.410 masked_v 0.064 NSP 0.044 lr 1.75357e-05
04/19/2022 20:30:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289720 Ep: 6.68 masked_t 0.378 masked_v 0.066 NSP 0.042 lr 1.75333e-05
04/19/2022 20:31:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289800 Ep: 6.68 masked_t 0.404 masked_v 0.065 NSP 0.040 lr 1.75309e-05
04/19/2022 20:32:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289880 Ep: 6.68 masked_t 0.436 masked_v 0.066 NSP 0.037 lr 1.75284e-05
04/19/2022 20:33:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 289960 Ep: 6.68 masked_t 0.378 masked_v 0.065 NSP 0.043 lr 1.7526e-05
04/19/2022 20:34:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290040 Ep: 6.68 masked_t 0.457 masked_v 0.065 NSP 0.041 lr 1.75236e-05
04/19/2022 20:35:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290120 Ep: 6.68 masked_t 0.425 masked_v 0.064 NSP 0.040 lr 1.75212e-05
04/19/2022 20:36:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290200 Ep: 6.69 masked_t 0.403 masked_v 0.065 NSP 0.037 lr 1.75187e-05
04/19/2022 20:37:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290280 Ep: 6.69 masked_t 0.389 masked_v 0.065 NSP 0.041 lr 1.75163e-05
04/19/2022 20:38:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290360 Ep: 6.69 masked_t 0.483 masked_v 0.063 NSP 0.042 lr 1.75139e-05
04/19/2022 20:39:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290440 Ep: 6.69 masked_t 0.415 masked_v 0.065 NSP 0.039 lr 1.75115e-05
04/19/2022 20:40:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290520 Ep: 6.69 masked_t 0.431 masked_v 0.064 NSP 0.036 lr 1.7509e-05
04/19/2022 20:41:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290600 Ep: 6.70 masked_t 0.447 masked_v 0.066 NSP 0.040 lr 1.75066e-05
04/19/2022 20:42:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290680 Ep: 6.70 masked_t 0.414 masked_v 0.066 NSP 0.044 lr 1.75042e-05
04/19/2022 20:43:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290760 Ep: 6.70 masked_t 0.402 masked_v 0.064 NSP 0.039 lr 1.75018e-05
04/19/2022 20:44:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290840 Ep: 6.70 masked_t 0.436 masked_v 0.064 NSP 0.035 lr 1.74993e-05
04/19/2022 20:45:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 290920 Ep: 6.70 masked_t 0.407 masked_v 0.067 NSP 0.041 lr 1.74969e-05
04/19/2022 20:46:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291000 Ep: 6.70 masked_t 0.441 masked_v 0.066 NSP 0.045 lr 1.74945e-05
04/19/2022 20:46:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291080 Ep: 6.71 masked_t 0.415 masked_v 0.066 NSP 0.040 lr 1.74921e-05
04/19/2022 20:47:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291160 Ep: 6.71 masked_t 0.414 masked_v 0.067 NSP 0.044 lr 1.74896e-05
04/19/2022 20:48:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291240 Ep: 6.71 masked_t 0.466 masked_v 0.064 NSP 0.043 lr 1.74872e-05
04/19/2022 20:49:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291320 Ep: 6.71 masked_t 0.408 masked_v 0.065 NSP 0.043 lr 1.74848e-05
04/19/2022 20:50:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291400 Ep: 6.71 masked_t 0.385 masked_v 0.066 NSP 0.043 lr 1.74824e-05
04/19/2022 20:51:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291480 Ep: 6.72 masked_t 0.395 masked_v 0.066 NSP 0.041 lr 1.74799e-05
04/19/2022 20:52:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291560 Ep: 6.72 masked_t 0.407 masked_v 0.064 NSP 0.038 lr 1.74775e-05
04/19/2022 20:53:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291640 Ep: 6.72 masked_t 0.438 masked_v 0.069 NSP 0.037 lr 1.74751e-05
04/19/2022 20:54:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291720 Ep: 6.72 masked_t 0.417 masked_v 0.062 NSP 0.038 lr 1.74727e-05
04/19/2022 20:55:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291800 Ep: 6.72 masked_t 0.436 masked_v 0.067 NSP 0.035 lr 1.74702e-05
04/19/2022 20:56:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291880 Ep: 6.73 masked_t 0.426 masked_v 0.064 NSP 0.046 lr 1.74678e-05
04/19/2022 20:57:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 291960 Ep: 6.73 masked_t 0.449 masked_v 0.065 NSP 0.040 lr 1.74654e-05
04/19/2022 20:58:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292040 Ep: 6.73 masked_t 0.403 masked_v 0.066 NSP 0.039 lr 1.7463e-05
04/19/2022 20:59:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292120 Ep: 6.73 masked_t 0.403 masked_v 0.065 NSP 0.045 lr 1.74605e-05
04/19/2022 21:00:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292200 Ep: 6.73 masked_t 0.408 masked_v 0.065 NSP 0.043 lr 1.74581e-05
04/19/2022 21:01:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292280 Ep: 6.73 masked_t 0.434 masked_v 0.067 NSP 0.050 lr 1.74557e-05
04/19/2022 21:02:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292360 Ep: 6.74 masked_t 0.413 masked_v 0.064 NSP 0.040 lr 1.74533e-05
04/19/2022 21:03:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292440 Ep: 6.74 masked_t 0.406 masked_v 0.064 NSP 0.047 lr 1.74508e-05
04/19/2022 21:04:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292520 Ep: 6.74 masked_t 0.414 masked_v 0.069 NSP 0.044 lr 1.74484e-05
04/19/2022 21:05:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292600 Ep: 6.74 masked_t 0.404 masked_v 0.063 NSP 0.040 lr 1.7446e-05
04/19/2022 21:06:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292680 Ep: 6.74 masked_t 0.403 masked_v 0.061 NSP 0.036 lr 1.74435e-05
04/19/2022 21:07:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292760 Ep: 6.75 masked_t 0.426 masked_v 0.064 NSP 0.045 lr 1.74411e-05
04/19/2022 21:08:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292840 Ep: 6.75 masked_t 0.421 masked_v 0.069 NSP 0.042 lr 1.74387e-05
04/19/2022 21:09:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 292920 Ep: 6.75 masked_t 0.403 masked_v 0.064 NSP 0.040 lr 1.74363e-05
04/19/2022 21:10:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293000 Ep: 6.75 masked_t 0.397 masked_v 0.062 NSP 0.041 lr 1.74338e-05
04/19/2022 21:11:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293080 Ep: 6.75 masked_t 0.413 masked_v 0.067 NSP 0.038 lr 1.74314e-05
04/19/2022 21:11:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293160 Ep: 6.75 masked_t 0.413 masked_v 0.067 NSP 0.040 lr 1.7429e-05
04/19/2022 21:12:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293240 Ep: 6.76 masked_t 0.434 masked_v 0.065 NSP 0.046 lr 1.74266e-05
04/19/2022 21:13:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293320 Ep: 6.76 masked_t 0.481 masked_v 0.064 NSP 0.046 lr 1.74241e-05
04/19/2022 21:14:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293400 Ep: 6.76 masked_t 0.435 masked_v 0.065 NSP 0.036 lr 1.74217e-05
04/19/2022 21:15:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293480 Ep: 6.76 masked_t 0.415 masked_v 0.066 NSP 0.043 lr 1.74193e-05
04/19/2022 21:16:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293560 Ep: 6.76 masked_t 0.434 masked_v 0.067 NSP 0.045 lr 1.74169e-05
04/19/2022 21:17:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293640 Ep: 6.77 masked_t 0.407 masked_v 0.066 NSP 0.043 lr 1.74144e-05
04/19/2022 21:18:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293720 Ep: 6.77 masked_t 0.447 masked_v 0.065 NSP 0.042 lr 1.7412e-05
04/19/2022 21:19:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293800 Ep: 6.77 masked_t 0.426 masked_v 0.068 NSP 0.045 lr 1.74096e-05
04/19/2022 21:20:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293880 Ep: 6.77 masked_t 0.440 masked_v 0.068 NSP 0.037 lr 1.74072e-05
04/19/2022 21:21:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 293960 Ep: 6.77 masked_t 0.421 masked_v 0.065 NSP 0.047 lr 1.74047e-05
04/19/2022 21:22:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294040 Ep: 6.77 masked_t 0.425 masked_v 0.067 NSP 0.042 lr 1.74023e-05
04/19/2022 21:23:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294120 Ep: 6.78 masked_t 0.458 masked_v 0.065 NSP 0.042 lr 1.73999e-05
04/19/2022 21:24:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294200 Ep: 6.78 masked_t 0.383 masked_v 0.063 NSP 0.042 lr 1.73975e-05
04/19/2022 21:25:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294280 Ep: 6.78 masked_t 0.402 masked_v 0.064 NSP 0.038 lr 1.7395e-05
04/19/2022 21:26:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294360 Ep: 6.78 masked_t 0.416 masked_v 0.066 NSP 0.039 lr 1.73926e-05
04/19/2022 21:27:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294440 Ep: 6.78 masked_t 0.390 masked_v 0.070 NSP 0.042 lr 1.73902e-05
04/19/2022 21:28:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294520 Ep: 6.79 masked_t 0.412 masked_v 0.063 NSP 0.042 lr 1.73878e-05
04/19/2022 21:29:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294600 Ep: 6.79 masked_t 0.406 masked_v 0.063 NSP 0.040 lr 1.73853e-05
04/19/2022 21:30:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294680 Ep: 6.79 masked_t 0.417 masked_v 0.065 NSP 0.038 lr 1.73829e-05
04/19/2022 21:31:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294760 Ep: 6.79 masked_t 0.446 masked_v 0.065 NSP 0.044 lr 1.73805e-05
04/19/2022 21:32:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294840 Ep: 6.79 masked_t 0.447 masked_v 0.066 NSP 0.049 lr 1.73781e-05
04/19/2022 21:33:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 294920 Ep: 6.80 masked_t 0.430 masked_v 0.065 NSP 0.042 lr 1.73756e-05
04/19/2022 21:34:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295000 Ep: 6.80 masked_t 0.396 masked_v 0.066 NSP 0.040 lr 1.73732e-05
04/19/2022 21:35:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295080 Ep: 6.80 masked_t 0.402 masked_v 0.063 NSP 0.043 lr 1.73708e-05
04/19/2022 21:36:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295160 Ep: 6.80 masked_t 0.438 masked_v 0.063 NSP 0.049 lr 1.73684e-05
04/19/2022 21:36:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295240 Ep: 6.80 masked_t 0.415 masked_v 0.063 NSP 0.039 lr 1.73659e-05
04/19/2022 21:37:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295320 Ep: 6.80 masked_t 0.439 masked_v 0.063 NSP 0.043 lr 1.73635e-05
04/19/2022 21:38:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295400 Ep: 6.81 masked_t 0.411 masked_v 0.065 NSP 0.038 lr 1.73611e-05
04/19/2022 21:39:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295480 Ep: 6.81 masked_t 0.448 masked_v 0.067 NSP 0.042 lr 1.73587e-05
04/19/2022 21:40:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295560 Ep: 6.81 masked_t 0.434 masked_v 0.068 NSP 0.045 lr 1.73562e-05
04/19/2022 21:41:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295640 Ep: 6.81 masked_t 0.392 masked_v 0.068 NSP 0.042 lr 1.73538e-05
04/19/2022 21:42:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295720 Ep: 6.81 masked_t 0.416 masked_v 0.066 NSP 0.043 lr 1.73514e-05
04/19/2022 21:43:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295800 Ep: 6.82 masked_t 0.434 masked_v 0.065 NSP 0.036 lr 1.7349e-05
04/19/2022 21:44:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295880 Ep: 6.82 masked_t 0.417 masked_v 0.062 NSP 0.042 lr 1.73465e-05
04/19/2022 21:45:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 295960 Ep: 6.82 masked_t 0.405 masked_v 0.067 NSP 0.038 lr 1.73441e-05
04/19/2022 21:46:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296040 Ep: 6.82 masked_t 0.411 masked_v 0.066 NSP 0.044 lr 1.73417e-05
04/19/2022 21:47:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296120 Ep: 6.82 masked_t 0.423 masked_v 0.064 NSP 0.039 lr 1.73393e-05
04/19/2022 21:48:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296200 Ep: 6.82 masked_t 0.383 masked_v 0.062 NSP 0.041 lr 1.73368e-05
04/19/2022 21:49:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296280 Ep: 6.83 masked_t 0.391 masked_v 0.064 NSP 0.041 lr 1.73344e-05
04/19/2022 21:50:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296360 Ep: 6.83 masked_t 0.399 masked_v 0.065 NSP 0.045 lr 1.7332e-05
04/19/2022 21:51:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296440 Ep: 6.83 masked_t 0.434 masked_v 0.064 NSP 0.045 lr 1.73296e-05
04/19/2022 21:52:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296520 Ep: 6.83 masked_t 0.465 masked_v 0.064 NSP 0.047 lr 1.73271e-05
04/19/2022 21:53:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296600 Ep: 6.83 masked_t 0.366 masked_v 0.062 NSP 0.046 lr 1.73247e-05
04/19/2022 21:54:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296680 Ep: 6.84 masked_t 0.422 masked_v 0.068 NSP 0.041 lr 1.73223e-05
04/19/2022 21:55:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296760 Ep: 6.84 masked_t 0.413 masked_v 0.065 NSP 0.039 lr 1.73199e-05
04/19/2022 21:56:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296840 Ep: 6.84 masked_t 0.417 masked_v 0.067 NSP 0.043 lr 1.73174e-05
04/19/2022 21:57:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 296920 Ep: 6.84 masked_t 0.414 masked_v 0.064 NSP 0.038 lr 1.7315e-05
04/19/2022 21:58:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297000 Ep: 6.84 masked_t 0.443 masked_v 0.066 NSP 0.047 lr 1.73126e-05
04/19/2022 21:59:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297080 Ep: 6.85 masked_t 0.426 masked_v 0.065 NSP 0.041 lr 1.73102e-05
04/19/2022 22:00:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297160 Ep: 6.85 masked_t 0.432 masked_v 0.064 NSP 0.043 lr 1.73077e-05
04/19/2022 22:01:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297240 Ep: 6.85 masked_t 0.428 masked_v 0.063 NSP 0.038 lr 1.73053e-05
04/19/2022 22:01:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297320 Ep: 6.85 masked_t 0.414 masked_v 0.066 NSP 0.044 lr 1.73029e-05
04/19/2022 22:02:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297400 Ep: 6.85 masked_t 0.442 masked_v 0.064 NSP 0.040 lr 1.73004e-05
04/19/2022 22:03:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297480 Ep: 6.85 masked_t 0.461 masked_v 0.064 NSP 0.042 lr 1.7298e-05
04/19/2022 22:04:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297560 Ep: 6.86 masked_t 0.420 masked_v 0.064 NSP 0.041 lr 1.72956e-05
04/19/2022 22:05:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297640 Ep: 6.86 masked_t 0.437 masked_v 0.066 NSP 0.041 lr 1.72932e-05
04/19/2022 22:06:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297720 Ep: 6.86 masked_t 0.411 masked_v 0.064 NSP 0.038 lr 1.72907e-05
04/19/2022 22:07:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297800 Ep: 6.86 masked_t 0.469 masked_v 0.064 NSP 0.038 lr 1.72883e-05
04/19/2022 22:08:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297880 Ep: 6.86 masked_t 0.409 masked_v 0.066 NSP 0.051 lr 1.72859e-05
04/19/2022 22:09:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 297960 Ep: 6.87 masked_t 0.429 masked_v 0.070 NSP 0.041 lr 1.72835e-05
04/19/2022 22:10:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298040 Ep: 6.87 masked_t 0.445 masked_v 0.060 NSP 0.036 lr 1.7281e-05
04/19/2022 22:11:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298120 Ep: 6.87 masked_t 0.421 masked_v 0.067 NSP 0.042 lr 1.72786e-05
04/19/2022 22:12:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298200 Ep: 6.87 masked_t 0.408 masked_v 0.065 NSP 0.048 lr 1.72762e-05
04/19/2022 22:13:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298280 Ep: 6.87 masked_t 0.387 masked_v 0.063 NSP 0.039 lr 1.72738e-05
04/19/2022 22:14:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298360 Ep: 6.87 masked_t 0.437 masked_v 0.064 NSP 0.044 lr 1.72713e-05
04/19/2022 22:15:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298440 Ep: 6.88 masked_t 0.428 masked_v 0.066 NSP 0.041 lr 1.72689e-05
04/19/2022 22:16:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298520 Ep: 6.88 masked_t 0.417 masked_v 0.065 NSP 0.040 lr 1.72665e-05
04/19/2022 22:17:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298600 Ep: 6.88 masked_t 0.426 masked_v 0.066 NSP 0.037 lr 1.72641e-05
04/19/2022 22:18:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298680 Ep: 6.88 masked_t 0.405 masked_v 0.067 NSP 0.045 lr 1.72616e-05
04/19/2022 22:19:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298760 Ep: 6.88 masked_t 0.404 masked_v 0.065 NSP 0.046 lr 1.72592e-05
04/19/2022 22:20:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298840 Ep: 6.89 masked_t 0.381 masked_v 0.063 NSP 0.047 lr 1.72568e-05
04/19/2022 22:21:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 298920 Ep: 6.89 masked_t 0.417 masked_v 0.063 NSP 0.043 lr 1.72544e-05
04/19/2022 22:22:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299000 Ep: 6.89 masked_t 0.433 masked_v 0.065 NSP 0.041 lr 1.72519e-05
04/19/2022 22:23:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299080 Ep: 6.89 masked_t 0.390 masked_v 0.068 NSP 0.036 lr 1.72495e-05
04/19/2022 22:24:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299160 Ep: 6.89 masked_t 0.394 masked_v 0.068 NSP 0.040 lr 1.72471e-05
04/19/2022 22:25:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299240 Ep: 6.89 masked_t 0.462 masked_v 0.066 NSP 0.038 lr 1.72447e-05
04/19/2022 22:26:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299320 Ep: 6.90 masked_t 0.400 masked_v 0.065 NSP 0.041 lr 1.72422e-05
04/19/2022 22:27:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299400 Ep: 6.90 masked_t 0.437 masked_v 0.069 NSP 0.040 lr 1.72398e-05
04/19/2022 22:27:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299480 Ep: 6.90 masked_t 0.394 masked_v 0.063 NSP 0.045 lr 1.72374e-05
04/19/2022 22:28:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299560 Ep: 6.90 masked_t 0.436 masked_v 0.067 NSP 0.036 lr 1.7235e-05
04/19/2022 22:29:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299640 Ep: 6.90 masked_t 0.424 masked_v 0.064 NSP 0.044 lr 1.72325e-05
04/19/2022 22:30:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299720 Ep: 6.91 masked_t 0.410 masked_v 0.063 NSP 0.042 lr 1.72301e-05
04/19/2022 22:31:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299800 Ep: 6.91 masked_t 0.408 masked_v 0.063 NSP 0.044 lr 1.72277e-05
04/19/2022 22:32:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299880 Ep: 6.91 masked_t 0.443 masked_v 0.068 NSP 0.043 lr 1.72253e-05
04/19/2022 22:33:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 299960 Ep: 6.91 masked_t 0.405 masked_v 0.067 NSP 0.042 lr 1.72228e-05
04/19/2022 22:34:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300040 Ep: 6.91 masked_t 0.435 masked_v 0.067 NSP 0.038 lr 1.72204e-05
04/19/2022 22:35:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300120 Ep: 6.92 masked_t 0.373 masked_v 0.063 NSP 0.040 lr 1.7218e-05
04/19/2022 22:36:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300200 Ep: 6.92 masked_t 0.392 masked_v 0.062 NSP 0.041 lr 1.72156e-05
04/19/2022 22:37:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300280 Ep: 6.92 masked_t 0.440 masked_v 0.068 NSP 0.046 lr 1.72131e-05
04/19/2022 22:38:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300360 Ep: 6.92 masked_t 0.401 masked_v 0.066 NSP 0.045 lr 1.72107e-05
04/19/2022 22:39:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300440 Ep: 6.92 masked_t 0.438 masked_v 0.062 NSP 0.047 lr 1.72083e-05
04/19/2022 22:40:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300520 Ep: 6.92 masked_t 0.422 masked_v 0.062 NSP 0.045 lr 1.72059e-05
04/19/2022 22:41:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300600 Ep: 6.93 masked_t 0.474 masked_v 0.069 NSP 0.042 lr 1.72034e-05
04/19/2022 22:42:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300680 Ep: 6.93 masked_t 0.410 masked_v 0.069 NSP 0.040 lr 1.7201e-05
04/19/2022 22:43:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300760 Ep: 6.93 masked_t 0.398 masked_v 0.067 NSP 0.037 lr 1.71986e-05
04/19/2022 22:44:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300840 Ep: 6.93 masked_t 0.399 masked_v 0.063 NSP 0.038 lr 1.71962e-05
04/19/2022 22:45:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 300920 Ep: 6.93 masked_t 0.408 masked_v 0.068 NSP 0.042 lr 1.71937e-05
04/19/2022 22:46:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301000 Ep: 6.94 masked_t 0.407 masked_v 0.068 NSP 0.035 lr 1.71913e-05
04/19/2022 22:47:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301080 Ep: 6.94 masked_t 0.400 masked_v 0.064 NSP 0.041 lr 1.71889e-05
04/19/2022 22:48:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301160 Ep: 6.94 masked_t 0.419 masked_v 0.068 NSP 0.039 lr 1.71865e-05
04/19/2022 22:49:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301240 Ep: 6.94 masked_t 0.391 masked_v 0.065 NSP 0.040 lr 1.7184e-05
04/19/2022 22:50:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301320 Ep: 6.94 masked_t 0.397 masked_v 0.064 NSP 0.040 lr 1.71816e-05
04/19/2022 22:51:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301400 Ep: 6.94 masked_t 0.432 masked_v 0.065 NSP 0.042 lr 1.71792e-05
04/19/2022 22:52:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301480 Ep: 6.95 masked_t 0.387 masked_v 0.062 NSP 0.047 lr 1.71768e-05
04/19/2022 22:52:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301560 Ep: 6.95 masked_t 0.390 masked_v 0.064 NSP 0.043 lr 1.71743e-05
04/19/2022 22:53:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301640 Ep: 6.95 masked_t 0.444 masked_v 0.064 NSP 0.041 lr 1.71719e-05
04/19/2022 22:54:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301720 Ep: 6.95 masked_t 0.402 masked_v 0.069 NSP 0.043 lr 1.71695e-05
04/19/2022 22:55:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301800 Ep: 6.95 masked_t 0.425 masked_v 0.063 NSP 0.042 lr 1.71671e-05
04/19/2022 22:56:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301880 Ep: 6.96 masked_t 0.407 masked_v 0.064 NSP 0.041 lr 1.71646e-05
04/19/2022 22:57:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 301960 Ep: 6.96 masked_t 0.445 masked_v 0.066 NSP 0.044 lr 1.71622e-05
04/19/2022 22:58:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302040 Ep: 6.96 masked_t 0.412 masked_v 0.064 NSP 0.042 lr 1.71598e-05
04/19/2022 22:59:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302120 Ep: 6.96 masked_t 0.422 masked_v 0.066 NSP 0.045 lr 1.71573e-05
04/19/2022 23:00:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302200 Ep: 6.96 masked_t 0.419 masked_v 0.068 NSP 0.032 lr 1.71549e-05
04/19/2022 23:01:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302280 Ep: 6.96 masked_t 0.384 masked_v 0.064 NSP 0.037 lr 1.71525e-05
04/19/2022 23:02:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302360 Ep: 6.97 masked_t 0.384 masked_v 0.062 NSP 0.049 lr 1.71501e-05
04/19/2022 23:03:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302440 Ep: 6.97 masked_t 0.424 masked_v 0.068 NSP 0.041 lr 1.71476e-05
04/19/2022 23:04:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302520 Ep: 6.97 masked_t 0.437 masked_v 0.064 NSP 0.038 lr 1.71452e-05
04/19/2022 23:05:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302600 Ep: 6.97 masked_t 0.423 masked_v 0.061 NSP 0.039 lr 1.71428e-05
04/19/2022 23:06:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302680 Ep: 6.97 masked_t 0.393 masked_v 0.063 NSP 0.033 lr 1.71404e-05
04/19/2022 23:07:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302760 Ep: 6.98 masked_t 0.411 masked_v 0.067 NSP 0.051 lr 1.71379e-05
04/19/2022 23:08:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302840 Ep: 6.98 masked_t 0.461 masked_v 0.063 NSP 0.041 lr 1.71355e-05
04/19/2022 23:09:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 302920 Ep: 6.98 masked_t 0.426 masked_v 0.061 NSP 0.042 lr 1.71331e-05
04/19/2022 23:10:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303000 Ep: 6.98 masked_t 0.433 masked_v 0.065 NSP 0.044 lr 1.71307e-05
04/19/2022 23:11:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303080 Ep: 6.98 masked_t 0.424 masked_v 0.063 NSP 0.039 lr 1.71282e-05
04/19/2022 23:12:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303160 Ep: 6.99 masked_t 0.429 masked_v 0.063 NSP 0.042 lr 1.71258e-05
04/19/2022 23:13:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303240 Ep: 6.99 masked_t 0.414 masked_v 0.064 NSP 0.043 lr 1.71234e-05
04/19/2022 23:14:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303320 Ep: 6.99 masked_t 0.396 masked_v 0.061 NSP 0.036 lr 1.7121e-05
04/19/2022 23:15:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303400 Ep: 6.99 masked_t 0.425 masked_v 0.065 NSP 0.035 lr 1.71185e-05
04/19/2022 23:16:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303480 Ep: 6.99 masked_t 0.390 masked_v 0.065 NSP 0.046 lr 1.71161e-05
04/19/2022 23:17:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303560 Ep: 6.99 masked_t 0.426 masked_v 0.064 NSP 0.041 lr 1.71137e-05
04/19/2022 23:17:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303640 Ep: 7.00 masked_t 0.429 masked_v 0.063 NSP 0.042 lr 1.71113e-05
04/19/2022 23:18:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303720 Ep: 7.00 masked_t 0.405 masked_v 0.065 NSP 0.040 lr 1.71088e-05
04/19/2022 23:19:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303800 Ep: 7.00 masked_t 0.453 masked_v 0.067 NSP 0.044 lr 1.71064e-05
04/19/2022 23:20:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303880 Ep: 7.00 masked_t 0.419 masked_v 0.064 NSP 0.043 lr 1.7104e-05
04/19/2022 23:21:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 303960 Ep: 7.00 masked_t 0.401 masked_v 0.063 NSP 0.038 lr 1.71016e-05
04/19/2022 23:22:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304040 Ep: 7.01 masked_t 0.440 masked_v 0.063 NSP 0.039 lr 1.70991e-05
04/19/2022 23:23:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304120 Ep: 7.01 masked_t 0.431 masked_v 0.065 NSP 0.045 lr 1.70967e-05
04/19/2022 23:24:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304200 Ep: 7.01 masked_t 0.427 masked_v 0.065 NSP 0.044 lr 1.70943e-05
04/19/2022 23:25:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304280 Ep: 7.01 masked_t 0.426 masked_v 0.067 NSP 0.040 lr 1.70919e-05
04/19/2022 23:26:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304360 Ep: 7.01 masked_t 0.409 masked_v 0.064 NSP 0.044 lr 1.70894e-05
04/19/2022 23:27:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304440 Ep: 7.01 masked_t 0.407 masked_v 0.061 NSP 0.047 lr 1.7087e-05
04/19/2022 23:28:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304520 Ep: 7.02 masked_t 0.416 masked_v 0.063 NSP 0.042 lr 1.70846e-05
04/19/2022 23:29:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304600 Ep: 7.02 masked_t 0.397 masked_v 0.065 NSP 0.046 lr 1.70822e-05
04/19/2022 23:30:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304680 Ep: 7.02 masked_t 0.438 masked_v 0.063 NSP 0.033 lr 1.70797e-05
04/19/2022 23:31:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304760 Ep: 7.02 masked_t 0.408 masked_v 0.065 NSP 0.038 lr 1.70773e-05
04/19/2022 23:32:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304840 Ep: 7.02 masked_t 0.436 masked_v 0.064 NSP 0.043 lr 1.70749e-05
04/19/2022 23:33:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 304920 Ep: 7.03 masked_t 0.406 masked_v 0.066 NSP 0.042 lr 1.70725e-05
04/19/2022 23:34:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305000 Ep: 7.03 masked_t 0.432 masked_v 0.066 NSP 0.037 lr 1.707e-05
04/19/2022 23:35:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305080 Ep: 7.03 masked_t 0.446 masked_v 0.062 NSP 0.036 lr 1.70676e-05
04/19/2022 23:36:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305160 Ep: 7.03 masked_t 0.418 masked_v 0.067 NSP 0.040 lr 1.70652e-05
04/19/2022 23:37:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305240 Ep: 7.03 masked_t 0.415 masked_v 0.063 NSP 0.042 lr 1.70628e-05
04/19/2022 23:38:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305320 Ep: 7.03 masked_t 0.427 masked_v 0.068 NSP 0.042 lr 1.70603e-05
04/19/2022 23:39:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305400 Ep: 7.04 masked_t 0.416 masked_v 0.064 NSP 0.046 lr 1.70579e-05
04/19/2022 23:40:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305480 Ep: 7.04 masked_t 0.430 masked_v 0.064 NSP 0.038 lr 1.70555e-05
04/19/2022 23:41:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305560 Ep: 7.04 masked_t 0.379 masked_v 0.063 NSP 0.038 lr 1.70531e-05
04/19/2022 23:42:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305640 Ep: 7.04 masked_t 0.409 masked_v 0.063 NSP 0.036 lr 1.70506e-05
04/19/2022 23:42:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305720 Ep: 7.04 masked_t 0.409 masked_v 0.065 NSP 0.046 lr 1.70482e-05
04/19/2022 23:43:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305800 Ep: 7.05 masked_t 0.449 masked_v 0.065 NSP 0.044 lr 1.70458e-05
04/19/2022 23:44:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305880 Ep: 7.05 masked_t 0.376 masked_v 0.064 NSP 0.041 lr 1.70434e-05
04/19/2022 23:45:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 305960 Ep: 7.05 masked_t 0.395 masked_v 0.065 NSP 0.037 lr 1.70409e-05
04/19/2022 23:46:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306040 Ep: 7.05 masked_t 0.439 masked_v 0.068 NSP 0.040 lr 1.70385e-05
04/19/2022 23:47:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306120 Ep: 7.05 masked_t 0.429 masked_v 0.066 NSP 0.039 lr 1.70361e-05
04/19/2022 23:48:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306200 Ep: 7.06 masked_t 0.433 masked_v 0.065 NSP 0.044 lr 1.70337e-05
04/19/2022 23:49:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306280 Ep: 7.06 masked_t 0.444 masked_v 0.067 NSP 0.043 lr 1.70312e-05
04/19/2022 23:50:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306360 Ep: 7.06 masked_t 0.399 masked_v 0.066 NSP 0.040 lr 1.70288e-05
04/19/2022 23:51:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306440 Ep: 7.06 masked_t 0.394 masked_v 0.065 NSP 0.042 lr 1.70264e-05
04/19/2022 23:52:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306520 Ep: 7.06 masked_t 0.424 masked_v 0.064 NSP 0.047 lr 1.7024e-05
04/19/2022 23:53:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306600 Ep: 7.06 masked_t 0.414 masked_v 0.066 NSP 0.036 lr 1.70215e-05
04/19/2022 23:54:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306680 Ep: 7.07 masked_t 0.469 masked_v 0.063 NSP 0.041 lr 1.70191e-05
04/19/2022 23:55:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306760 Ep: 7.07 masked_t 0.408 masked_v 0.067 NSP 0.045 lr 1.70167e-05
04/19/2022 23:56:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306840 Ep: 7.07 masked_t 0.433 masked_v 0.066 NSP 0.036 lr 1.70142e-05
04/19/2022 23:57:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 306920 Ep: 7.07 masked_t 0.402 masked_v 0.068 NSP 0.045 lr 1.70118e-05
04/19/2022 23:58:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307000 Ep: 7.07 masked_t 0.401 masked_v 0.064 NSP 0.043 lr 1.70094e-05
04/19/2022 23:59:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307080 Ep: 7.08 masked_t 0.413 masked_v 0.067 NSP 0.038 lr 1.7007e-05
04/20/2022 00:00:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307160 Ep: 7.08 masked_t 0.414 masked_v 0.064 NSP 0.048 lr 1.70045e-05
04/20/2022 00:01:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307240 Ep: 7.08 masked_t 0.409 masked_v 0.066 NSP 0.040 lr 1.70021e-05
04/20/2022 00:02:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307320 Ep: 7.08 masked_t 0.395 masked_v 0.065 NSP 0.032 lr 1.69997e-05
04/20/2022 00:03:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307400 Ep: 7.08 masked_t 0.380 masked_v 0.063 NSP 0.038 lr 1.69973e-05
04/20/2022 00:04:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307480 Ep: 7.08 masked_t 0.438 masked_v 0.067 NSP 0.041 lr 1.69948e-05
04/20/2022 00:05:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307560 Ep: 7.09 masked_t 0.420 masked_v 0.063 NSP 0.042 lr 1.69924e-05
04/20/2022 00:06:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307640 Ep: 7.09 masked_t 0.449 masked_v 0.064 NSP 0.041 lr 1.699e-05
04/20/2022 00:07:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307720 Ep: 7.09 masked_t 0.407 masked_v 0.067 NSP 0.037 lr 1.69876e-05
04/20/2022 00:07:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307800 Ep: 7.09 masked_t 0.410 masked_v 0.066 NSP 0.035 lr 1.69851e-05
04/20/2022 00:08:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307880 Ep: 7.09 masked_t 0.438 masked_v 0.066 NSP 0.042 lr 1.69827e-05
04/20/2022 00:09:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 307960 Ep: 7.10 masked_t 0.427 masked_v 0.064 NSP 0.038 lr 1.69803e-05
04/20/2022 00:10:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308040 Ep: 7.10 masked_t 0.402 masked_v 0.066 NSP 0.041 lr 1.69779e-05
04/20/2022 00:11:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308120 Ep: 7.10 masked_t 0.461 masked_v 0.064 NSP 0.039 lr 1.69754e-05
04/20/2022 00:12:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308200 Ep: 7.10 masked_t 0.396 masked_v 0.063 NSP 0.039 lr 1.6973e-05
04/20/2022 00:13:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308280 Ep: 7.10 masked_t 0.466 masked_v 0.066 NSP 0.041 lr 1.69706e-05
04/20/2022 00:14:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308360 Ep: 7.10 masked_t 0.404 masked_v 0.067 NSP 0.043 lr 1.69682e-05
04/20/2022 00:15:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308440 Ep: 7.11 masked_t 0.429 masked_v 0.063 NSP 0.040 lr 1.69657e-05
04/20/2022 00:16:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308520 Ep: 7.11 masked_t 0.377 masked_v 0.063 NSP 0.038 lr 1.69633e-05
04/20/2022 00:17:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308600 Ep: 7.11 masked_t 0.439 masked_v 0.065 NSP 0.047 lr 1.69609e-05
04/20/2022 00:18:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308680 Ep: 7.11 masked_t 0.417 masked_v 0.065 NSP 0.044 lr 1.69585e-05
04/20/2022 00:19:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308760 Ep: 7.11 masked_t 0.413 masked_v 0.066 NSP 0.037 lr 1.6956e-05
04/20/2022 00:20:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308840 Ep: 7.12 masked_t 0.410 masked_v 0.065 NSP 0.052 lr 1.69536e-05
04/20/2022 00:21:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 308920 Ep: 7.12 masked_t 0.389 masked_v 0.061 NSP 0.036 lr 1.69512e-05
04/20/2022 00:22:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309000 Ep: 7.12 masked_t 0.405 masked_v 0.064 NSP 0.040 lr 1.69488e-05
04/20/2022 00:23:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309080 Ep: 7.12 masked_t 0.424 masked_v 0.065 NSP 0.034 lr 1.69463e-05
04/20/2022 00:24:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309160 Ep: 7.12 masked_t 0.425 masked_v 0.064 NSP 0.044 lr 1.69439e-05
04/20/2022 00:25:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309240 Ep: 7.13 masked_t 0.394 masked_v 0.066 NSP 0.042 lr 1.69415e-05
04/20/2022 00:26:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309320 Ep: 7.13 masked_t 0.454 masked_v 0.066 NSP 0.043 lr 1.69391e-05
04/20/2022 00:27:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309400 Ep: 7.13 masked_t 0.440 masked_v 0.062 NSP 0.043 lr 1.69366e-05
04/20/2022 00:28:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309480 Ep: 7.13 masked_t 0.431 masked_v 0.063 NSP 0.050 lr 1.69342e-05
04/20/2022 00:29:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309560 Ep: 7.13 masked_t 0.429 masked_v 0.067 NSP 0.039 lr 1.69318e-05
04/20/2022 00:30:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309640 Ep: 7.13 masked_t 0.389 masked_v 0.064 NSP 0.034 lr 1.69294e-05
04/20/2022 00:31:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309720 Ep: 7.14 masked_t 0.460 masked_v 0.065 NSP 0.040 lr 1.69269e-05
04/20/2022 00:32:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309800 Ep: 7.14 masked_t 0.418 masked_v 0.063 NSP 0.042 lr 1.69245e-05
04/20/2022 00:32:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309880 Ep: 7.14 masked_t 0.437 masked_v 0.062 NSP 0.039 lr 1.69221e-05
04/20/2022 00:33:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 309960 Ep: 7.14 masked_t 0.404 masked_v 0.067 NSP 0.039 lr 1.69197e-05
04/20/2022 00:34:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310040 Ep: 7.14 masked_t 0.410 masked_v 0.062 NSP 0.038 lr 1.69172e-05
04/20/2022 00:35:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310120 Ep: 7.15 masked_t 0.393 masked_v 0.064 NSP 0.039 lr 1.69148e-05
04/20/2022 00:36:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310200 Ep: 7.15 masked_t 0.438 masked_v 0.065 NSP 0.040 lr 1.69124e-05
04/20/2022 00:37:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310280 Ep: 7.15 masked_t 0.431 masked_v 0.070 NSP 0.039 lr 1.691e-05
04/20/2022 00:38:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310360 Ep: 7.15 masked_t 0.434 masked_v 0.068 NSP 0.042 lr 1.69075e-05
04/20/2022 00:39:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310440 Ep: 7.15 masked_t 0.383 masked_v 0.066 NSP 0.038 lr 1.69051e-05
04/20/2022 00:40:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310520 Ep: 7.15 masked_t 0.394 masked_v 0.065 NSP 0.043 lr 1.69027e-05
04/20/2022 00:41:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310600 Ep: 7.16 masked_t 0.410 masked_v 0.063 NSP 0.046 lr 1.69003e-05
04/20/2022 00:42:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310680 Ep: 7.16 masked_t 0.417 masked_v 0.062 NSP 0.041 lr 1.68978e-05
04/20/2022 00:43:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310760 Ep: 7.16 masked_t 0.450 masked_v 0.065 NSP 0.033 lr 1.68954e-05
04/20/2022 00:44:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310840 Ep: 7.16 masked_t 0.412 masked_v 0.061 NSP 0.039 lr 1.6893e-05
04/20/2022 00:45:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 310920 Ep: 7.16 masked_t 0.421 masked_v 0.066 NSP 0.042 lr 1.68906e-05
04/20/2022 00:46:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311000 Ep: 7.17 masked_t 0.390 masked_v 0.065 NSP 0.040 lr 1.68881e-05
04/20/2022 00:47:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311080 Ep: 7.17 masked_t 0.393 masked_v 0.065 NSP 0.039 lr 1.68857e-05
04/20/2022 00:48:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311160 Ep: 7.17 masked_t 0.391 masked_v 0.068 NSP 0.037 lr 1.68833e-05
04/20/2022 00:49:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311240 Ep: 7.17 masked_t 0.456 masked_v 0.065 NSP 0.046 lr 1.68809e-05
04/20/2022 00:50:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311320 Ep: 7.17 masked_t 0.423 masked_v 0.066 NSP 0.037 lr 1.68784e-05
04/20/2022 00:51:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311400 Ep: 7.17 masked_t 0.475 masked_v 0.068 NSP 0.042 lr 1.6876e-05
04/20/2022 00:52:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311480 Ep: 7.18 masked_t 0.406 masked_v 0.067 NSP 0.040 lr 1.68736e-05
04/20/2022 00:53:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311560 Ep: 7.18 masked_t 0.428 masked_v 0.065 NSP 0.046 lr 1.68711e-05
04/20/2022 00:54:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311640 Ep: 7.18 masked_t 0.385 masked_v 0.066 NSP 0.037 lr 1.68687e-05
04/20/2022 00:55:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311720 Ep: 7.18 masked_t 0.426 masked_v 0.068 NSP 0.043 lr 1.68663e-05
04/20/2022 00:56:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311800 Ep: 7.18 masked_t 0.394 masked_v 0.065 NSP 0.043 lr 1.68639e-05
04/20/2022 00:57:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311880 Ep: 7.19 masked_t 0.406 masked_v 0.061 NSP 0.042 lr 1.68614e-05
04/20/2022 00:57:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 311960 Ep: 7.19 masked_t 0.419 masked_v 0.069 NSP 0.039 lr 1.6859e-05
04/20/2022 00:58:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312040 Ep: 7.19 masked_t 0.386 masked_v 0.063 NSP 0.037 lr 1.68566e-05
04/20/2022 00:59:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312120 Ep: 7.19 masked_t 0.409 masked_v 0.064 NSP 0.047 lr 1.68542e-05
04/20/2022 01:00:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312200 Ep: 7.19 masked_t 0.426 masked_v 0.066 NSP 0.042 lr 1.68517e-05
04/20/2022 01:01:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312280 Ep: 7.20 masked_t 0.406 masked_v 0.063 NSP 0.046 lr 1.68493e-05
04/20/2022 01:02:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312360 Ep: 7.20 masked_t 0.424 masked_v 0.064 NSP 0.044 lr 1.68469e-05
04/20/2022 01:03:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312440 Ep: 7.20 masked_t 0.395 masked_v 0.067 NSP 0.038 lr 1.68445e-05
04/20/2022 01:04:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312520 Ep: 7.20 masked_t 0.379 masked_v 0.068 NSP 0.038 lr 1.6842e-05
04/20/2022 01:05:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312600 Ep: 7.20 masked_t 0.407 masked_v 0.065 NSP 0.034 lr 1.68396e-05
04/20/2022 01:06:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312680 Ep: 7.20 masked_t 0.406 masked_v 0.062 NSP 0.037 lr 1.68372e-05
04/20/2022 01:07:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312760 Ep: 7.21 masked_t 0.399 masked_v 0.063 NSP 0.034 lr 1.68348e-05
04/20/2022 01:08:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312840 Ep: 7.21 masked_t 0.407 masked_v 0.064 NSP 0.041 lr 1.68323e-05
04/20/2022 01:09:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 312920 Ep: 7.21 masked_t 0.424 masked_v 0.066 NSP 0.034 lr 1.68299e-05
04/20/2022 01:10:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313000 Ep: 7.21 masked_t 0.439 masked_v 0.064 NSP 0.039 lr 1.68275e-05
04/20/2022 01:11:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313080 Ep: 7.21 masked_t 0.404 masked_v 0.064 NSP 0.036 lr 1.68251e-05
04/20/2022 01:12:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313160 Ep: 7.22 masked_t 0.408 masked_v 0.061 NSP 0.044 lr 1.68226e-05
04/20/2022 01:13:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313240 Ep: 7.22 masked_t 0.431 masked_v 0.063 NSP 0.048 lr 1.68202e-05
04/20/2022 01:14:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313320 Ep: 7.22 masked_t 0.449 masked_v 0.063 NSP 0.035 lr 1.68178e-05
04/20/2022 01:15:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313400 Ep: 7.22 masked_t 0.387 masked_v 0.065 NSP 0.043 lr 1.68154e-05
04/20/2022 01:16:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313480 Ep: 7.22 masked_t 0.413 masked_v 0.065 NSP 0.045 lr 1.68129e-05
04/20/2022 01:17:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313560 Ep: 7.22 masked_t 0.444 masked_v 0.062 NSP 0.048 lr 1.68105e-05
04/20/2022 01:18:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313640 Ep: 7.23 masked_t 0.429 masked_v 0.062 NSP 0.039 lr 1.68081e-05
04/20/2022 01:19:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313720 Ep: 7.23 masked_t 0.383 masked_v 0.066 NSP 0.048 lr 1.68057e-05
04/20/2022 01:20:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313800 Ep: 7.23 masked_t 0.422 masked_v 0.067 NSP 0.044 lr 1.68032e-05
04/20/2022 01:21:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313880 Ep: 7.23 masked_t 0.393 masked_v 0.063 NSP 0.044 lr 1.68008e-05
04/20/2022 01:22:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 313960 Ep: 7.23 masked_t 0.399 masked_v 0.066 NSP 0.038 lr 1.67984e-05
04/20/2022 01:22:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314040 Ep: 7.24 masked_t 0.408 masked_v 0.064 NSP 0.041 lr 1.6796e-05
04/20/2022 01:23:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314120 Ep: 7.24 masked_t 0.380 masked_v 0.064 NSP 0.035 lr 1.67935e-05
04/20/2022 01:24:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314200 Ep: 7.24 masked_t 0.433 masked_v 0.064 NSP 0.040 lr 1.67911e-05
04/20/2022 01:25:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314280 Ep: 7.24 masked_t 0.417 masked_v 0.061 NSP 0.043 lr 1.67887e-05
04/20/2022 01:26:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314360 Ep: 7.24 masked_t 0.406 masked_v 0.066 NSP 0.045 lr 1.67863e-05
04/20/2022 01:27:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314440 Ep: 7.25 masked_t 0.429 masked_v 0.068 NSP 0.041 lr 1.67838e-05
04/20/2022 01:28:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314520 Ep: 7.25 masked_t 0.433 masked_v 0.065 NSP 0.045 lr 1.67814e-05
04/20/2022 01:29:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314600 Ep: 7.25 masked_t 0.442 masked_v 0.063 NSP 0.043 lr 1.6779e-05
04/20/2022 01:30:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314680 Ep: 7.25 masked_t 0.460 masked_v 0.067 NSP 0.041 lr 1.67766e-05
04/20/2022 01:31:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314760 Ep: 7.25 masked_t 0.447 masked_v 0.064 NSP 0.037 lr 1.67741e-05
04/20/2022 01:32:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314840 Ep: 7.25 masked_t 0.418 masked_v 0.061 NSP 0.040 lr 1.67717e-05
04/20/2022 01:33:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 314920 Ep: 7.26 masked_t 0.425 masked_v 0.067 NSP 0.038 lr 1.67693e-05
04/20/2022 01:34:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315000 Ep: 7.26 masked_t 0.406 masked_v 0.066 NSP 0.040 lr 1.67669e-05
04/20/2022 01:35:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315080 Ep: 7.26 masked_t 0.436 masked_v 0.064 NSP 0.041 lr 1.67644e-05
04/20/2022 01:36:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315160 Ep: 7.26 masked_t 0.386 masked_v 0.065 NSP 0.046 lr 1.6762e-05
04/20/2022 01:37:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315240 Ep: 7.26 masked_t 0.436 masked_v 0.064 NSP 0.042 lr 1.67596e-05
04/20/2022 01:38:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315320 Ep: 7.27 masked_t 0.407 masked_v 0.064 NSP 0.039 lr 1.67572e-05
04/20/2022 01:39:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315400 Ep: 7.27 masked_t 0.378 masked_v 0.066 NSP 0.044 lr 1.67547e-05
04/20/2022 01:40:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315480 Ep: 7.27 masked_t 0.424 masked_v 0.064 NSP 0.037 lr 1.67523e-05
04/20/2022 01:41:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315560 Ep: 7.27 masked_t 0.376 masked_v 0.062 NSP 0.040 lr 1.67499e-05
04/20/2022 01:42:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315640 Ep: 7.27 masked_t 0.424 masked_v 0.068 NSP 0.042 lr 1.67475e-05
04/20/2022 01:43:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315720 Ep: 7.27 masked_t 0.412 masked_v 0.061 NSP 0.040 lr 1.6745e-05
04/20/2022 01:44:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315800 Ep: 7.28 masked_t 0.434 masked_v 0.066 NSP 0.044 lr 1.67426e-05
04/20/2022 01:45:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315880 Ep: 7.28 masked_t 0.420 masked_v 0.064 NSP 0.046 lr 1.67402e-05
04/20/2022 01:46:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 315960 Ep: 7.28 masked_t 0.382 masked_v 0.063 NSP 0.045 lr 1.67378e-05
04/20/2022 01:47:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316040 Ep: 7.28 masked_t 0.430 masked_v 0.065 NSP 0.043 lr 1.67353e-05
04/20/2022 01:47:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316120 Ep: 7.28 masked_t 0.396 masked_v 0.064 NSP 0.042 lr 1.67329e-05
04/20/2022 01:48:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316200 Ep: 7.29 masked_t 0.457 masked_v 0.066 NSP 0.041 lr 1.67305e-05
04/20/2022 01:49:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316280 Ep: 7.29 masked_t 0.413 masked_v 0.066 NSP 0.042 lr 1.6728e-05
04/20/2022 01:50:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316360 Ep: 7.29 masked_t 0.384 masked_v 0.067 NSP 0.035 lr 1.67256e-05
04/20/2022 01:51:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316440 Ep: 7.29 masked_t 0.410 masked_v 0.066 NSP 0.043 lr 1.67232e-05
04/20/2022 01:52:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316520 Ep: 7.29 masked_t 0.455 masked_v 0.064 NSP 0.045 lr 1.67208e-05
04/20/2022 01:53:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316600 Ep: 7.29 masked_t 0.457 masked_v 0.064 NSP 0.046 lr 1.67183e-05
04/20/2022 01:54:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316680 Ep: 7.30 masked_t 0.406 masked_v 0.064 NSP 0.045 lr 1.67159e-05
04/20/2022 01:55:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316760 Ep: 7.30 masked_t 0.442 masked_v 0.062 NSP 0.044 lr 1.67135e-05
04/20/2022 01:56:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316840 Ep: 7.30 masked_t 0.423 masked_v 0.063 NSP 0.036 lr 1.67111e-05
04/20/2022 01:57:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 316920 Ep: 7.30 masked_t 0.397 masked_v 0.063 NSP 0.034 lr 1.67086e-05
04/20/2022 01:58:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317000 Ep: 7.30 masked_t 0.429 masked_v 0.062 NSP 0.040 lr 1.67062e-05
04/20/2022 01:59:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317080 Ep: 7.31 masked_t 0.393 masked_v 0.064 NSP 0.039 lr 1.67038e-05
04/20/2022 02:00:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317160 Ep: 7.31 masked_t 0.382 masked_v 0.065 NSP 0.044 lr 1.67014e-05
04/20/2022 02:01:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317240 Ep: 7.31 masked_t 0.405 masked_v 0.061 NSP 0.035 lr 1.66989e-05
04/20/2022 02:02:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317320 Ep: 7.31 masked_t 0.411 masked_v 0.062 NSP 0.039 lr 1.66965e-05
04/20/2022 02:03:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317400 Ep: 7.31 masked_t 0.385 masked_v 0.065 NSP 0.040 lr 1.66941e-05
04/20/2022 02:04:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317480 Ep: 7.32 masked_t 0.450 masked_v 0.065 NSP 0.039 lr 1.66917e-05
04/20/2022 02:05:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317560 Ep: 7.32 masked_t 0.425 masked_v 0.066 NSP 0.040 lr 1.66892e-05
04/20/2022 02:06:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317640 Ep: 7.32 masked_t 0.392 masked_v 0.063 NSP 0.045 lr 1.66868e-05
04/20/2022 02:07:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317720 Ep: 7.32 masked_t 0.409 masked_v 0.062 NSP 0.042 lr 1.66844e-05
04/20/2022 02:08:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317800 Ep: 7.32 masked_t 0.453 masked_v 0.061 NSP 0.037 lr 1.6682e-05
04/20/2022 02:09:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317880 Ep: 7.32 masked_t 0.439 masked_v 0.066 NSP 0.046 lr 1.66795e-05
04/20/2022 02:10:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 317960 Ep: 7.33 masked_t 0.437 masked_v 0.069 NSP 0.038 lr 1.66771e-05
04/20/2022 02:11:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318040 Ep: 7.33 masked_t 0.414 masked_v 0.068 NSP 0.035 lr 1.66747e-05
04/20/2022 02:12:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318120 Ep: 7.33 masked_t 0.383 masked_v 0.064 NSP 0.041 lr 1.66723e-05
04/20/2022 02:12:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318200 Ep: 7.33 masked_t 0.406 masked_v 0.067 NSP 0.039 lr 1.66698e-05
04/20/2022 02:13:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318280 Ep: 7.33 masked_t 0.426 masked_v 0.065 NSP 0.038 lr 1.66674e-05
04/20/2022 02:14:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318360 Ep: 7.34 masked_t 0.434 masked_v 0.063 NSP 0.043 lr 1.6665e-05
04/20/2022 02:15:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318440 Ep: 7.34 masked_t 0.379 masked_v 0.062 NSP 0.042 lr 1.66626e-05
04/20/2022 02:16:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318520 Ep: 7.34 masked_t 0.416 masked_v 0.064 NSP 0.046 lr 1.66601e-05
04/20/2022 02:17:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318600 Ep: 7.34 masked_t 0.431 masked_v 0.062 NSP 0.041 lr 1.66577e-05
04/20/2022 02:18:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318680 Ep: 7.34 masked_t 0.399 masked_v 0.062 NSP 0.032 lr 1.66553e-05
04/20/2022 02:19:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318760 Ep: 7.34 masked_t 0.425 masked_v 0.065 NSP 0.044 lr 1.66529e-05
04/20/2022 02:20:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318840 Ep: 7.35 masked_t 0.390 masked_v 0.066 NSP 0.038 lr 1.66504e-05
04/20/2022 02:21:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 318920 Ep: 7.35 masked_t 0.420 masked_v 0.066 NSP 0.043 lr 1.6648e-05
04/20/2022 02:22:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319000 Ep: 7.35 masked_t 0.415 masked_v 0.066 NSP 0.039 lr 1.66456e-05
04/20/2022 02:23:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319080 Ep: 7.35 masked_t 0.387 masked_v 0.067 NSP 0.043 lr 1.66432e-05
04/20/2022 02:24:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319160 Ep: 7.35 masked_t 0.451 masked_v 0.059 NSP 0.039 lr 1.66407e-05
04/20/2022 02:25:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319240 Ep: 7.36 masked_t 0.396 masked_v 0.061 NSP 0.042 lr 1.66383e-05
04/20/2022 02:26:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319320 Ep: 7.36 masked_t 0.434 masked_v 0.064 NSP 0.040 lr 1.66359e-05
04/20/2022 02:27:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319400 Ep: 7.36 masked_t 0.428 masked_v 0.062 NSP 0.043 lr 1.66335e-05
04/20/2022 02:28:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319480 Ep: 7.36 masked_t 0.407 masked_v 0.062 NSP 0.042 lr 1.6631e-05
04/20/2022 02:29:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319560 Ep: 7.36 masked_t 0.412 masked_v 0.064 NSP 0.041 lr 1.66286e-05
04/20/2022 02:30:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319640 Ep: 7.36 masked_t 0.433 masked_v 0.064 NSP 0.038 lr 1.66262e-05
04/20/2022 02:31:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319720 Ep: 7.37 masked_t 0.405 masked_v 0.064 NSP 0.039 lr 1.66238e-05
04/20/2022 02:32:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319800 Ep: 7.37 masked_t 0.416 masked_v 0.068 NSP 0.048 lr 1.66213e-05
04/20/2022 02:33:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319880 Ep: 7.37 masked_t 0.432 masked_v 0.063 NSP 0.035 lr 1.66189e-05
04/20/2022 02:34:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 319960 Ep: 7.37 masked_t 0.397 masked_v 0.065 NSP 0.041 lr 1.66165e-05
04/20/2022 02:34:37 - INFO - __main__ -   ** ** * Saving model * ** ** 
04/20/2022 02:35:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320040 Ep: 7.37 masked_t 0.433 masked_v 0.065 NSP 0.042 lr 1.66141e-05
04/20/2022 02:36:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320120 Ep: 7.38 masked_t 0.373 masked_v 0.065 NSP 0.038 lr 1.66116e-05
04/20/2022 02:37:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320200 Ep: 7.38 masked_t 0.372 masked_v 0.064 NSP 0.038 lr 1.66092e-05
04/20/2022 02:38:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320280 Ep: 7.38 masked_t 0.450 masked_v 0.061 NSP 0.042 lr 1.66068e-05
04/20/2022 02:39:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320360 Ep: 7.38 masked_t 0.462 masked_v 0.067 NSP 0.042 lr 1.66044e-05
04/20/2022 02:40:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320440 Ep: 7.38 masked_t 0.399 masked_v 0.065 NSP 0.042 lr 1.66019e-05
04/20/2022 02:41:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320520 Ep: 7.39 masked_t 0.394 masked_v 0.063 NSP 0.042 lr 1.65995e-05
04/20/2022 02:42:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320600 Ep: 7.39 masked_t 0.406 masked_v 0.063 NSP 0.043 lr 1.65971e-05
04/20/2022 02:43:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320680 Ep: 7.39 masked_t 0.418 masked_v 0.063 NSP 0.039 lr 1.65947e-05
04/20/2022 02:44:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320760 Ep: 7.39 masked_t 0.394 masked_v 0.066 NSP 0.040 lr 1.65922e-05
04/20/2022 02:45:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320840 Ep: 7.39 masked_t 0.426 masked_v 0.066 NSP 0.040 lr 1.65898e-05
04/20/2022 02:46:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320920 Ep: 7.39 masked_t 0.410 masked_v 0.068 NSP 0.042 lr 1.65874e-05
04/20/2022 02:47:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321000 Ep: 7.40 masked_t 0.363 masked_v 0.064 NSP 0.043 lr 1.6585e-05
04/20/2022 02:48:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321080 Ep: 7.40 masked_t 0.399 masked_v 0.061 NSP 0.045 lr 1.65825e-05
04/20/2022 02:49:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321160 Ep: 7.40 masked_t 0.379 masked_v 0.064 NSP 0.043 lr 1.65801e-05
04/20/2022 02:50:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321240 Ep: 7.40 masked_t 0.400 masked_v 0.063 NSP 0.040 lr 1.65777e-05
04/20/2022 02:51:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321320 Ep: 7.40 masked_t 0.422 masked_v 0.061 NSP 0.044 lr 1.65752e-05
04/20/2022 02:51:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321400 Ep: 7.41 masked_t 0.389 masked_v 0.063 NSP 0.036 lr 1.65728e-05
04/20/2022 02:52:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321480 Ep: 7.41 masked_t 0.422 masked_v 0.063 NSP 0.038 lr 1.65704e-05
04/20/2022 02:53:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321560 Ep: 7.41 masked_t 0.417 masked_v 0.064 NSP 0.044 lr 1.6568e-05
04/20/2022 02:54:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321640 Ep: 7.41 masked_t 0.408 masked_v 0.067 NSP 0.042 lr 1.65655e-05
04/20/2022 02:55:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321720 Ep: 7.41 masked_t 0.425 masked_v 0.066 NSP 0.039 lr 1.65631e-05
04/20/2022 02:56:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321800 Ep: 7.41 masked_t 0.375 masked_v 0.066 NSP 0.037 lr 1.65607e-05
04/20/2022 02:57:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321880 Ep: 7.42 masked_t 0.424 masked_v 0.064 NSP 0.045 lr 1.65583e-05
04/20/2022 02:58:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 321960 Ep: 7.42 masked_t 0.391 masked_v 0.065 NSP 0.041 lr 1.65558e-05
slurmstepd: error: *** JOB 2128126 ON a00861 CANCELLED AT 2022-04-20T02:59:11 DUE TO TIME LIMIT ***
