train_batch_size:256
strategy:random_lg
WARNING:tensorflow:From /home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

04/19/2022 10:40:19 - INFO - __main__ -   device: cuda n_gpu: 2, distributed training: False
Loading from /science/image/nlp-datasets/emanuele/data/conceptual_captions/resnet101_faster_rcnn_genome_imgfeats/volta/training_feat_all.lmdb
[32m[0419 10:40:25 @format.py:92][0m Found 2777649 entries in /science/image/nlp-datasets/emanuele/data/conceptual_captions/resnet101_faster_rcnn_genome_imgfeats/volta/training_feat_all.lmdb
[32m[0419 10:41:13 @parallel.py:309][0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0419 10:41:13 @argtools.py:146][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0419 10:41:13 @argtools.py:146][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
04/19/2022 10:41:15 - INFO - volta.train_utils -   logging file at: /science/image/nlp-datasets/tt-mml/logs/pretrain/ctrl_ttmml_random_lg/ctrl_xuniter_base/train_batch_size_256/conceptual_captions-random_lg/ctrl_xuniter_base
04/19/2022 10:41:16 - INFO - volta.utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin from cache at /home/mwp141/.pytorch_pretrained_bert/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267
04/19/2022 10:41:34 - INFO - volta.utils -   
04/19/2022 10:41:35 - INFO - volta.utils -   Weights of BertForVLPreTraining not initialized from pretrained model: ['bert.embeddings.image_embeddings.weight', 'bert.embeddings.image_embeddings.bias', 'bert.embeddings.image_location_embeddings.weight', 'bert.embeddings.image_location_embeddings.bias', 'bert.embeddings.image_token_type_embeddings.weight', 'bert.embeddings.image_layer_norm.weight', 'bert.embeddings.image_layer_norm.bias', 'bert.embeddings.image_location_layer_norm.weight', 'bert.embeddings.image_location_layer_norm.bias', 'bert.embeddings.v_LayerNorm.weight', 'bert.embeddings.v_LayerNorm.bias', 'bert.encoder.layer.0.attention_self.v_query.weight', 'bert.encoder.layer.0.attention_self.v_query.bias', 'bert.encoder.layer.0.attention_self.v_key.weight', 'bert.encoder.layer.0.attention_self.v_key.bias', 'bert.encoder.layer.0.attention_self.v_value.weight', 'bert.encoder.layer.0.attention_self.v_value.bias', 'bert.encoder.layer.0.attention_output.v_dense.weight', 'bert.encoder.layer.0.attention_output.v_dense.bias', 'bert.encoder.layer.0.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.0.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.1.intermediate.v_dense.weight', 'bert.encoder.layer.1.intermediate.v_dense.bias', 'bert.encoder.layer.1.output.v_dense.weight', 'bert.encoder.layer.1.output.v_dense.bias', 'bert.encoder.layer.1.output.v_LayerNorm.weight', 'bert.encoder.layer.1.output.v_LayerNorm.bias', 'bert.encoder.layer.2.attention_self.v_query.weight', 'bert.encoder.layer.2.attention_self.v_query.bias', 'bert.encoder.layer.2.attention_self.v_key.weight', 'bert.encoder.layer.2.attention_self.v_key.bias', 'bert.encoder.layer.2.attention_self.v_value.weight', 'bert.encoder.layer.2.attention_self.v_value.bias', 'bert.encoder.layer.2.attention_output.v_dense.weight', 'bert.encoder.layer.2.attention_output.v_dense.bias', 'bert.encoder.layer.2.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.2.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.3.intermediate.v_dense.weight', 'bert.encoder.layer.3.intermediate.v_dense.bias', 'bert.encoder.layer.3.output.v_dense.weight', 'bert.encoder.layer.3.output.v_dense.bias', 'bert.encoder.layer.3.output.v_LayerNorm.weight', 'bert.encoder.layer.3.output.v_LayerNorm.bias', 'bert.encoder.layer.4.attention_self.v_query.weight', 'bert.encoder.layer.4.attention_self.v_query.bias', 'bert.encoder.layer.4.attention_self.v_key.weight', 'bert.encoder.layer.4.attention_self.v_key.bias', 'bert.encoder.layer.4.attention_self.v_value.weight', 'bert.encoder.layer.4.attention_self.v_value.bias', 'bert.encoder.layer.4.attention_output.v_dense.weight', 'bert.encoder.layer.4.attention_output.v_dense.bias', 'bert.encoder.layer.4.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.4.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.5.intermediate.v_dense.weight', 'bert.encoder.layer.5.intermediate.v_dense.bias', 'bert.encoder.layer.5.output.v_dense.weight', 'bert.encoder.layer.5.output.v_dense.bias', 'bert.encoder.layer.5.output.v_LayerNorm.weight', 'bert.encoder.layer.5.output.v_LayerNorm.bias', 'bert.encoder.layer.6.attention_self.v_query.weight', 'bert.encoder.layer.6.attention_self.v_query.bias', 'bert.encoder.layer.6.attention_self.v_key.weight', 'bert.encoder.layer.6.attention_self.v_key.bias', 'bert.encoder.layer.6.attention_self.v_value.weight', 'bert.encoder.layer.6.attention_self.v_value.bias', 'bert.encoder.layer.6.attention_output.v_dense.weight', 'bert.encoder.layer.6.attention_output.v_dense.bias', 'bert.encoder.layer.6.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.6.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.7.intermediate.v_dense.weight', 'bert.encoder.layer.7.intermediate.v_dense.bias', 'bert.encoder.layer.7.output.v_dense.weight', 'bert.encoder.layer.7.output.v_dense.bias', 'bert.encoder.layer.7.output.v_LayerNorm.weight', 'bert.encoder.layer.7.output.v_LayerNorm.bias', 'bert.encoder.layer.8.attention_self.v_query.weight', 'bert.encoder.layer.8.attention_self.v_query.bias', 'bert.encoder.layer.8.attention_self.v_key.weight', 'bert.encoder.layer.8.attention_self.v_key.bias', 'bert.encoder.layer.8.attention_self.v_value.weight', 'bert.encoder.layer.8.attention_self.v_value.bias', 'bert.encoder.layer.8.attention_output.v_dense.weight', 'bert.encoder.layer.8.attention_output.v_dense.bias', 'bert.encoder.layer.8.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.8.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.9.intermediate.v_dense.weight', 'bert.encoder.layer.9.intermediate.v_dense.bias', 'bert.encoder.layer.9.output.v_dense.weight', 'bert.encoder.layer.9.output.v_dense.bias', 'bert.encoder.layer.9.output.v_LayerNorm.weight', 'bert.encoder.layer.9.output.v_LayerNorm.bias', 'bert.encoder.layer.10.attention_self.v_query.weight', 'bert.encoder.layer.10.attention_self.v_query.bias', 'bert.encoder.layer.10.attention_self.v_key.weight', 'bert.encoder.layer.10.attention_self.v_key.bias', 'bert.encoder.layer.10.attention_self.v_value.weight', 'bert.encoder.layer.10.attention_self.v_value.bias', 'bert.encoder.layer.10.attention_output.v_dense.weight', 'bert.encoder.layer.10.attention_output.v_dense.bias', 'bert.encoder.layer.10.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.10.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.11.intermediate.v_dense.weight', 'bert.encoder.layer.11.intermediate.v_dense.bias', 'bert.encoder.layer.11.output.v_dense.weight', 'bert.encoder.layer.11.output.v_dense.bias', 'bert.encoder.layer.11.output.v_LayerNorm.weight', 'bert.encoder.layer.11.output.v_LayerNorm.bias', 'bert.encoder.layer.12.attention_self.v_query.weight', 'bert.encoder.layer.12.attention_self.v_query.bias', 'bert.encoder.layer.12.attention_self.v_key.weight', 'bert.encoder.layer.12.attention_self.v_key.bias', 'bert.encoder.layer.12.attention_self.v_value.weight', 'bert.encoder.layer.12.attention_self.v_value.bias', 'bert.encoder.layer.12.attention_output.v_dense.weight', 'bert.encoder.layer.12.attention_output.v_dense.bias', 'bert.encoder.layer.12.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.12.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.13.intermediate.v_dense.weight', 'bert.encoder.layer.13.intermediate.v_dense.bias', 'bert.encoder.layer.13.output.v_dense.weight', 'bert.encoder.layer.13.output.v_dense.bias', 'bert.encoder.layer.13.output.v_LayerNorm.weight', 'bert.encoder.layer.13.output.v_LayerNorm.bias', 'bert.encoder.layer.14.attention_self.v_query.weight', 'bert.encoder.layer.14.attention_self.v_query.bias', 'bert.encoder.layer.14.attention_self.v_key.weight', 'bert.encoder.layer.14.attention_self.v_key.bias', 'bert.encoder.layer.14.attention_self.v_value.weight', 'bert.encoder.layer.14.attention_self.v_value.bias', 'bert.encoder.layer.14.attention_output.v_dense.weight', 'bert.encoder.layer.14.attention_output.v_dense.bias', 'bert.encoder.layer.14.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.14.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.15.intermediate.v_dense.weight', 'bert.encoder.layer.15.intermediate.v_dense.bias', 'bert.encoder.layer.15.output.v_dense.weight', 'bert.encoder.layer.15.output.v_dense.bias', 'bert.encoder.layer.15.output.v_LayerNorm.weight', 'bert.encoder.layer.15.output.v_LayerNorm.bias', 'bert.encoder.layer.16.attention_self.v_query.weight', 'bert.encoder.layer.16.attention_self.v_query.bias', 'bert.encoder.layer.16.attention_self.v_key.weight', 'bert.encoder.layer.16.attention_self.v_key.bias', 'bert.encoder.layer.16.attention_self.v_value.weight', 'bert.encoder.layer.16.attention_self.v_value.bias', 'bert.encoder.layer.16.attention_output.v_dense.weight', 'bert.encoder.layer.16.attention_output.v_dense.bias', 'bert.encoder.layer.16.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.16.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.17.intermediate.v_dense.weight', 'bert.encoder.layer.17.intermediate.v_dense.bias', 'bert.encoder.layer.17.output.v_dense.weight', 'bert.encoder.layer.17.output.v_dense.bias', 'bert.encoder.layer.17.output.v_LayerNorm.weight', 'bert.encoder.layer.17.output.v_LayerNorm.bias', 'bert.encoder.layer.18.attention_self.v_query.weight', 'bert.encoder.layer.18.attention_self.v_query.bias', 'bert.encoder.layer.18.attention_self.v_key.weight', 'bert.encoder.layer.18.attention_self.v_key.bias', 'bert.encoder.layer.18.attention_self.v_value.weight', 'bert.encoder.layer.18.attention_self.v_value.bias', 'bert.encoder.layer.18.attention_output.v_dense.weight', 'bert.encoder.layer.18.attention_output.v_dense.bias', 'bert.encoder.layer.18.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.18.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.19.intermediate.v_dense.weight', 'bert.encoder.layer.19.intermediate.v_dense.bias', 'bert.encoder.layer.19.output.v_dense.weight', 'bert.encoder.layer.19.output.v_dense.bias', 'bert.encoder.layer.19.output.v_LayerNorm.weight', 'bert.encoder.layer.19.output.v_LayerNorm.bias', 'bert.encoder.layer.20.attention_self.v_query.weight', 'bert.encoder.layer.20.attention_self.v_query.bias', 'bert.encoder.layer.20.attention_self.v_key.weight', 'bert.encoder.layer.20.attention_self.v_key.bias', 'bert.encoder.layer.20.attention_self.v_value.weight', 'bert.encoder.layer.20.attention_self.v_value.bias', 'bert.encoder.layer.20.attention_output.v_dense.weight', 'bert.encoder.layer.20.attention_output.v_dense.bias', 'bert.encoder.layer.20.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.20.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.21.intermediate.v_dense.weight', 'bert.encoder.layer.21.intermediate.v_dense.bias', 'bert.encoder.layer.21.output.v_dense.weight', 'bert.encoder.layer.21.output.v_dense.bias', 'bert.encoder.layer.21.output.v_LayerNorm.weight', 'bert.encoder.layer.21.output.v_LayerNorm.bias', 'bert.encoder.layer.22.attention_self.v_query.weight', 'bert.encoder.layer.22.attention_self.v_query.bias', 'bert.encoder.layer.22.attention_self.v_key.weight', 'bert.encoder.layer.22.attention_self.v_key.bias', 'bert.encoder.layer.22.attention_self.v_value.weight', 'bert.encoder.layer.22.attention_self.v_value.bias', 'bert.encoder.layer.22.attention_output.v_dense.weight', 'bert.encoder.layer.22.attention_output.v_dense.bias', 'bert.encoder.layer.22.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.22.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.23.intermediate.v_dense.weight', 'bert.encoder.layer.23.intermediate.v_dense.bias', 'bert.encoder.layer.23.output.v_dense.weight', 'bert.encoder.layer.23.output.v_dense.bias', 'bert.encoder.layer.23.output.v_LayerNorm.weight', 'bert.encoder.layer.23.output.v_LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
04/19/2022 10:41:35 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLPreTraining: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
04/19/2022 10:41:51 - INFO - __main__ -   ** ** * Saving model * ** ** 
04/19/2022 10:42:08 - INFO - __main__ -   >> Parameters:
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |Name                                                              |Dtype            |Shape            |#Params      |Trainable|
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                     |torch.float32    |(250002, 768)    |192001536    |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                 |torch.float32    |(514, 768)       |394752       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight               |torch.float32    |(1, 768)         |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)         |3840         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_token_type_embeddings.weight         |torch.float32    |(1, 768)         |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.predictions.bias                                       |torch.float32    |(250002,)        |250002       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                     |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                       |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                 |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                   |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                             |torch.float32    |(2, 1024)        |2048         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                               |torch.float32    |(2,)             |2            |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                |torch.float32    |(768, 768)       |589824       |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                  |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight            |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias              |torch.float32    |(768,)           |768          |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.weight                 |torch.float32    |(1601, 768)      |1229568      |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.bias                   |torch.float32    |(1601,)          |1601         |True    |
04/19/2022 10:42:08 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------
04/19/2022 10:42:08 - INFO - __main__ -   >> # TrainableParams:       	283.28	M
04/19/2022 10:42:08 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
04/19/2022 10:42:08 - INFO - __main__ -   >> # TotalParams:           	283.28	M
04/19/2022 10:42:08 - INFO - __main__ -   ***** Running training *****
04/19/2022 10:42:08 - INFO - __main__ -     Num examples = 2777649
04/19/2022 10:42:08 - INFO - __main__ -     Batch size = 64
04/19/2022 10:42:08 - INFO - __main__ -     Num steps = 217000
/home/mwp141/anaconda3/envs/tt-mml/lib/python3.7/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
04/19/2022 10:43:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80 Ep: 0.00 masked_t 4.464 masked_v 1.410 NSP 0.176 lr 2.41935e-08
04/19/2022 10:44:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 160 Ep: 0.00 masked_t 4.161 masked_v 1.409 NSP 0.175 lr 7.02765e-08
04/19/2022 10:45:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 240 Ep: 0.01 masked_t 3.975 masked_v 1.408 NSP 0.176 lr 1.16359e-07
04/19/2022 10:46:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 320 Ep: 0.01 masked_t 3.500 masked_v 1.416 NSP 0.176 lr 1.62442e-07
04/19/2022 10:46:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 400 Ep: 0.01 masked_t 3.104 masked_v 1.412 NSP 0.175 lr 2.08525e-07
04/19/2022 10:47:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 480 Ep: 0.01 masked_t 2.693 masked_v 1.408 NSP 0.175 lr 2.54608e-07
04/19/2022 10:48:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 560 Ep: 0.01 masked_t 2.532 masked_v 1.396 NSP 0.176 lr 3.00691e-07
04/19/2022 10:49:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 640 Ep: 0.01 masked_t 2.477 masked_v 1.380 NSP 0.174 lr 3.46774e-07
04/19/2022 10:50:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 720 Ep: 0.02 masked_t 2.442 masked_v 1.370 NSP 0.176 lr 3.92857e-07
04/19/2022 10:51:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 800 Ep: 0.02 masked_t 2.375 masked_v 1.334 NSP 0.174 lr 4.3894e-07
04/19/2022 10:52:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 880 Ep: 0.02 masked_t 2.305 masked_v 1.318 NSP 0.175 lr 4.85023e-07
04/19/2022 10:53:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 960 Ep: 0.02 masked_t 2.296 masked_v 1.302 NSP 0.174 lr 5.31106e-07
04/19/2022 10:54:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1040 Ep: 0.02 masked_t 2.235 masked_v 1.268 NSP 0.174 lr 5.77189e-07
04/19/2022 10:55:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1120 Ep: 0.03 masked_t 2.206 masked_v 1.226 NSP 0.175 lr 6.23272e-07
04/19/2022 10:56:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1200 Ep: 0.03 masked_t 2.100 masked_v 1.156 NSP 0.173 lr 6.69355e-07
04/19/2022 10:57:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1280 Ep: 0.03 masked_t 2.015 masked_v 1.102 NSP 0.174 lr 7.15438e-07
04/19/2022 10:58:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1360 Ep: 0.03 masked_t 1.941 masked_v 1.051 NSP 0.173 lr 7.61521e-07
04/19/2022 10:59:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1440 Ep: 0.03 masked_t 1.878 masked_v 1.006 NSP 0.174 lr 8.07604e-07
04/19/2022 11:00:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1520 Ep: 0.04 masked_t 1.793 masked_v 0.985 NSP 0.173 lr 8.53687e-07
04/19/2022 11:01:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1600 Ep: 0.04 masked_t 1.716 masked_v 0.952 NSP 0.173 lr 8.9977e-07
04/19/2022 11:02:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1680 Ep: 0.04 masked_t 1.627 masked_v 0.914 NSP 0.173 lr 9.45853e-07
04/19/2022 11:03:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1760 Ep: 0.04 masked_t 1.510 masked_v 0.902 NSP 0.173 lr 9.91935e-07
04/19/2022 11:03:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1840 Ep: 0.04 masked_t 1.409 masked_v 0.855 NSP 0.172 lr 1.03802e-06
04/19/2022 11:04:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 1920 Ep: 0.04 masked_t 1.325 masked_v 0.829 NSP 0.173 lr 1.0841e-06
04/19/2022 11:05:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2000 Ep: 0.05 masked_t 1.238 masked_v 0.822 NSP 0.173 lr 1.13018e-06
04/19/2022 11:06:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2080 Ep: 0.05 masked_t 1.213 masked_v 0.813 NSP 0.173 lr 1.17627e-06
04/19/2022 11:07:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2160 Ep: 0.05 masked_t 1.151 masked_v 0.802 NSP 0.173 lr 1.22235e-06
04/19/2022 11:08:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2240 Ep: 0.05 masked_t 1.061 masked_v 0.784 NSP 0.173 lr 1.26843e-06
04/19/2022 11:09:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2320 Ep: 0.05 masked_t 0.969 masked_v 0.771 NSP 0.173 lr 1.31452e-06
04/19/2022 11:10:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2400 Ep: 0.06 masked_t 0.957 masked_v 0.770 NSP 0.173 lr 1.3606e-06
04/19/2022 11:11:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2480 Ep: 0.06 masked_t 0.869 masked_v 0.753 NSP 0.173 lr 1.40668e-06
04/19/2022 11:12:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2560 Ep: 0.06 masked_t 0.886 masked_v 0.762 NSP 0.173 lr 1.45276e-06
04/19/2022 11:13:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2640 Ep: 0.06 masked_t 0.834 masked_v 0.739 NSP 0.171 lr 1.49885e-06
04/19/2022 11:14:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2720 Ep: 0.06 masked_t 0.793 masked_v 0.744 NSP 0.171 lr 1.54493e-06
04/19/2022 11:15:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2800 Ep: 0.06 masked_t 0.777 masked_v 0.739 NSP 0.172 lr 1.59101e-06
04/19/2022 11:16:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2880 Ep: 0.07 masked_t 0.754 masked_v 0.742 NSP 0.169 lr 1.6371e-06
04/19/2022 11:17:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 2960 Ep: 0.07 masked_t 0.717 masked_v 0.753 NSP 0.169 lr 1.68318e-06
04/19/2022 11:18:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3040 Ep: 0.07 masked_t 0.689 masked_v 0.724 NSP 0.165 lr 1.72926e-06
04/19/2022 11:19:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3120 Ep: 0.07 masked_t 0.666 masked_v 0.729 NSP 0.159 lr 1.77535e-06
04/19/2022 11:20:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3200 Ep: 0.07 masked_t 0.664 masked_v 0.719 NSP 0.154 lr 1.82143e-06
04/19/2022 11:21:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3280 Ep: 0.08 masked_t 0.644 masked_v 0.723 NSP 0.152 lr 1.86751e-06
04/19/2022 11:21:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3360 Ep: 0.08 masked_t 0.649 masked_v 0.719 NSP 0.150 lr 1.91359e-06
04/19/2022 11:22:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3440 Ep: 0.08 masked_t 0.631 masked_v 0.709 NSP 0.144 lr 1.95968e-06
04/19/2022 11:23:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3520 Ep: 0.08 masked_t 0.654 masked_v 0.704 NSP 0.136 lr 2.00576e-06
04/19/2022 11:24:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3600 Ep: 0.08 masked_t 0.586 masked_v 0.692 NSP 0.142 lr 2.05184e-06
04/19/2022 11:25:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3680 Ep: 0.08 masked_t 0.633 masked_v 0.700 NSP 0.138 lr 2.09793e-06
04/19/2022 11:26:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3760 Ep: 0.09 masked_t 0.608 masked_v 0.694 NSP 0.137 lr 2.14401e-06
04/19/2022 11:27:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3840 Ep: 0.09 masked_t 0.592 masked_v 0.677 NSP 0.131 lr 2.19009e-06
04/19/2022 11:28:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 3920 Ep: 0.09 masked_t 0.662 masked_v 0.683 NSP 0.130 lr 2.23618e-06
04/19/2022 11:29:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4000 Ep: 0.09 masked_t 0.576 masked_v 0.685 NSP 0.127 lr 2.28226e-06
04/19/2022 11:30:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4080 Ep: 0.09 masked_t 0.632 masked_v 0.671 NSP 0.125 lr 2.32834e-06
04/19/2022 11:31:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4160 Ep: 0.10 masked_t 0.557 masked_v 0.672 NSP 0.130 lr 2.37442e-06
04/19/2022 11:32:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4240 Ep: 0.10 masked_t 0.569 masked_v 0.672 NSP 0.125 lr 2.42051e-06
04/19/2022 11:33:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4320 Ep: 0.10 masked_t 0.529 masked_v 0.659 NSP 0.125 lr 2.46659e-06
04/19/2022 11:34:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4400 Ep: 0.10 masked_t 0.592 masked_v 0.669 NSP 0.122 lr 2.51267e-06
04/19/2022 11:35:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4480 Ep: 0.10 masked_t 0.584 masked_v 0.651 NSP 0.127 lr 2.55876e-06
04/19/2022 11:36:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4560 Ep: 0.11 masked_t 0.569 masked_v 0.639 NSP 0.128 lr 2.60484e-06
04/19/2022 11:37:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4640 Ep: 0.11 masked_t 0.554 masked_v 0.651 NSP 0.125 lr 2.65092e-06
04/19/2022 11:38:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4720 Ep: 0.11 masked_t 0.598 masked_v 0.639 NSP 0.125 lr 2.697e-06
04/19/2022 11:39:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4800 Ep: 0.11 masked_t 0.541 masked_v 0.641 NSP 0.123 lr 2.74309e-06
04/19/2022 11:40:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4880 Ep: 0.11 masked_t 0.577 masked_v 0.642 NSP 0.120 lr 2.78917e-06
04/19/2022 11:40:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 4960 Ep: 0.11 masked_t 0.578 masked_v 0.627 NSP 0.123 lr 2.83525e-06
04/19/2022 11:41:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5040 Ep: 0.12 masked_t 0.564 masked_v 0.639 NSP 0.118 lr 2.88134e-06
04/19/2022 11:42:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5120 Ep: 0.12 masked_t 0.563 masked_v 0.642 NSP 0.120 lr 2.92742e-06
04/19/2022 11:43:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5200 Ep: 0.12 masked_t 0.566 masked_v 0.624 NSP 0.119 lr 2.9735e-06
04/19/2022 11:44:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5280 Ep: 0.12 masked_t 0.592 masked_v 0.619 NSP 0.123 lr 3.01959e-06
04/19/2022 11:45:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5360 Ep: 0.12 masked_t 0.573 masked_v 0.631 NSP 0.113 lr 3.06567e-06
04/19/2022 11:46:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5440 Ep: 0.13 masked_t 0.555 masked_v 0.618 NSP 0.124 lr 3.11175e-06
04/19/2022 11:47:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5520 Ep: 0.13 masked_t 0.558 masked_v 0.625 NSP 0.120 lr 3.15783e-06
04/19/2022 11:48:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5600 Ep: 0.13 masked_t 0.600 masked_v 0.622 NSP 0.114 lr 3.20392e-06
04/19/2022 11:49:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5680 Ep: 0.13 masked_t 0.560 masked_v 0.608 NSP 0.122 lr 3.25e-06
04/19/2022 11:50:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5760 Ep: 0.13 masked_t 0.574 masked_v 0.600 NSP 0.112 lr 3.29608e-06
04/19/2022 11:51:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5840 Ep: 0.13 masked_t 0.556 masked_v 0.600 NSP 0.113 lr 3.34217e-06
04/19/2022 11:52:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 5920 Ep: 0.14 masked_t 0.548 masked_v 0.594 NSP 0.118 lr 3.38825e-06
04/19/2022 11:53:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6000 Ep: 0.14 masked_t 0.576 masked_v 0.599 NSP 0.114 lr 3.43433e-06
04/19/2022 11:54:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6080 Ep: 0.14 masked_t 0.565 masked_v 0.586 NSP 0.116 lr 3.48041e-06
04/19/2022 11:55:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6160 Ep: 0.14 masked_t 0.569 masked_v 0.590 NSP 0.116 lr 3.5265e-06
04/19/2022 11:56:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6240 Ep: 0.14 masked_t 0.557 masked_v 0.578 NSP 0.112 lr 3.57258e-06
04/19/2022 11:57:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6320 Ep: 0.15 masked_t 0.527 masked_v 0.574 NSP 0.115 lr 3.61866e-06
04/19/2022 11:58:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6400 Ep: 0.15 masked_t 0.577 masked_v 0.565 NSP 0.114 lr 3.66475e-06
04/19/2022 11:58:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6480 Ep: 0.15 masked_t 0.577 masked_v 0.566 NSP 0.112 lr 3.71083e-06
04/19/2022 11:59:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6560 Ep: 0.15 masked_t 0.572 masked_v 0.572 NSP 0.109 lr 3.75691e-06
04/19/2022 12:00:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6640 Ep: 0.15 masked_t 0.547 masked_v 0.556 NSP 0.103 lr 3.803e-06
04/19/2022 12:01:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6720 Ep: 0.15 masked_t 0.546 masked_v 0.559 NSP 0.112 lr 3.84908e-06
04/19/2022 12:02:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6800 Ep: 0.16 masked_t 0.575 masked_v 0.559 NSP 0.107 lr 3.89516e-06
04/19/2022 12:03:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6880 Ep: 0.16 masked_t 0.542 masked_v 0.560 NSP 0.109 lr 3.94124e-06
04/19/2022 12:04:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 6960 Ep: 0.16 masked_t 0.541 masked_v 0.533 NSP 0.108 lr 3.98733e-06
04/19/2022 12:05:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7040 Ep: 0.16 masked_t 0.547 masked_v 0.549 NSP 0.107 lr 4.03341e-06
04/19/2022 12:06:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7120 Ep: 0.16 masked_t 0.594 masked_v 0.523 NSP 0.109 lr 4.07949e-06
04/19/2022 12:07:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7200 Ep: 0.17 masked_t 0.544 masked_v 0.535 NSP 0.107 lr 4.12558e-06
04/19/2022 12:08:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7280 Ep: 0.17 masked_t 0.548 masked_v 0.516 NSP 0.106 lr 4.17166e-06
04/19/2022 12:09:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7360 Ep: 0.17 masked_t 0.527 masked_v 0.526 NSP 0.111 lr 4.21774e-06
04/19/2022 12:10:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7440 Ep: 0.17 masked_t 0.543 masked_v 0.533 NSP 0.097 lr 4.26382e-06
04/19/2022 12:11:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7520 Ep: 0.17 masked_t 0.560 masked_v 0.514 NSP 0.101 lr 4.30991e-06
04/19/2022 12:12:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7600 Ep: 0.18 masked_t 0.539 masked_v 0.519 NSP 0.106 lr 4.35599e-06
04/19/2022 12:13:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7680 Ep: 0.18 masked_t 0.577 masked_v 0.501 NSP 0.110 lr 4.40207e-06
04/19/2022 12:14:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7760 Ep: 0.18 masked_t 0.544 masked_v 0.507 NSP 0.102 lr 4.44816e-06
04/19/2022 12:15:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7840 Ep: 0.18 masked_t 0.501 masked_v 0.501 NSP 0.102 lr 4.49424e-06
04/19/2022 12:15:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 7920 Ep: 0.18 masked_t 0.539 masked_v 0.493 NSP 0.104 lr 4.54032e-06
04/19/2022 12:16:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8000 Ep: 0.18 masked_t 0.557 masked_v 0.486 NSP 0.105 lr 4.58641e-06
04/19/2022 12:17:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8080 Ep: 0.19 masked_t 0.541 masked_v 0.482 NSP 0.093 lr 4.63249e-06
04/19/2022 12:18:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8160 Ep: 0.19 masked_t 0.583 masked_v 0.492 NSP 0.104 lr 4.67857e-06
04/19/2022 12:19:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8240 Ep: 0.19 masked_t 0.545 masked_v 0.490 NSP 0.099 lr 4.72465e-06
04/19/2022 12:20:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8320 Ep: 0.19 masked_t 0.537 masked_v 0.471 NSP 0.096 lr 4.77074e-06
04/19/2022 12:21:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8400 Ep: 0.19 masked_t 0.542 masked_v 0.487 NSP 0.103 lr 4.81682e-06
04/19/2022 12:22:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8480 Ep: 0.20 masked_t 0.538 masked_v 0.468 NSP 0.101 lr 4.8629e-06
04/19/2022 12:23:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8560 Ep: 0.20 masked_t 0.522 masked_v 0.457 NSP 0.092 lr 4.90899e-06
04/19/2022 12:24:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8640 Ep: 0.20 masked_t 0.522 masked_v 0.465 NSP 0.100 lr 4.95507e-06
04/19/2022 12:25:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8720 Ep: 0.20 masked_t 0.541 masked_v 0.453 NSP 0.106 lr 5.00115e-06
04/19/2022 12:26:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8800 Ep: 0.20 masked_t 0.498 masked_v 0.450 NSP 0.096 lr 5.04724e-06
04/19/2022 12:27:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8880 Ep: 0.20 masked_t 0.565 masked_v 0.448 NSP 0.093 lr 5.09332e-06
04/19/2022 12:28:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 8960 Ep: 0.21 masked_t 0.521 masked_v 0.448 NSP 0.099 lr 5.1394e-06
04/19/2022 12:29:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9040 Ep: 0.21 masked_t 0.537 masked_v 0.437 NSP 0.097 lr 5.18548e-06
04/19/2022 12:30:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9120 Ep: 0.21 masked_t 0.564 masked_v 0.442 NSP 0.098 lr 5.23157e-06
04/19/2022 12:31:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9200 Ep: 0.21 masked_t 0.529 masked_v 0.440 NSP 0.096 lr 5.27765e-06
04/19/2022 12:32:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9280 Ep: 0.21 masked_t 0.568 masked_v 0.429 NSP 0.091 lr 5.32373e-06
04/19/2022 12:33:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9360 Ep: 0.22 masked_t 0.532 masked_v 0.430 NSP 0.101 lr 5.36982e-06
04/19/2022 12:33:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9440 Ep: 0.22 masked_t 0.523 masked_v 0.423 NSP 0.092 lr 5.4159e-06
04/19/2022 12:34:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9520 Ep: 0.22 masked_t 0.524 masked_v 0.411 NSP 0.103 lr 5.46198e-06
04/19/2022 12:35:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9600 Ep: 0.22 masked_t 0.556 masked_v 0.407 NSP 0.101 lr 5.50806e-06
04/19/2022 12:36:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9680 Ep: 0.22 masked_t 0.584 masked_v 0.427 NSP 0.093 lr 5.55415e-06
04/19/2022 12:37:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9760 Ep: 0.22 masked_t 0.543 masked_v 0.423 NSP 0.098 lr 5.60023e-06
04/19/2022 12:38:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9840 Ep: 0.23 masked_t 0.571 masked_v 0.424 NSP 0.102 lr 5.64631e-06
04/19/2022 12:39:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 9920 Ep: 0.23 masked_t 0.560 masked_v 0.408 NSP 0.100 lr 5.6924e-06
04/19/2022 12:40:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10000 Ep: 0.23 masked_t 0.533 masked_v 0.403 NSP 0.091 lr 5.73848e-06
04/19/2022 12:41:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10080 Ep: 0.23 masked_t 0.501 masked_v 0.404 NSP 0.089 lr 5.78456e-06
04/19/2022 12:42:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10160 Ep: 0.23 masked_t 0.540 masked_v 0.395 NSP 0.090 lr 5.83065e-06
04/19/2022 12:43:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10240 Ep: 0.24 masked_t 0.581 masked_v 0.394 NSP 0.095 lr 5.87673e-06
04/19/2022 12:44:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10320 Ep: 0.24 masked_t 0.525 masked_v 0.400 NSP 0.097 lr 5.92281e-06
04/19/2022 12:45:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10400 Ep: 0.24 masked_t 0.552 masked_v 0.385 NSP 0.095 lr 5.96889e-06
04/19/2022 12:46:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10480 Ep: 0.24 masked_t 0.565 masked_v 0.390 NSP 0.090 lr 6.01498e-06
04/19/2022 12:47:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10560 Ep: 0.24 masked_t 0.519 masked_v 0.376 NSP 0.092 lr 6.06106e-06
04/19/2022 12:48:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10640 Ep: 0.25 masked_t 0.537 masked_v 0.384 NSP 0.091 lr 6.10714e-06
04/19/2022 12:49:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10720 Ep: 0.25 masked_t 0.458 masked_v 0.381 NSP 0.090 lr 6.15323e-06
04/19/2022 12:49:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10800 Ep: 0.25 masked_t 0.544 masked_v 0.379 NSP 0.087 lr 6.19931e-06
04/19/2022 12:50:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10880 Ep: 0.25 masked_t 0.529 masked_v 0.375 NSP 0.083 lr 6.24539e-06
04/19/2022 12:51:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 10960 Ep: 0.25 masked_t 0.505 masked_v 0.383 NSP 0.095 lr 6.29147e-06
04/19/2022 12:52:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11040 Ep: 0.25 masked_t 0.514 masked_v 0.368 NSP 0.093 lr 6.33756e-06
04/19/2022 12:53:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11120 Ep: 0.26 masked_t 0.543 masked_v 0.367 NSP 0.094 lr 6.38364e-06
04/19/2022 12:54:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11200 Ep: 0.26 masked_t 0.520 masked_v 0.368 NSP 0.094 lr 6.42972e-06
04/19/2022 12:55:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11280 Ep: 0.26 masked_t 0.480 masked_v 0.357 NSP 0.095 lr 6.47581e-06
04/19/2022 12:56:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11360 Ep: 0.26 masked_t 0.507 masked_v 0.364 NSP 0.091 lr 6.52189e-06
04/19/2022 12:57:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11440 Ep: 0.26 masked_t 0.523 masked_v 0.356 NSP 0.093 lr 6.56797e-06
04/19/2022 12:58:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11520 Ep: 0.27 masked_t 0.532 masked_v 0.341 NSP 0.086 lr 6.61406e-06
04/19/2022 12:59:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11600 Ep: 0.27 masked_t 0.538 masked_v 0.352 NSP 0.088 lr 6.66014e-06
04/19/2022 13:00:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11680 Ep: 0.27 masked_t 0.548 masked_v 0.342 NSP 0.089 lr 6.70622e-06
04/19/2022 13:01:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11760 Ep: 0.27 masked_t 0.513 masked_v 0.344 NSP 0.087 lr 6.7523e-06
04/19/2022 13:02:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11840 Ep: 0.27 masked_t 0.545 masked_v 0.330 NSP 0.084 lr 6.79839e-06
04/19/2022 13:03:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 11920 Ep: 0.27 masked_t 0.519 masked_v 0.332 NSP 0.085 lr 6.84447e-06
04/19/2022 13:04:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12000 Ep: 0.28 masked_t 0.522 masked_v 0.326 NSP 0.087 lr 6.89055e-06
04/19/2022 13:05:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12080 Ep: 0.28 masked_t 0.528 masked_v 0.321 NSP 0.089 lr 6.93664e-06
04/19/2022 13:05:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12160 Ep: 0.28 masked_t 0.555 masked_v 0.325 NSP 0.082 lr 6.98272e-06
04/19/2022 13:06:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12240 Ep: 0.28 masked_t 0.525 masked_v 0.301 NSP 0.084 lr 7.0288e-06
04/19/2022 13:07:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12320 Ep: 0.28 masked_t 0.513 masked_v 0.305 NSP 0.090 lr 7.07488e-06
04/19/2022 13:08:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12400 Ep: 0.29 masked_t 0.503 masked_v 0.306 NSP 0.081 lr 7.12097e-06
04/19/2022 13:09:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12480 Ep: 0.29 masked_t 0.526 masked_v 0.314 NSP 0.088 lr 7.16705e-06
04/19/2022 13:10:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12560 Ep: 0.29 masked_t 0.510 masked_v 0.300 NSP 0.078 lr 7.21313e-06
04/19/2022 13:11:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12640 Ep: 0.29 masked_t 0.521 masked_v 0.304 NSP 0.088 lr 7.25922e-06
04/19/2022 13:12:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12720 Ep: 0.29 masked_t 0.525 masked_v 0.303 NSP 0.081 lr 7.3053e-06
04/19/2022 13:13:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12800 Ep: 0.29 masked_t 0.575 masked_v 0.303 NSP 0.085 lr 7.35138e-06
04/19/2022 13:14:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12880 Ep: 0.30 masked_t 0.538 masked_v 0.293 NSP 0.088 lr 7.39747e-06
04/19/2022 13:15:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 12960 Ep: 0.30 masked_t 0.541 masked_v 0.289 NSP 0.083 lr 7.44355e-06
04/19/2022 13:16:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13040 Ep: 0.30 masked_t 0.514 masked_v 0.295 NSP 0.085 lr 7.48963e-06
04/19/2022 13:17:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13120 Ep: 0.30 masked_t 0.517 masked_v 0.287 NSP 0.081 lr 7.53571e-06
04/19/2022 13:18:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13200 Ep: 0.30 masked_t 0.479 masked_v 0.286 NSP 0.089 lr 7.5818e-06
04/19/2022 13:19:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13280 Ep: 0.31 masked_t 0.510 masked_v 0.288 NSP 0.081 lr 7.62788e-06
04/19/2022 13:20:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13360 Ep: 0.31 masked_t 0.562 masked_v 0.283 NSP 0.076 lr 7.67396e-06
04/19/2022 13:20:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13440 Ep: 0.31 masked_t 0.505 masked_v 0.274 NSP 0.086 lr 7.72005e-06
04/19/2022 13:21:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13520 Ep: 0.31 masked_t 0.555 masked_v 0.286 NSP 0.082 lr 7.76613e-06
04/19/2022 13:22:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13600 Ep: 0.31 masked_t 0.496 masked_v 0.282 NSP 0.076 lr 7.81221e-06
04/19/2022 13:23:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13680 Ep: 0.32 masked_t 0.505 masked_v 0.279 NSP 0.087 lr 7.85829e-06
04/19/2022 13:24:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13760 Ep: 0.32 masked_t 0.525 masked_v 0.270 NSP 0.082 lr 7.90438e-06
04/19/2022 13:25:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13840 Ep: 0.32 masked_t 0.523 masked_v 0.263 NSP 0.077 lr 7.95046e-06
04/19/2022 13:26:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 13920 Ep: 0.32 masked_t 0.505 masked_v 0.271 NSP 0.083 lr 7.99654e-06
04/19/2022 13:27:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14000 Ep: 0.32 masked_t 0.494 masked_v 0.266 NSP 0.080 lr 8.04263e-06
04/19/2022 13:28:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14080 Ep: 0.32 masked_t 0.517 masked_v 0.275 NSP 0.079 lr 8.08871e-06
04/19/2022 13:29:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14160 Ep: 0.33 masked_t 0.498 masked_v 0.262 NSP 0.078 lr 8.13479e-06
04/19/2022 13:30:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14240 Ep: 0.33 masked_t 0.519 masked_v 0.259 NSP 0.083 lr 8.18088e-06
04/19/2022 13:31:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14320 Ep: 0.33 masked_t 0.547 masked_v 0.255 NSP 0.079 lr 8.22696e-06
04/19/2022 13:32:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14400 Ep: 0.33 masked_t 0.498 masked_v 0.261 NSP 0.081 lr 8.27304e-06
04/19/2022 13:33:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14480 Ep: 0.33 masked_t 0.479 masked_v 0.252 NSP 0.079 lr 8.31912e-06
04/19/2022 13:34:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14560 Ep: 0.34 masked_t 0.502 masked_v 0.262 NSP 0.072 lr 8.36521e-06
04/19/2022 13:35:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14640 Ep: 0.34 masked_t 0.505 masked_v 0.250 NSP 0.086 lr 8.41129e-06
04/19/2022 13:36:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14720 Ep: 0.34 masked_t 0.478 masked_v 0.256 NSP 0.080 lr 8.45737e-06
04/19/2022 13:37:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14800 Ep: 0.34 masked_t 0.537 masked_v 0.249 NSP 0.079 lr 8.50346e-06
04/19/2022 13:37:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14880 Ep: 0.34 masked_t 0.507 masked_v 0.252 NSP 0.081 lr 8.54954e-06
04/19/2022 13:38:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 14960 Ep: 0.34 masked_t 0.518 masked_v 0.248 NSP 0.078 lr 8.59562e-06
04/19/2022 13:39:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15040 Ep: 0.35 masked_t 0.509 masked_v 0.252 NSP 0.077 lr 8.64171e-06
04/19/2022 13:40:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15120 Ep: 0.35 masked_t 0.547 masked_v 0.237 NSP 0.076 lr 8.68779e-06
04/19/2022 13:41:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15200 Ep: 0.35 masked_t 0.520 masked_v 0.241 NSP 0.089 lr 8.73387e-06
04/19/2022 13:42:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15280 Ep: 0.35 masked_t 0.515 masked_v 0.238 NSP 0.073 lr 8.77995e-06
04/19/2022 13:43:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15360 Ep: 0.35 masked_t 0.502 masked_v 0.238 NSP 0.076 lr 8.82604e-06
04/19/2022 13:44:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15440 Ep: 0.36 masked_t 0.501 masked_v 0.240 NSP 0.074 lr 8.87212e-06
04/19/2022 13:45:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15520 Ep: 0.36 masked_t 0.490 masked_v 0.240 NSP 0.076 lr 8.9182e-06
04/19/2022 13:46:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15600 Ep: 0.36 masked_t 0.534 masked_v 0.238 NSP 0.078 lr 8.96429e-06
04/19/2022 13:47:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15680 Ep: 0.36 masked_t 0.479 masked_v 0.239 NSP 0.079 lr 9.01037e-06
04/19/2022 13:48:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15760 Ep: 0.36 masked_t 0.496 masked_v 0.236 NSP 0.075 lr 9.05645e-06
04/19/2022 13:49:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15840 Ep: 0.36 masked_t 0.524 masked_v 0.231 NSP 0.075 lr 9.10253e-06
04/19/2022 13:50:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 15920 Ep: 0.37 masked_t 0.501 masked_v 0.237 NSP 0.081 lr 9.14862e-06
04/19/2022 13:51:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16000 Ep: 0.37 masked_t 0.486 masked_v 0.230 NSP 0.078 lr 9.1947e-06
04/19/2022 13:52:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16080 Ep: 0.37 masked_t 0.538 masked_v 0.225 NSP 0.078 lr 9.24078e-06
04/19/2022 13:52:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16160 Ep: 0.37 masked_t 0.532 masked_v 0.228 NSP 0.079 lr 9.28687e-06
04/19/2022 13:53:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16240 Ep: 0.37 masked_t 0.479 masked_v 0.228 NSP 0.076 lr 9.33295e-06
04/19/2022 13:54:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16320 Ep: 0.38 masked_t 0.501 masked_v 0.225 NSP 0.073 lr 9.37903e-06
04/19/2022 13:55:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16400 Ep: 0.38 masked_t 0.501 masked_v 0.215 NSP 0.071 lr 9.42512e-06
04/19/2022 13:56:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16480 Ep: 0.38 masked_t 0.507 masked_v 0.219 NSP 0.066 lr 9.4712e-06
04/19/2022 13:57:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16560 Ep: 0.38 masked_t 0.482 masked_v 0.220 NSP 0.079 lr 9.51728e-06
04/19/2022 13:58:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16640 Ep: 0.38 masked_t 0.527 masked_v 0.216 NSP 0.078 lr 9.56336e-06
04/19/2022 13:59:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16720 Ep: 0.39 masked_t 0.491 masked_v 0.212 NSP 0.071 lr 9.60945e-06
04/19/2022 14:00:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16800 Ep: 0.39 masked_t 0.527 masked_v 0.218 NSP 0.077 lr 9.65553e-06
04/19/2022 14:01:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16880 Ep: 0.39 masked_t 0.495 masked_v 0.221 NSP 0.078 lr 9.70161e-06
04/19/2022 14:02:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 16960 Ep: 0.39 masked_t 0.503 masked_v 0.218 NSP 0.075 lr 9.7477e-06
04/19/2022 14:03:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17040 Ep: 0.39 masked_t 0.485 masked_v 0.217 NSP 0.076 lr 9.79378e-06
04/19/2022 14:04:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17120 Ep: 0.39 masked_t 0.514 masked_v 0.206 NSP 0.075 lr 9.83986e-06
04/19/2022 14:05:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17200 Ep: 0.40 masked_t 0.527 masked_v 0.207 NSP 0.080 lr 9.88594e-06
04/19/2022 14:06:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17280 Ep: 0.40 masked_t 0.563 masked_v 0.209 NSP 0.074 lr 9.93203e-06
04/19/2022 14:07:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17360 Ep: 0.40 masked_t 0.530 masked_v 0.208 NSP 0.075 lr 9.97811e-06
04/19/2022 14:08:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17440 Ep: 0.40 masked_t 0.510 masked_v 0.212 NSP 0.077 lr 1.00242e-05
04/19/2022 14:08:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17520 Ep: 0.40 masked_t 0.529 masked_v 0.211 NSP 0.076 lr 1.00703e-05
04/19/2022 14:09:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17600 Ep: 0.41 masked_t 0.512 masked_v 0.206 NSP 0.072 lr 1.01164e-05
04/19/2022 14:10:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17680 Ep: 0.41 masked_t 0.479 masked_v 0.214 NSP 0.073 lr 1.01624e-05
04/19/2022 14:11:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17760 Ep: 0.41 masked_t 0.483 masked_v 0.200 NSP 0.078 lr 1.02085e-05
04/19/2022 14:12:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17840 Ep: 0.41 masked_t 0.534 masked_v 0.205 NSP 0.067 lr 1.02546e-05
04/19/2022 14:13:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 17920 Ep: 0.41 masked_t 0.570 masked_v 0.205 NSP 0.067 lr 1.03007e-05
04/19/2022 14:14:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18000 Ep: 0.41 masked_t 0.486 masked_v 0.199 NSP 0.076 lr 1.03468e-05
04/19/2022 14:15:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18080 Ep: 0.42 masked_t 0.540 masked_v 0.199 NSP 0.075 lr 1.03929e-05
04/19/2022 14:16:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18160 Ep: 0.42 masked_t 0.496 masked_v 0.200 NSP 0.071 lr 1.04389e-05
04/19/2022 14:17:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18240 Ep: 0.42 masked_t 0.528 masked_v 0.199 NSP 0.064 lr 1.0485e-05
04/19/2022 14:18:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18320 Ep: 0.42 masked_t 0.508 masked_v 0.195 NSP 0.073 lr 1.05311e-05
04/19/2022 14:19:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18400 Ep: 0.42 masked_t 0.483 masked_v 0.195 NSP 0.078 lr 1.05772e-05
04/19/2022 14:20:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18480 Ep: 0.43 masked_t 0.521 masked_v 0.199 NSP 0.069 lr 1.06233e-05
04/19/2022 14:21:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18560 Ep: 0.43 masked_t 0.514 masked_v 0.205 NSP 0.073 lr 1.06694e-05
04/19/2022 14:22:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18640 Ep: 0.43 masked_t 0.525 masked_v 0.194 NSP 0.065 lr 1.07154e-05
04/19/2022 14:23:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18720 Ep: 0.43 masked_t 0.511 masked_v 0.197 NSP 0.073 lr 1.07615e-05
04/19/2022 14:24:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18800 Ep: 0.43 masked_t 0.467 masked_v 0.191 NSP 0.080 lr 1.08076e-05
04/19/2022 14:25:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18880 Ep: 0.44 masked_t 0.529 masked_v 0.199 NSP 0.068 lr 1.08537e-05
04/19/2022 14:25:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 18960 Ep: 0.44 masked_t 0.552 masked_v 0.190 NSP 0.065 lr 1.08998e-05
04/19/2022 14:26:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19040 Ep: 0.44 masked_t 0.502 masked_v 0.189 NSP 0.074 lr 1.09459e-05
04/19/2022 14:27:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19120 Ep: 0.44 masked_t 0.541 masked_v 0.194 NSP 0.069 lr 1.09919e-05
04/19/2022 14:28:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19200 Ep: 0.44 masked_t 0.512 masked_v 0.184 NSP 0.064 lr 1.1038e-05
04/19/2022 14:29:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19280 Ep: 0.44 masked_t 0.516 masked_v 0.190 NSP 0.070 lr 1.10841e-05
04/19/2022 14:30:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19360 Ep: 0.45 masked_t 0.516 masked_v 0.187 NSP 0.079 lr 1.11302e-05
04/19/2022 14:31:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19440 Ep: 0.45 masked_t 0.557 masked_v 0.177 NSP 0.066 lr 1.11763e-05
04/19/2022 14:32:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19520 Ep: 0.45 masked_t 0.486 masked_v 0.182 NSP 0.074 lr 1.12224e-05
04/19/2022 14:33:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19600 Ep: 0.45 masked_t 0.531 masked_v 0.184 NSP 0.066 lr 1.12684e-05
04/19/2022 14:34:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19680 Ep: 0.45 masked_t 0.498 masked_v 0.184 NSP 0.068 lr 1.13145e-05
04/19/2022 14:35:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19760 Ep: 0.46 masked_t 0.537 masked_v 0.176 NSP 0.067 lr 1.13606e-05
04/19/2022 14:36:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19840 Ep: 0.46 masked_t 0.518 masked_v 0.178 NSP 0.071 lr 1.14067e-05
04/19/2022 14:37:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 19920 Ep: 0.46 masked_t 0.502 masked_v 0.187 NSP 0.063 lr 1.14528e-05
04/19/2022 14:38:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20000 Ep: 0.46 masked_t 0.493 masked_v 0.184 NSP 0.070 lr 1.14988e-05
04/19/2022 14:39:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20080 Ep: 0.46 masked_t 0.520 masked_v 0.182 NSP 0.073 lr 1.15449e-05
04/19/2022 14:40:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20160 Ep: 0.46 masked_t 0.514 masked_v 0.179 NSP 0.075 lr 1.1591e-05
04/19/2022 14:41:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20240 Ep: 0.47 masked_t 0.512 masked_v 0.184 NSP 0.063 lr 1.16371e-05
04/19/2022 14:41:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20320 Ep: 0.47 masked_t 0.503 masked_v 0.184 NSP 0.071 lr 1.16832e-05
04/19/2022 14:42:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20400 Ep: 0.47 masked_t 0.540 masked_v 0.180 NSP 0.063 lr 1.17293e-05
04/19/2022 14:43:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20480 Ep: 0.47 masked_t 0.480 masked_v 0.178 NSP 0.066 lr 1.17753e-05
04/19/2022 14:44:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20560 Ep: 0.47 masked_t 0.513 masked_v 0.173 NSP 0.065 lr 1.18214e-05
04/19/2022 14:45:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20640 Ep: 0.48 masked_t 0.508 masked_v 0.179 NSP 0.075 lr 1.18675e-05
04/19/2022 14:46:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20720 Ep: 0.48 masked_t 0.521 masked_v 0.174 NSP 0.071 lr 1.19136e-05
04/19/2022 14:47:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20800 Ep: 0.48 masked_t 0.525 masked_v 0.173 NSP 0.070 lr 1.19597e-05
04/19/2022 14:48:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20880 Ep: 0.48 masked_t 0.516 masked_v 0.175 NSP 0.075 lr 1.20058e-05
04/19/2022 14:49:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 20960 Ep: 0.48 masked_t 0.515 masked_v 0.170 NSP 0.074 lr 1.20518e-05
04/19/2022 14:50:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21040 Ep: 0.48 masked_t 0.529 masked_v 0.170 NSP 0.063 lr 1.20979e-05
04/19/2022 14:51:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21120 Ep: 0.49 masked_t 0.499 masked_v 0.175 NSP 0.067 lr 1.2144e-05
04/19/2022 14:52:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21200 Ep: 0.49 masked_t 0.506 masked_v 0.168 NSP 0.060 lr 1.21901e-05
04/19/2022 14:53:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21280 Ep: 0.49 masked_t 0.505 masked_v 0.170 NSP 0.074 lr 1.22362e-05
04/19/2022 14:54:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21360 Ep: 0.49 masked_t 0.491 masked_v 0.169 NSP 0.061 lr 1.22823e-05
04/19/2022 14:55:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21440 Ep: 0.49 masked_t 0.518 masked_v 0.175 NSP 0.064 lr 1.23283e-05
04/19/2022 14:56:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21520 Ep: 0.50 masked_t 0.525 masked_v 0.168 NSP 0.068 lr 1.23744e-05
04/19/2022 14:56:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21600 Ep: 0.50 masked_t 0.522 masked_v 0.166 NSP 0.066 lr 1.24205e-05
04/19/2022 14:57:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21680 Ep: 0.50 masked_t 0.508 masked_v 0.170 NSP 0.077 lr 1.24666e-05
04/19/2022 14:58:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21760 Ep: 0.50 masked_t 0.482 masked_v 0.167 NSP 0.063 lr 1.25127e-05
04/19/2022 14:59:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21840 Ep: 0.50 masked_t 0.509 masked_v 0.172 NSP 0.068 lr 1.25588e-05
04/19/2022 15:00:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 21920 Ep: 0.51 masked_t 0.505 masked_v 0.175 NSP 0.069 lr 1.26048e-05
04/19/2022 15:01:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22000 Ep: 0.51 masked_t 0.533 masked_v 0.170 NSP 0.065 lr 1.26509e-05
04/19/2022 15:02:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22080 Ep: 0.51 masked_t 0.515 masked_v 0.172 NSP 0.066 lr 1.2697e-05
04/19/2022 15:03:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22160 Ep: 0.51 masked_t 0.507 masked_v 0.172 NSP 0.059 lr 1.27431e-05
04/19/2022 15:04:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22240 Ep: 0.51 masked_t 0.500 masked_v 0.163 NSP 0.062 lr 1.27892e-05
04/19/2022 15:05:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22320 Ep: 0.51 masked_t 0.530 masked_v 0.163 NSP 0.060 lr 1.28353e-05
04/19/2022 15:06:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22400 Ep: 0.52 masked_t 0.538 masked_v 0.162 NSP 0.061 lr 1.28813e-05
04/19/2022 15:07:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22480 Ep: 0.52 masked_t 0.484 masked_v 0.161 NSP 0.061 lr 1.29274e-05
04/19/2022 15:08:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22560 Ep: 0.52 masked_t 0.553 masked_v 0.169 NSP 0.065 lr 1.29735e-05
04/19/2022 15:09:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22640 Ep: 0.52 masked_t 0.459 masked_v 0.168 NSP 0.072 lr 1.30196e-05
04/19/2022 15:10:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22720 Ep: 0.52 masked_t 0.533 masked_v 0.161 NSP 0.062 lr 1.30657e-05
04/19/2022 15:11:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22800 Ep: 0.53 masked_t 0.507 masked_v 0.163 NSP 0.063 lr 1.31118e-05
04/19/2022 15:12:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22880 Ep: 0.53 masked_t 0.555 masked_v 0.165 NSP 0.069 lr 1.31578e-05
04/19/2022 15:13:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 22960 Ep: 0.53 masked_t 0.545 masked_v 0.165 NSP 0.067 lr 1.32039e-05
04/19/2022 15:13:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23040 Ep: 0.53 masked_t 0.495 masked_v 0.165 NSP 0.067 lr 1.325e-05
04/19/2022 15:14:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23120 Ep: 0.53 masked_t 0.493 masked_v 0.164 NSP 0.065 lr 1.32961e-05
04/19/2022 15:15:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23200 Ep: 0.53 masked_t 0.529 masked_v 0.160 NSP 0.073 lr 1.33422e-05
04/19/2022 15:16:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23280 Ep: 0.54 masked_t 0.522 masked_v 0.160 NSP 0.062 lr 1.33882e-05
04/19/2022 15:17:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23360 Ep: 0.54 masked_t 0.481 masked_v 0.165 NSP 0.072 lr 1.34343e-05
04/19/2022 15:18:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23440 Ep: 0.54 masked_t 0.484 masked_v 0.156 NSP 0.065 lr 1.34804e-05
04/19/2022 15:19:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23520 Ep: 0.54 masked_t 0.473 masked_v 0.157 NSP 0.069 lr 1.35265e-05
04/19/2022 15:20:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23600 Ep: 0.54 masked_t 0.482 masked_v 0.158 NSP 0.066 lr 1.35726e-05
04/19/2022 15:21:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23680 Ep: 0.55 masked_t 0.513 masked_v 0.165 NSP 0.068 lr 1.36187e-05
04/19/2022 15:22:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23760 Ep: 0.55 masked_t 0.523 masked_v 0.159 NSP 0.065 lr 1.36647e-05
04/19/2022 15:23:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23840 Ep: 0.55 masked_t 0.496 masked_v 0.162 NSP 0.064 lr 1.37108e-05
04/19/2022 15:24:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 23920 Ep: 0.55 masked_t 0.501 masked_v 0.157 NSP 0.069 lr 1.37569e-05
04/19/2022 15:25:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24000 Ep: 0.55 masked_t 0.498 masked_v 0.163 NSP 0.064 lr 1.3803e-05
04/19/2022 15:26:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24080 Ep: 0.55 masked_t 0.516 masked_v 0.155 NSP 0.062 lr 1.38491e-05
04/19/2022 15:27:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24160 Ep: 0.56 masked_t 0.492 masked_v 0.156 NSP 0.064 lr 1.38952e-05
04/19/2022 15:28:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24240 Ep: 0.56 masked_t 0.515 masked_v 0.146 NSP 0.055 lr 1.39412e-05
04/19/2022 15:29:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24320 Ep: 0.56 masked_t 0.524 masked_v 0.152 NSP 0.061 lr 1.39873e-05
04/19/2022 15:29:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24400 Ep: 0.56 masked_t 0.491 masked_v 0.155 NSP 0.062 lr 1.40334e-05
04/19/2022 15:30:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24480 Ep: 0.56 masked_t 0.474 masked_v 0.154 NSP 0.066 lr 1.40795e-05
04/19/2022 15:31:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24560 Ep: 0.57 masked_t 0.505 masked_v 0.157 NSP 0.073 lr 1.41256e-05
04/19/2022 15:32:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24640 Ep: 0.57 masked_t 0.512 masked_v 0.145 NSP 0.062 lr 1.41717e-05
04/19/2022 15:33:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24720 Ep: 0.57 masked_t 0.530 masked_v 0.152 NSP 0.066 lr 1.42177e-05
04/19/2022 15:34:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24800 Ep: 0.57 masked_t 0.479 masked_v 0.153 NSP 0.065 lr 1.42638e-05
04/19/2022 15:35:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24880 Ep: 0.57 masked_t 0.503 masked_v 0.152 NSP 0.065 lr 1.43099e-05
04/19/2022 15:36:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 24960 Ep: 0.58 masked_t 0.515 masked_v 0.152 NSP 0.066 lr 1.4356e-05
04/19/2022 15:37:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25040 Ep: 0.58 masked_t 0.559 masked_v 0.153 NSP 0.067 lr 1.44021e-05
04/19/2022 15:38:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25120 Ep: 0.58 masked_t 0.501 masked_v 0.152 NSP 0.068 lr 1.44482e-05
04/19/2022 15:39:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25200 Ep: 0.58 masked_t 0.480 masked_v 0.150 NSP 0.062 lr 1.44942e-05
04/19/2022 15:40:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25280 Ep: 0.58 masked_t 0.533 masked_v 0.152 NSP 0.064 lr 1.45403e-05
04/19/2022 15:41:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25360 Ep: 0.58 masked_t 0.487 masked_v 0.148 NSP 0.065 lr 1.45864e-05
04/19/2022 15:42:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25440 Ep: 0.59 masked_t 0.464 masked_v 0.148 NSP 0.065 lr 1.46325e-05
04/19/2022 15:43:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25520 Ep: 0.59 masked_t 0.515 masked_v 0.152 NSP 0.069 lr 1.46786e-05
04/19/2022 15:44:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25600 Ep: 0.59 masked_t 0.514 masked_v 0.153 NSP 0.066 lr 1.47247e-05
04/19/2022 15:44:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25680 Ep: 0.59 masked_t 0.505 masked_v 0.148 NSP 0.060 lr 1.47707e-05
04/19/2022 15:45:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25760 Ep: 0.59 masked_t 0.453 masked_v 0.149 NSP 0.065 lr 1.48168e-05
04/19/2022 15:46:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25840 Ep: 0.60 masked_t 0.522 masked_v 0.148 NSP 0.068 lr 1.48629e-05
04/19/2022 15:47:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 25920 Ep: 0.60 masked_t 0.534 masked_v 0.150 NSP 0.059 lr 1.4909e-05
04/19/2022 15:48:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26000 Ep: 0.60 masked_t 0.550 masked_v 0.150 NSP 0.064 lr 1.49551e-05
04/19/2022 15:49:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26080 Ep: 0.60 masked_t 0.484 masked_v 0.141 NSP 0.061 lr 1.50012e-05
04/19/2022 15:50:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26160 Ep: 0.60 masked_t 0.519 masked_v 0.147 NSP 0.064 lr 1.50472e-05
04/19/2022 15:51:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26240 Ep: 0.60 masked_t 0.469 masked_v 0.145 NSP 0.065 lr 1.50933e-05
04/19/2022 15:52:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26320 Ep: 0.61 masked_t 0.511 masked_v 0.154 NSP 0.064 lr 1.51394e-05
04/19/2022 15:53:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26400 Ep: 0.61 masked_t 0.471 masked_v 0.147 NSP 0.069 lr 1.51855e-05
04/19/2022 15:54:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26480 Ep: 0.61 masked_t 0.522 masked_v 0.149 NSP 0.060 lr 1.52316e-05
04/19/2022 15:55:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26560 Ep: 0.61 masked_t 0.501 masked_v 0.144 NSP 0.062 lr 1.52776e-05
04/19/2022 15:56:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26640 Ep: 0.61 masked_t 0.496 masked_v 0.149 NSP 0.067 lr 1.53237e-05
04/19/2022 15:57:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26720 Ep: 0.62 masked_t 0.478 masked_v 0.150 NSP 0.066 lr 1.53698e-05
04/19/2022 15:58:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26800 Ep: 0.62 masked_t 0.491 masked_v 0.144 NSP 0.055 lr 1.54159e-05
04/19/2022 15:59:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26880 Ep: 0.62 masked_t 0.590 masked_v 0.144 NSP 0.068 lr 1.5462e-05
04/19/2022 15:59:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 26960 Ep: 0.62 masked_t 0.549 masked_v 0.145 NSP 0.068 lr 1.55081e-05
04/19/2022 16:00:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27040 Ep: 0.62 masked_t 0.533 masked_v 0.143 NSP 0.068 lr 1.55541e-05
04/19/2022 16:01:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27120 Ep: 0.62 masked_t 0.494 masked_v 0.144 NSP 0.065 lr 1.56002e-05
04/19/2022 16:02:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27200 Ep: 0.63 masked_t 0.486 masked_v 0.137 NSP 0.065 lr 1.56463e-05
04/19/2022 16:03:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27280 Ep: 0.63 masked_t 0.502 masked_v 0.142 NSP 0.062 lr 1.56924e-05
04/19/2022 16:04:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27360 Ep: 0.63 masked_t 0.503 masked_v 0.144 NSP 0.057 lr 1.57385e-05
04/19/2022 16:05:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27440 Ep: 0.63 masked_t 0.535 masked_v 0.143 NSP 0.065 lr 1.57846e-05
04/19/2022 16:06:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27520 Ep: 0.63 masked_t 0.499 masked_v 0.137 NSP 0.055 lr 1.58306e-05
04/19/2022 16:07:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27600 Ep: 0.64 masked_t 0.514 masked_v 0.139 NSP 0.059 lr 1.58767e-05
04/19/2022 16:08:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27680 Ep: 0.64 masked_t 0.476 masked_v 0.146 NSP 0.058 lr 1.59228e-05
04/19/2022 16:09:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27760 Ep: 0.64 masked_t 0.494 masked_v 0.145 NSP 0.065 lr 1.59689e-05
04/19/2022 16:10:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27840 Ep: 0.64 masked_t 0.462 masked_v 0.135 NSP 0.066 lr 1.6015e-05
04/19/2022 16:11:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 27920 Ep: 0.64 masked_t 0.495 masked_v 0.140 NSP 0.059 lr 1.60611e-05
04/19/2022 16:12:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28000 Ep: 0.65 masked_t 0.455 masked_v 0.147 NSP 0.066 lr 1.61071e-05
04/19/2022 16:13:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28080 Ep: 0.65 masked_t 0.509 masked_v 0.142 NSP 0.057 lr 1.61532e-05
04/19/2022 16:14:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28160 Ep: 0.65 masked_t 0.511 masked_v 0.145 NSP 0.063 lr 1.61993e-05
04/19/2022 16:15:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28240 Ep: 0.65 masked_t 0.491 masked_v 0.141 NSP 0.059 lr 1.62454e-05
04/19/2022 16:15:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28320 Ep: 0.65 masked_t 0.516 masked_v 0.136 NSP 0.067 lr 1.62915e-05
04/19/2022 16:16:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28400 Ep: 0.65 masked_t 0.505 masked_v 0.138 NSP 0.063 lr 1.63376e-05
04/19/2022 16:17:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28480 Ep: 0.66 masked_t 0.490 masked_v 0.134 NSP 0.056 lr 1.63836e-05
04/19/2022 16:18:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28560 Ep: 0.66 masked_t 0.482 masked_v 0.139 NSP 0.064 lr 1.64297e-05
04/19/2022 16:19:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28640 Ep: 0.66 masked_t 0.528 masked_v 0.142 NSP 0.061 lr 1.64758e-05
04/19/2022 16:20:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28720 Ep: 0.66 masked_t 0.506 masked_v 0.143 NSP 0.065 lr 1.65219e-05
04/19/2022 16:21:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28800 Ep: 0.66 masked_t 0.483 masked_v 0.134 NSP 0.055 lr 1.6568e-05
04/19/2022 16:22:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28880 Ep: 0.67 masked_t 0.518 masked_v 0.142 NSP 0.062 lr 1.66141e-05
04/19/2022 16:23:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 28960 Ep: 0.67 masked_t 0.504 masked_v 0.139 NSP 0.066 lr 1.66601e-05
04/19/2022 16:24:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29040 Ep: 0.67 masked_t 0.500 masked_v 0.141 NSP 0.057 lr 1.67062e-05
04/19/2022 16:25:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29120 Ep: 0.67 masked_t 0.447 masked_v 0.138 NSP 0.062 lr 1.67523e-05
04/19/2022 16:26:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29200 Ep: 0.67 masked_t 0.499 masked_v 0.139 NSP 0.064 lr 1.67984e-05
04/19/2022 16:27:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29280 Ep: 0.67 masked_t 0.539 masked_v 0.136 NSP 0.057 lr 1.68445e-05
04/19/2022 16:28:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29360 Ep: 0.68 masked_t 0.508 masked_v 0.141 NSP 0.063 lr 1.68906e-05
04/19/2022 16:29:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29440 Ep: 0.68 masked_t 0.527 masked_v 0.138 NSP 0.060 lr 1.69366e-05
04/19/2022 16:30:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29520 Ep: 0.68 masked_t 0.517 masked_v 0.137 NSP 0.065 lr 1.69827e-05
04/19/2022 16:31:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29600 Ep: 0.68 masked_t 0.523 masked_v 0.132 NSP 0.064 lr 1.70288e-05
04/19/2022 16:31:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29680 Ep: 0.68 masked_t 0.524 masked_v 0.137 NSP 0.062 lr 1.70749e-05
04/19/2022 16:32:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29760 Ep: 0.69 masked_t 0.515 masked_v 0.142 NSP 0.059 lr 1.7121e-05
04/19/2022 16:33:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29840 Ep: 0.69 masked_t 0.524 masked_v 0.136 NSP 0.056 lr 1.71671e-05
04/19/2022 16:34:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 29920 Ep: 0.69 masked_t 0.484 masked_v 0.134 NSP 0.058 lr 1.72131e-05
04/19/2022 16:35:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30000 Ep: 0.69 masked_t 0.514 masked_v 0.136 NSP 0.060 lr 1.72592e-05
04/19/2022 16:36:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30080 Ep: 0.69 masked_t 0.475 masked_v 0.136 NSP 0.058 lr 1.73053e-05
04/19/2022 16:37:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30160 Ep: 0.69 masked_t 0.496 masked_v 0.136 NSP 0.061 lr 1.73514e-05
04/19/2022 16:38:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30240 Ep: 0.70 masked_t 0.509 masked_v 0.135 NSP 0.058 lr 1.73975e-05
04/19/2022 16:39:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30320 Ep: 0.70 masked_t 0.526 masked_v 0.129 NSP 0.061 lr 1.74435e-05
04/19/2022 16:40:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30400 Ep: 0.70 masked_t 0.508 masked_v 0.132 NSP 0.058 lr 1.74896e-05
04/19/2022 16:41:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30480 Ep: 0.70 masked_t 0.541 masked_v 0.131 NSP 0.059 lr 1.75357e-05
04/19/2022 16:42:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30560 Ep: 0.70 masked_t 0.477 masked_v 0.134 NSP 0.060 lr 1.75818e-05
04/19/2022 16:43:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30640 Ep: 0.71 masked_t 0.495 masked_v 0.137 NSP 0.061 lr 1.76279e-05
04/19/2022 16:44:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30720 Ep: 0.71 masked_t 0.493 masked_v 0.133 NSP 0.061 lr 1.7674e-05
04/19/2022 16:45:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30800 Ep: 0.71 masked_t 0.503 masked_v 0.135 NSP 0.056 lr 1.772e-05
04/19/2022 16:46:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30880 Ep: 0.71 masked_t 0.509 masked_v 0.136 NSP 0.057 lr 1.77661e-05
04/19/2022 16:46:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 30960 Ep: 0.71 masked_t 0.508 masked_v 0.134 NSP 0.064 lr 1.78122e-05
04/19/2022 16:47:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31040 Ep: 0.72 masked_t 0.523 masked_v 0.135 NSP 0.058 lr 1.78583e-05
04/19/2022 16:48:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31120 Ep: 0.72 masked_t 0.499 masked_v 0.137 NSP 0.066 lr 1.79044e-05
04/19/2022 16:49:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31200 Ep: 0.72 masked_t 0.510 masked_v 0.135 NSP 0.057 lr 1.79505e-05
04/19/2022 16:50:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31280 Ep: 0.72 masked_t 0.518 masked_v 0.133 NSP 0.056 lr 1.79965e-05
04/19/2022 16:51:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31360 Ep: 0.72 masked_t 0.511 masked_v 0.136 NSP 0.051 lr 1.80426e-05
04/19/2022 16:52:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31440 Ep: 0.72 masked_t 0.516 masked_v 0.135 NSP 0.065 lr 1.80887e-05
04/19/2022 16:53:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31520 Ep: 0.73 masked_t 0.495 masked_v 0.129 NSP 0.060 lr 1.81348e-05
04/19/2022 16:54:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31600 Ep: 0.73 masked_t 0.525 masked_v 0.131 NSP 0.057 lr 1.81809e-05
04/19/2022 16:55:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31680 Ep: 0.73 masked_t 0.538 masked_v 0.135 NSP 0.056 lr 1.8227e-05
04/19/2022 16:56:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31760 Ep: 0.73 masked_t 0.502 masked_v 0.129 NSP 0.056 lr 1.8273e-05
04/19/2022 16:57:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31840 Ep: 0.73 masked_t 0.525 masked_v 0.135 NSP 0.061 lr 1.83191e-05
04/19/2022 16:58:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 31920 Ep: 0.74 masked_t 0.508 masked_v 0.131 NSP 0.054 lr 1.83652e-05
04/19/2022 16:59:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32000 Ep: 0.74 masked_t 0.542 masked_v 0.130 NSP 0.059 lr 1.84113e-05
04/19/2022 17:00:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32080 Ep: 0.74 masked_t 0.562 masked_v 0.128 NSP 0.055 lr 1.84574e-05
04/19/2022 17:01:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32160 Ep: 0.74 masked_t 0.519 masked_v 0.126 NSP 0.058 lr 1.85035e-05
04/19/2022 17:01:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32240 Ep: 0.74 masked_t 0.539 masked_v 0.130 NSP 0.058 lr 1.85495e-05
04/19/2022 17:02:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32320 Ep: 0.74 masked_t 0.528 masked_v 0.123 NSP 0.063 lr 1.85956e-05
04/19/2022 17:03:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32400 Ep: 0.75 masked_t 0.520 masked_v 0.127 NSP 0.061 lr 1.86417e-05
04/19/2022 17:04:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32480 Ep: 0.75 masked_t 0.493 masked_v 0.133 NSP 0.063 lr 1.86878e-05
04/19/2022 17:05:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32560 Ep: 0.75 masked_t 0.496 masked_v 0.130 NSP 0.054 lr 1.87339e-05
04/19/2022 17:06:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32640 Ep: 0.75 masked_t 0.508 masked_v 0.129 NSP 0.054 lr 1.878e-05
04/19/2022 17:07:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32720 Ep: 0.75 masked_t 0.530 masked_v 0.130 NSP 0.056 lr 1.8826e-05
04/19/2022 17:08:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32800 Ep: 0.76 masked_t 0.535 masked_v 0.124 NSP 0.061 lr 1.88721e-05
04/19/2022 17:09:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32880 Ep: 0.76 masked_t 0.498 masked_v 0.131 NSP 0.056 lr 1.89182e-05
04/19/2022 17:10:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 32960 Ep: 0.76 masked_t 0.527 masked_v 0.125 NSP 0.057 lr 1.89643e-05
04/19/2022 17:11:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33040 Ep: 0.76 masked_t 0.528 masked_v 0.127 NSP 0.053 lr 1.90104e-05
04/19/2022 17:12:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33120 Ep: 0.76 masked_t 0.493 masked_v 0.130 NSP 0.055 lr 1.90565e-05
04/19/2022 17:13:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33200 Ep: 0.76 masked_t 0.560 masked_v 0.127 NSP 0.057 lr 1.91025e-05
04/19/2022 17:14:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33280 Ep: 0.77 masked_t 0.546 masked_v 0.125 NSP 0.060 lr 1.91486e-05
04/19/2022 17:15:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33360 Ep: 0.77 masked_t 0.511 masked_v 0.126 NSP 0.054 lr 1.91947e-05
04/19/2022 17:16:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33440 Ep: 0.77 masked_t 0.500 masked_v 0.125 NSP 0.066 lr 1.92408e-05
04/19/2022 17:16:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33520 Ep: 0.77 masked_t 0.529 masked_v 0.130 NSP 0.061 lr 1.92869e-05
04/19/2022 17:17:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33600 Ep: 0.77 masked_t 0.489 masked_v 0.132 NSP 0.061 lr 1.93329e-05
04/19/2022 17:18:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33680 Ep: 0.78 masked_t 0.464 masked_v 0.126 NSP 0.056 lr 1.9379e-05
04/19/2022 17:19:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33760 Ep: 0.78 masked_t 0.494 masked_v 0.127 NSP 0.051 lr 1.94251e-05
04/19/2022 17:20:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33840 Ep: 0.78 masked_t 0.520 masked_v 0.128 NSP 0.053 lr 1.94712e-05
04/19/2022 17:21:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 33920 Ep: 0.78 masked_t 0.512 masked_v 0.128 NSP 0.059 lr 1.95173e-05
04/19/2022 17:22:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34000 Ep: 0.78 masked_t 0.493 masked_v 0.122 NSP 0.065 lr 1.95634e-05
04/19/2022 17:23:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34080 Ep: 0.79 masked_t 0.525 masked_v 0.119 NSP 0.056 lr 1.96094e-05
04/19/2022 17:24:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34160 Ep: 0.79 masked_t 0.540 masked_v 0.126 NSP 0.057 lr 1.96555e-05
04/19/2022 17:25:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34240 Ep: 0.79 masked_t 0.506 masked_v 0.126 NSP 0.062 lr 1.97016e-05
04/19/2022 17:26:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34320 Ep: 0.79 masked_t 0.520 masked_v 0.127 NSP 0.053 lr 1.97477e-05
04/19/2022 17:27:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34400 Ep: 0.79 masked_t 0.524 masked_v 0.118 NSP 0.059 lr 1.97938e-05
04/19/2022 17:28:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34480 Ep: 0.79 masked_t 0.483 masked_v 0.126 NSP 0.054 lr 1.98399e-05
04/19/2022 17:29:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34560 Ep: 0.80 masked_t 0.490 masked_v 0.126 NSP 0.060 lr 1.98859e-05
04/19/2022 17:30:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34640 Ep: 0.80 masked_t 0.479 masked_v 0.126 NSP 0.051 lr 1.9932e-05
04/19/2022 17:31:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34720 Ep: 0.80 masked_t 0.503 masked_v 0.126 NSP 0.057 lr 1.99781e-05
04/19/2022 17:32:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34800 Ep: 0.80 masked_t 0.535 masked_v 0.128 NSP 0.059 lr 2.00242e-05
04/19/2022 17:33:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34880 Ep: 0.80 masked_t 0.522 masked_v 0.124 NSP 0.057 lr 2.00703e-05
04/19/2022 17:33:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 34960 Ep: 0.81 masked_t 0.513 masked_v 0.124 NSP 0.055 lr 2.01164e-05
04/19/2022 17:34:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35040 Ep: 0.81 masked_t 0.531 masked_v 0.125 NSP 0.055 lr 2.01624e-05
04/19/2022 17:35:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35120 Ep: 0.81 masked_t 0.516 masked_v 0.125 NSP 0.065 lr 2.02085e-05
04/19/2022 17:36:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35200 Ep: 0.81 masked_t 0.481 masked_v 0.122 NSP 0.059 lr 2.02546e-05
04/19/2022 17:37:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35280 Ep: 0.81 masked_t 0.516 masked_v 0.126 NSP 0.056 lr 2.03007e-05
04/19/2022 17:38:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35360 Ep: 0.81 masked_t 0.474 masked_v 0.125 NSP 0.054 lr 2.03468e-05
04/19/2022 17:39:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35440 Ep: 0.82 masked_t 0.523 masked_v 0.122 NSP 0.052 lr 2.03929e-05
04/19/2022 17:40:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35520 Ep: 0.82 masked_t 0.546 masked_v 0.119 NSP 0.057 lr 2.04389e-05
04/19/2022 17:41:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35600 Ep: 0.82 masked_t 0.499 masked_v 0.125 NSP 0.049 lr 2.0485e-05
04/19/2022 17:42:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35680 Ep: 0.82 masked_t 0.528 masked_v 0.123 NSP 0.051 lr 2.05311e-05
04/19/2022 17:43:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35760 Ep: 0.82 masked_t 0.521 masked_v 0.117 NSP 0.061 lr 2.05772e-05
04/19/2022 17:44:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35840 Ep: 0.83 masked_t 0.533 masked_v 0.125 NSP 0.063 lr 2.06233e-05
04/19/2022 17:45:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 35920 Ep: 0.83 masked_t 0.501 masked_v 0.123 NSP 0.062 lr 2.06694e-05
04/19/2022 17:46:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36000 Ep: 0.83 masked_t 0.488 masked_v 0.121 NSP 0.058 lr 2.07154e-05
04/19/2022 17:47:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36080 Ep: 0.83 masked_t 0.561 masked_v 0.120 NSP 0.062 lr 2.07615e-05
04/19/2022 17:48:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36160 Ep: 0.83 masked_t 0.530 masked_v 0.118 NSP 0.056 lr 2.08076e-05
04/19/2022 17:48:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36240 Ep: 0.84 masked_t 0.543 masked_v 0.119 NSP 0.052 lr 2.08537e-05
04/19/2022 17:49:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36320 Ep: 0.84 masked_t 0.537 masked_v 0.121 NSP 0.065 lr 2.08998e-05
04/19/2022 17:50:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36400 Ep: 0.84 masked_t 0.454 masked_v 0.127 NSP 0.053 lr 2.09459e-05
04/19/2022 17:51:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36480 Ep: 0.84 masked_t 0.525 masked_v 0.123 NSP 0.058 lr 2.09919e-05
04/19/2022 17:52:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36560 Ep: 0.84 masked_t 0.499 masked_v 0.139 NSP 0.058 lr 2.1038e-05
04/19/2022 17:53:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36640 Ep: 0.84 masked_t 0.550 masked_v 0.131 NSP 0.060 lr 2.10841e-05
04/19/2022 17:54:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36720 Ep: 0.85 masked_t 0.526 masked_v 0.127 NSP 0.057 lr 2.11302e-05
04/19/2022 17:55:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36800 Ep: 0.85 masked_t 0.514 masked_v 0.122 NSP 0.061 lr 2.11763e-05
04/19/2022 17:56:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36880 Ep: 0.85 masked_t 0.508 masked_v 0.128 NSP 0.056 lr 2.12224e-05
04/19/2022 17:57:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 36960 Ep: 0.85 masked_t 0.509 masked_v 0.119 NSP 0.064 lr 2.12684e-05
04/19/2022 17:58:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37040 Ep: 0.85 masked_t 0.502 masked_v 0.121 NSP 0.056 lr 2.13145e-05
04/19/2022 17:59:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37120 Ep: 0.86 masked_t 0.470 masked_v 0.126 NSP 0.057 lr 2.13606e-05
04/19/2022 18:00:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37200 Ep: 0.86 masked_t 0.487 masked_v 0.120 NSP 0.053 lr 2.14067e-05
04/19/2022 18:01:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37280 Ep: 0.86 masked_t 0.606 masked_v 0.121 NSP 0.065 lr 2.14528e-05
04/19/2022 18:02:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37360 Ep: 0.86 masked_t 0.508 masked_v 0.121 NSP 0.058 lr 2.14988e-05
04/19/2022 18:03:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37440 Ep: 0.86 masked_t 0.522 masked_v 0.123 NSP 0.054 lr 2.15449e-05
04/19/2022 18:04:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37520 Ep: 0.86 masked_t 0.535 masked_v 0.121 NSP 0.059 lr 2.1591e-05
04/19/2022 18:04:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37600 Ep: 0.87 masked_t 0.533 masked_v 0.125 NSP 0.051 lr 2.16371e-05
04/19/2022 18:05:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37680 Ep: 0.87 masked_t 0.514 masked_v 0.123 NSP 0.050 lr 2.16832e-05
04/19/2022 18:06:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37760 Ep: 0.87 masked_t 0.480 masked_v 0.125 NSP 0.063 lr 2.17293e-05
04/19/2022 18:07:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37840 Ep: 0.87 masked_t 0.536 masked_v 0.125 NSP 0.061 lr 2.17753e-05
04/19/2022 18:08:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 37920 Ep: 0.87 masked_t 0.548 masked_v 0.122 NSP 0.058 lr 2.18214e-05
04/19/2022 18:09:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38000 Ep: 0.88 masked_t 0.531 masked_v 0.123 NSP 0.059 lr 2.18675e-05
04/19/2022 18:10:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38080 Ep: 0.88 masked_t 0.468 masked_v 0.115 NSP 0.053 lr 2.19136e-05
04/19/2022 18:11:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38160 Ep: 0.88 masked_t 0.469 masked_v 0.127 NSP 0.050 lr 2.19597e-05
04/19/2022 18:12:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38240 Ep: 0.88 masked_t 0.488 masked_v 0.123 NSP 0.057 lr 2.20058e-05
04/19/2022 18:13:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38320 Ep: 0.88 masked_t 0.541 masked_v 0.119 NSP 0.063 lr 2.20518e-05
04/19/2022 18:14:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38400 Ep: 0.88 masked_t 0.555 masked_v 0.118 NSP 0.058 lr 2.20979e-05
04/19/2022 18:15:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38480 Ep: 0.89 masked_t 0.484 masked_v 0.119 NSP 0.050 lr 2.2144e-05
04/19/2022 18:16:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38560 Ep: 0.89 masked_t 0.509 masked_v 0.119 NSP 0.057 lr 2.21901e-05
04/19/2022 18:17:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38640 Ep: 0.89 masked_t 0.526 masked_v 0.120 NSP 0.053 lr 2.22362e-05
04/19/2022 18:18:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38720 Ep: 0.89 masked_t 0.518 masked_v 0.122 NSP 0.055 lr 2.22823e-05
04/19/2022 18:19:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38800 Ep: 0.89 masked_t 0.499 masked_v 0.119 NSP 0.058 lr 2.23283e-05
04/19/2022 18:19:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38880 Ep: 0.90 masked_t 0.520 masked_v 0.116 NSP 0.052 lr 2.23744e-05
04/19/2022 18:20:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 38960 Ep: 0.90 masked_t 0.522 masked_v 0.118 NSP 0.059 lr 2.24205e-05
04/19/2022 18:21:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39040 Ep: 0.90 masked_t 0.497 masked_v 0.114 NSP 0.050 lr 2.24666e-05
04/19/2022 18:22:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39120 Ep: 0.90 masked_t 0.511 masked_v 0.120 NSP 0.048 lr 2.25127e-05
04/19/2022 18:23:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39200 Ep: 0.90 masked_t 0.472 masked_v 0.116 NSP 0.053 lr 2.25588e-05
04/19/2022 18:24:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39280 Ep: 0.91 masked_t 0.507 masked_v 0.115 NSP 0.057 lr 2.26048e-05
04/19/2022 18:25:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39360 Ep: 0.91 masked_t 0.506 masked_v 0.114 NSP 0.054 lr 2.26509e-05
04/19/2022 18:26:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39440 Ep: 0.91 masked_t 0.457 masked_v 0.121 NSP 0.051 lr 2.2697e-05
04/19/2022 18:27:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39520 Ep: 0.91 masked_t 0.483 masked_v 0.114 NSP 0.056 lr 2.27431e-05
04/19/2022 18:28:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39600 Ep: 0.91 masked_t 0.525 masked_v 0.118 NSP 0.059 lr 2.27892e-05
04/19/2022 18:29:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39680 Ep: 0.91 masked_t 0.487 masked_v 0.120 NSP 0.049 lr 2.28353e-05
04/19/2022 18:30:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39760 Ep: 0.92 masked_t 0.481 masked_v 0.118 NSP 0.064 lr 2.28813e-05
04/19/2022 18:31:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39840 Ep: 0.92 masked_t 0.468 masked_v 0.118 NSP 0.058 lr 2.29274e-05
04/19/2022 18:32:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 39920 Ep: 0.92 masked_t 0.489 masked_v 0.118 NSP 0.056 lr 2.29735e-05
04/19/2022 18:33:08 - INFO - __main__ -   ** ** * Saving model * ** ** 
04/19/2022 18:33:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40000 Ep: 0.92 masked_t 0.523 masked_v 0.114 NSP 0.055 lr 2.30196e-05
04/19/2022 18:34:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40080 Ep: 0.92 masked_t 0.522 masked_v 0.120 NSP 0.061 lr 2.30657e-05
04/19/2022 18:35:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40160 Ep: 0.93 masked_t 0.479 masked_v 0.117 NSP 0.057 lr 2.31118e-05
04/19/2022 18:36:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40240 Ep: 0.93 masked_t 0.506 masked_v 0.114 NSP 0.055 lr 2.31578e-05
04/19/2022 18:37:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40320 Ep: 0.93 masked_t 0.503 masked_v 0.115 NSP 0.062 lr 2.32039e-05
04/19/2022 18:38:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40400 Ep: 0.93 masked_t 0.524 masked_v 0.116 NSP 0.057 lr 2.325e-05
04/19/2022 18:39:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40480 Ep: 0.93 masked_t 0.524 masked_v 0.120 NSP 0.049 lr 2.32961e-05
04/19/2022 18:40:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40560 Ep: 0.93 masked_t 0.482 masked_v 0.116 NSP 0.051 lr 2.33422e-05
04/19/2022 18:41:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40640 Ep: 0.94 masked_t 0.496 masked_v 0.110 NSP 0.052 lr 2.33882e-05
04/19/2022 18:42:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40720 Ep: 0.94 masked_t 0.507 masked_v 0.115 NSP 0.063 lr 2.34343e-05
04/19/2022 18:43:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40800 Ep: 0.94 masked_t 0.497 masked_v 0.113 NSP 0.062 lr 2.34804e-05
04/19/2022 18:43:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40880 Ep: 0.94 masked_t 0.479 masked_v 0.114 NSP 0.052 lr 2.35265e-05
04/19/2022 18:44:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 40960 Ep: 0.94 masked_t 0.483 masked_v 0.113 NSP 0.056 lr 2.35726e-05
04/19/2022 18:45:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41040 Ep: 0.95 masked_t 0.519 masked_v 0.110 NSP 0.053 lr 2.36187e-05
04/19/2022 18:46:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41120 Ep: 0.95 masked_t 0.530 masked_v 0.111 NSP 0.058 lr 2.36647e-05
04/19/2022 18:47:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41200 Ep: 0.95 masked_t 0.506 masked_v 0.115 NSP 0.057 lr 2.37108e-05
04/19/2022 18:48:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41280 Ep: 0.95 masked_t 0.559 masked_v 0.115 NSP 0.056 lr 2.37569e-05
04/19/2022 18:49:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41360 Ep: 0.95 masked_t 0.551 masked_v 0.114 NSP 0.054 lr 2.3803e-05
04/19/2022 18:50:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41440 Ep: 0.95 masked_t 0.544 masked_v 0.116 NSP 0.044 lr 2.38491e-05
04/19/2022 18:51:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41520 Ep: 0.96 masked_t 0.517 masked_v 0.116 NSP 0.050 lr 2.38952e-05
04/19/2022 18:52:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41600 Ep: 0.96 masked_t 0.525 masked_v 0.118 NSP 0.061 lr 2.39412e-05
04/19/2022 18:53:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41680 Ep: 0.96 masked_t 0.546 masked_v 0.114 NSP 0.055 lr 2.39873e-05
04/19/2022 18:54:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41760 Ep: 0.96 masked_t 0.517 masked_v 0.115 NSP 0.056 lr 2.40334e-05
04/19/2022 18:55:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41840 Ep: 0.96 masked_t 0.505 masked_v 0.112 NSP 0.057 lr 2.40795e-05
04/19/2022 18:56:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 41920 Ep: 0.97 masked_t 0.512 masked_v 0.112 NSP 0.058 lr 2.41256e-05
04/19/2022 18:57:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42000 Ep: 0.97 masked_t 0.545 masked_v 0.113 NSP 0.053 lr 2.41717e-05
04/19/2022 18:58:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42080 Ep: 0.97 masked_t 0.528 masked_v 0.115 NSP 0.053 lr 2.42177e-05
04/19/2022 18:59:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42160 Ep: 0.97 masked_t 0.492 masked_v 0.158 NSP 0.056 lr 2.42638e-05
04/19/2022 18:59:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42240 Ep: 0.97 masked_t 0.531 masked_v 0.127 NSP 0.053 lr 2.43099e-05
04/19/2022 19:00:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42320 Ep: 0.98 masked_t 0.522 masked_v 0.118 NSP 0.058 lr 2.4356e-05
04/19/2022 19:01:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42400 Ep: 0.98 masked_t 0.498 masked_v 0.111 NSP 0.049 lr 2.44021e-05
04/19/2022 19:02:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42480 Ep: 0.98 masked_t 0.538 masked_v 0.117 NSP 0.057 lr 2.44482e-05
04/19/2022 19:03:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42560 Ep: 0.98 masked_t 0.523 masked_v 0.113 NSP 0.056 lr 2.44942e-05
04/19/2022 19:04:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42640 Ep: 0.98 masked_t 0.537 masked_v 0.109 NSP 0.056 lr 2.45403e-05
04/19/2022 19:05:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42720 Ep: 0.98 masked_t 0.492 masked_v 0.111 NSP 0.056 lr 2.45864e-05
04/19/2022 19:06:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42800 Ep: 0.99 masked_t 0.525 masked_v 0.110 NSP 0.053 lr 2.46325e-05
04/19/2022 19:07:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42880 Ep: 0.99 masked_t 0.537 masked_v 0.109 NSP 0.057 lr 2.46786e-05
04/19/2022 19:08:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 42960 Ep: 0.99 masked_t 0.478 masked_v 0.113 NSP 0.062 lr 2.47247e-05
04/19/2022 19:09:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43040 Ep: 0.99 masked_t 0.545 masked_v 0.111 NSP 0.052 lr 2.47707e-05
04/19/2022 19:10:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43120 Ep: 0.99 masked_t 0.495 masked_v 0.114 NSP 0.051 lr 2.48168e-05
04/19/2022 19:11:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43200 Ep: 1.00 masked_t 0.505 masked_v 0.115 NSP 0.048 lr 2.48629e-05
04/19/2022 19:12:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43280 Ep: 1.00 masked_t 0.512 masked_v 0.116 NSP 0.051 lr 2.4909e-05
04/19/2022 19:13:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43360 Ep: 1.00 masked_t 0.524 masked_v 0.114 NSP 0.049 lr 2.49551e-05
04/19/2022 19:14:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43480 Ep: 1.00 masked_t 0.509 masked_v 0.115 NSP 0.057 lr 2.49957e-05
04/19/2022 19:15:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43560 Ep: 1.00 masked_t 0.490 masked_v 0.115 NSP 0.050 lr 2.49963e-05
04/19/2022 19:16:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43640 Ep: 1.01 masked_t 0.547 masked_v 0.112 NSP 0.055 lr 2.49939e-05
04/19/2022 19:17:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43720 Ep: 1.01 masked_t 0.489 masked_v 0.108 NSP 0.052 lr 2.49915e-05
04/19/2022 19:18:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43800 Ep: 1.01 masked_t 0.512 masked_v 0.112 NSP 0.054 lr 2.4989e-05
04/19/2022 19:19:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43880 Ep: 1.01 masked_t 0.506 masked_v 0.106 NSP 0.052 lr 2.49866e-05
04/19/2022 19:20:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 43960 Ep: 1.01 masked_t 0.512 masked_v 0.109 NSP 0.055 lr 2.49842e-05
04/19/2022 19:21:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44040 Ep: 1.01 masked_t 0.546 masked_v 0.110 NSP 0.055 lr 2.49817e-05
04/19/2022 19:22:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44120 Ep: 1.02 masked_t 0.513 masked_v 0.112 NSP 0.059 lr 2.49793e-05
04/19/2022 19:23:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44200 Ep: 1.02 masked_t 0.518 masked_v 0.107 NSP 0.058 lr 2.49769e-05
04/19/2022 19:24:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44280 Ep: 1.02 masked_t 0.530 masked_v 0.109 NSP 0.058 lr 2.49745e-05
04/19/2022 19:25:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44360 Ep: 1.02 masked_t 0.520 masked_v 0.114 NSP 0.056 lr 2.4972e-05
04/19/2022 19:26:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44440 Ep: 1.02 masked_t 0.518 masked_v 0.108 NSP 0.058 lr 2.49696e-05
04/19/2022 19:27:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44520 Ep: 1.03 masked_t 0.509 masked_v 0.111 NSP 0.044 lr 2.49672e-05
04/19/2022 19:28:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44600 Ep: 1.03 masked_t 0.491 masked_v 0.113 NSP 0.049 lr 2.49648e-05
04/19/2022 19:28:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44680 Ep: 1.03 masked_t 0.541 masked_v 0.116 NSP 0.051 lr 2.49623e-05
04/19/2022 19:29:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44760 Ep: 1.03 masked_t 0.491 masked_v 0.114 NSP 0.052 lr 2.49599e-05
04/19/2022 19:30:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44840 Ep: 1.03 masked_t 0.492 masked_v 0.114 NSP 0.058 lr 2.49575e-05
04/19/2022 19:31:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 44920 Ep: 1.04 masked_t 0.467 masked_v 0.108 NSP 0.053 lr 2.49551e-05
04/19/2022 19:32:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45000 Ep: 1.04 masked_t 0.522 masked_v 0.114 NSP 0.055 lr 2.49526e-05
04/19/2022 19:33:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45080 Ep: 1.04 masked_t 0.528 masked_v 0.112 NSP 0.052 lr 2.49502e-05
04/19/2022 19:34:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45160 Ep: 1.04 masked_t 0.494 masked_v 0.113 NSP 0.045 lr 2.49478e-05
04/19/2022 19:35:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45240 Ep: 1.04 masked_t 0.521 masked_v 0.111 NSP 0.046 lr 2.49454e-05
04/19/2022 19:36:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45320 Ep: 1.04 masked_t 0.493 masked_v 0.112 NSP 0.054 lr 2.49429e-05
04/19/2022 19:37:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45400 Ep: 1.05 masked_t 0.520 masked_v 0.109 NSP 0.053 lr 2.49405e-05
04/19/2022 19:38:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45480 Ep: 1.05 masked_t 0.553 masked_v 0.115 NSP 0.052 lr 2.49381e-05
04/19/2022 19:39:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45560 Ep: 1.05 masked_t 0.495 masked_v 0.109 NSP 0.056 lr 2.49357e-05
04/19/2022 19:40:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45640 Ep: 1.05 masked_t 0.537 masked_v 0.116 NSP 0.053 lr 2.49332e-05
04/19/2022 19:41:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45720 Ep: 1.05 masked_t 0.520 masked_v 0.107 NSP 0.055 lr 2.49308e-05
04/19/2022 19:42:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45800 Ep: 1.06 masked_t 0.486 masked_v 0.106 NSP 0.058 lr 2.49284e-05
04/19/2022 19:43:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45880 Ep: 1.06 masked_t 0.501 masked_v 0.107 NSP 0.055 lr 2.4926e-05
04/19/2022 19:44:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 45960 Ep: 1.06 masked_t 0.525 masked_v 0.114 NSP 0.046 lr 2.49235e-05
04/19/2022 19:45:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46040 Ep: 1.06 masked_t 0.564 masked_v 0.110 NSP 0.053 lr 2.49211e-05
04/19/2022 19:46:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46120 Ep: 1.06 masked_t 0.524 masked_v 0.108 NSP 0.051 lr 2.49187e-05
04/19/2022 19:47:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46200 Ep: 1.06 masked_t 0.502 masked_v 0.109 NSP 0.047 lr 2.49163e-05
04/19/2022 19:48:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46280 Ep: 1.07 masked_t 0.577 masked_v 0.110 NSP 0.061 lr 2.49138e-05
04/19/2022 19:49:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46360 Ep: 1.07 masked_t 0.523 masked_v 0.108 NSP 0.055 lr 2.49114e-05
04/19/2022 19:49:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46440 Ep: 1.07 masked_t 0.541 masked_v 0.111 NSP 0.054 lr 2.4909e-05
04/19/2022 19:50:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46520 Ep: 1.07 masked_t 0.545 masked_v 0.108 NSP 0.062 lr 2.49066e-05
04/19/2022 19:51:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46600 Ep: 1.07 masked_t 0.514 masked_v 0.106 NSP 0.047 lr 2.49041e-05
04/19/2022 19:52:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46680 Ep: 1.08 masked_t 0.513 masked_v 0.116 NSP 0.054 lr 2.49017e-05
04/19/2022 19:53:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46760 Ep: 1.08 masked_t 0.493 masked_v 0.107 NSP 0.055 lr 2.48993e-05
04/19/2022 19:54:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46840 Ep: 1.08 masked_t 0.510 masked_v 0.112 NSP 0.051 lr 2.48969e-05
04/19/2022 19:55:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 46920 Ep: 1.08 masked_t 0.487 masked_v 0.112 NSP 0.053 lr 2.48944e-05
04/19/2022 19:56:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47000 Ep: 1.08 masked_t 0.525 masked_v 0.105 NSP 0.057 lr 2.4892e-05
04/19/2022 19:57:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47080 Ep: 1.08 masked_t 0.554 masked_v 0.112 NSP 0.056 lr 2.48896e-05
04/19/2022 19:58:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47160 Ep: 1.09 masked_t 0.482 masked_v 0.111 NSP 0.053 lr 2.48872e-05
04/19/2022 19:59:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47240 Ep: 1.09 masked_t 0.471 masked_v 0.108 NSP 0.055 lr 2.48847e-05
04/19/2022 20:00:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47320 Ep: 1.09 masked_t 0.525 masked_v 0.109 NSP 0.049 lr 2.48823e-05
04/19/2022 20:01:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47400 Ep: 1.09 masked_t 0.550 masked_v 0.104 NSP 0.056 lr 2.48799e-05
04/19/2022 20:02:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47480 Ep: 1.09 masked_t 0.539 masked_v 0.112 NSP 0.053 lr 2.48775e-05
04/19/2022 20:03:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47560 Ep: 1.10 masked_t 0.481 masked_v 0.111 NSP 0.051 lr 2.4875e-05
04/19/2022 20:04:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47640 Ep: 1.10 masked_t 0.507 masked_v 0.106 NSP 0.055 lr 2.48726e-05
04/19/2022 20:04:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47720 Ep: 1.10 masked_t 0.520 masked_v 0.105 NSP 0.054 lr 2.48702e-05
04/19/2022 20:05:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47800 Ep: 1.10 masked_t 0.544 masked_v 0.108 NSP 0.054 lr 2.48678e-05
04/19/2022 20:06:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47880 Ep: 1.10 masked_t 0.534 masked_v 0.106 NSP 0.059 lr 2.48653e-05
04/19/2022 20:07:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 47960 Ep: 1.11 masked_t 0.515 masked_v 0.109 NSP 0.051 lr 2.48629e-05
04/19/2022 20:08:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48040 Ep: 1.11 masked_t 0.513 masked_v 0.105 NSP 0.056 lr 2.48605e-05
04/19/2022 20:09:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48120 Ep: 1.11 masked_t 0.492 masked_v 0.109 NSP 0.051 lr 2.48581e-05
04/19/2022 20:10:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48200 Ep: 1.11 masked_t 0.483 masked_v 0.105 NSP 0.048 lr 2.48556e-05
04/19/2022 20:11:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48280 Ep: 1.11 masked_t 0.549 masked_v 0.108 NSP 0.054 lr 2.48532e-05
04/19/2022 20:12:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48360 Ep: 1.11 masked_t 0.578 masked_v 0.106 NSP 0.051 lr 2.48508e-05
04/19/2022 20:13:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48440 Ep: 1.12 masked_t 0.512 masked_v 0.107 NSP 0.063 lr 2.48484e-05
04/19/2022 20:14:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48520 Ep: 1.12 masked_t 0.508 masked_v 0.109 NSP 0.058 lr 2.48459e-05
04/19/2022 20:15:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48600 Ep: 1.12 masked_t 0.485 masked_v 0.108 NSP 0.054 lr 2.48435e-05
04/19/2022 20:16:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48680 Ep: 1.12 masked_t 0.475 masked_v 0.110 NSP 0.054 lr 2.48411e-05
04/19/2022 20:17:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48760 Ep: 1.12 masked_t 0.527 masked_v 0.105 NSP 0.050 lr 2.48386e-05
04/19/2022 20:18:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48840 Ep: 1.13 masked_t 0.491 masked_v 0.108 NSP 0.054 lr 2.48362e-05
04/19/2022 20:19:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 48920 Ep: 1.13 masked_t 0.524 masked_v 0.101 NSP 0.047 lr 2.48338e-05
04/19/2022 20:20:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49000 Ep: 1.13 masked_t 0.521 masked_v 0.103 NSP 0.052 lr 2.48314e-05
04/19/2022 20:21:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49080 Ep: 1.13 masked_t 0.522 masked_v 0.103 NSP 0.056 lr 2.48289e-05
04/19/2022 20:22:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49160 Ep: 1.13 masked_t 0.512 masked_v 0.107 NSP 0.053 lr 2.48265e-05
04/19/2022 20:23:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49240 Ep: 1.13 masked_t 0.511 masked_v 0.110 NSP 0.044 lr 2.48241e-05
04/19/2022 20:23:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49320 Ep: 1.14 masked_t 0.530 masked_v 0.104 NSP 0.050 lr 2.48217e-05
04/19/2022 20:24:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49400 Ep: 1.14 masked_t 0.515 masked_v 0.111 NSP 0.044 lr 2.48192e-05
04/19/2022 20:25:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49480 Ep: 1.14 masked_t 0.466 masked_v 0.107 NSP 0.049 lr 2.48168e-05
04/19/2022 20:26:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49560 Ep: 1.14 masked_t 0.530 masked_v 0.104 NSP 0.044 lr 2.48144e-05
04/19/2022 20:27:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49640 Ep: 1.14 masked_t 0.480 masked_v 0.107 NSP 0.053 lr 2.4812e-05
04/19/2022 20:28:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49720 Ep: 1.15 masked_t 0.525 masked_v 0.105 NSP 0.045 lr 2.48095e-05
04/19/2022 20:29:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49800 Ep: 1.15 masked_t 0.487 masked_v 0.100 NSP 0.051 lr 2.48071e-05
04/19/2022 20:30:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49880 Ep: 1.15 masked_t 0.519 masked_v 0.102 NSP 0.056 lr 2.48047e-05
04/19/2022 20:31:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 49960 Ep: 1.15 masked_t 0.538 masked_v 0.101 NSP 0.051 lr 2.48023e-05
04/19/2022 20:32:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50040 Ep: 1.15 masked_t 0.523 masked_v 0.108 NSP 0.053 lr 2.47998e-05
04/19/2022 20:33:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50120 Ep: 1.15 masked_t 0.535 masked_v 0.105 NSP 0.048 lr 2.47974e-05
04/19/2022 20:34:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50200 Ep: 1.16 masked_t 0.496 masked_v 0.102 NSP 0.053 lr 2.4795e-05
04/19/2022 20:35:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50280 Ep: 1.16 masked_t 0.538 masked_v 0.105 NSP 0.052 lr 2.47926e-05
04/19/2022 20:36:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50360 Ep: 1.16 masked_t 0.500 masked_v 0.109 NSP 0.047 lr 2.47901e-05
04/19/2022 20:37:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50440 Ep: 1.16 masked_t 0.499 masked_v 0.109 NSP 0.052 lr 2.47877e-05
04/19/2022 20:38:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50520 Ep: 1.16 masked_t 0.504 masked_v 0.103 NSP 0.051 lr 2.47853e-05
04/19/2022 20:39:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50600 Ep: 1.17 masked_t 0.478 masked_v 0.103 NSP 0.053 lr 2.47829e-05
04/19/2022 20:40:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50680 Ep: 1.17 masked_t 0.543 masked_v 0.104 NSP 0.044 lr 2.47804e-05
04/19/2022 20:41:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50760 Ep: 1.17 masked_t 0.505 masked_v 0.108 NSP 0.054 lr 2.4778e-05
04/19/2022 20:41:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50840 Ep: 1.17 masked_t 0.512 masked_v 0.102 NSP 0.044 lr 2.47756e-05
04/19/2022 20:42:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 50920 Ep: 1.17 masked_t 0.514 masked_v 0.099 NSP 0.055 lr 2.47732e-05
04/19/2022 20:43:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51000 Ep: 1.18 masked_t 0.476 masked_v 0.107 NSP 0.044 lr 2.47707e-05
04/19/2022 20:44:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51080 Ep: 1.18 masked_t 0.503 masked_v 0.104 NSP 0.053 lr 2.47683e-05
04/19/2022 20:45:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51160 Ep: 1.18 masked_t 0.534 masked_v 0.105 NSP 0.048 lr 2.47659e-05
04/19/2022 20:46:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51240 Ep: 1.18 masked_t 0.510 masked_v 0.102 NSP 0.054 lr 2.47635e-05
04/19/2022 20:47:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51320 Ep: 1.18 masked_t 0.515 masked_v 0.103 NSP 0.055 lr 2.4761e-05
04/19/2022 20:48:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51400 Ep: 1.18 masked_t 0.512 masked_v 0.107 NSP 0.062 lr 2.47586e-05
04/19/2022 20:49:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51480 Ep: 1.19 masked_t 0.494 masked_v 0.105 NSP 0.053 lr 2.47562e-05
04/19/2022 20:50:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51560 Ep: 1.19 masked_t 0.499 masked_v 0.101 NSP 0.045 lr 2.47538e-05
04/19/2022 20:51:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51640 Ep: 1.19 masked_t 0.513 masked_v 0.103 NSP 0.052 lr 2.47513e-05
04/19/2022 20:52:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51720 Ep: 1.19 masked_t 0.536 masked_v 0.102 NSP 0.049 lr 2.47489e-05
04/19/2022 20:53:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51800 Ep: 1.19 masked_t 0.506 masked_v 0.105 NSP 0.052 lr 2.47465e-05
04/19/2022 20:54:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51880 Ep: 1.20 masked_t 0.551 masked_v 0.104 NSP 0.049 lr 2.47441e-05
04/19/2022 20:55:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 51960 Ep: 1.20 masked_t 0.531 masked_v 0.104 NSP 0.047 lr 2.47416e-05
04/19/2022 20:56:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52040 Ep: 1.20 masked_t 0.503 masked_v 0.104 NSP 0.053 lr 2.47392e-05
04/19/2022 20:57:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52120 Ep: 1.20 masked_t 0.533 masked_v 0.107 NSP 0.049 lr 2.47368e-05
04/19/2022 20:58:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52200 Ep: 1.20 masked_t 0.527 masked_v 0.111 NSP 0.046 lr 2.47344e-05
04/19/2022 20:59:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52280 Ep: 1.20 masked_t 0.471 masked_v 0.102 NSP 0.053 lr 2.47319e-05
04/19/2022 20:59:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52360 Ep: 1.21 masked_t 0.502 masked_v 0.101 NSP 0.047 lr 2.47295e-05
04/19/2022 21:00:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52440 Ep: 1.21 masked_t 0.496 masked_v 0.104 NSP 0.048 lr 2.47271e-05
04/19/2022 21:01:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52520 Ep: 1.21 masked_t 0.508 masked_v 0.103 NSP 0.050 lr 2.47247e-05
04/19/2022 21:02:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52600 Ep: 1.21 masked_t 0.541 masked_v 0.106 NSP 0.059 lr 2.47222e-05
04/19/2022 21:03:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52680 Ep: 1.21 masked_t 0.524 masked_v 0.103 NSP 0.049 lr 2.47198e-05
04/19/2022 21:04:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52760 Ep: 1.22 masked_t 0.466 masked_v 0.104 NSP 0.052 lr 2.47174e-05
04/19/2022 21:05:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52840 Ep: 1.22 masked_t 0.487 masked_v 0.094 NSP 0.054 lr 2.4715e-05
04/19/2022 21:06:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 52920 Ep: 1.22 masked_t 0.483 masked_v 0.107 NSP 0.050 lr 2.47125e-05
04/19/2022 21:07:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53000 Ep: 1.22 masked_t 0.528 masked_v 0.108 NSP 0.045 lr 2.47101e-05
04/19/2022 21:08:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53080 Ep: 1.22 masked_t 0.520 masked_v 0.098 NSP 0.047 lr 2.47077e-05
04/19/2022 21:09:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53160 Ep: 1.22 masked_t 0.510 masked_v 0.105 NSP 0.051 lr 2.47053e-05
04/19/2022 21:10:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53240 Ep: 1.23 masked_t 0.509 masked_v 0.103 NSP 0.057 lr 2.47028e-05
04/19/2022 21:11:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53320 Ep: 1.23 masked_t 0.526 masked_v 0.099 NSP 0.050 lr 2.47004e-05
04/19/2022 21:12:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53400 Ep: 1.23 masked_t 0.522 masked_v 0.104 NSP 0.050 lr 2.4698e-05
04/19/2022 21:13:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53480 Ep: 1.23 masked_t 0.478 masked_v 0.102 NSP 0.058 lr 2.46955e-05
04/19/2022 21:14:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53560 Ep: 1.23 masked_t 0.497 masked_v 0.105 NSP 0.048 lr 2.46931e-05
04/19/2022 21:15:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53640 Ep: 1.24 masked_t 0.495 masked_v 0.102 NSP 0.051 lr 2.46907e-05
04/19/2022 21:16:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53720 Ep: 1.24 masked_t 0.481 masked_v 0.098 NSP 0.048 lr 2.46883e-05
04/19/2022 21:17:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53800 Ep: 1.24 masked_t 0.535 masked_v 0.102 NSP 0.059 lr 2.46858e-05
04/19/2022 21:17:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53880 Ep: 1.24 masked_t 0.508 masked_v 0.104 NSP 0.051 lr 2.46834e-05
04/19/2022 21:18:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 53960 Ep: 1.24 masked_t 0.511 masked_v 0.100 NSP 0.055 lr 2.4681e-05
04/19/2022 21:19:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54040 Ep: 1.25 masked_t 0.511 masked_v 0.101 NSP 0.053 lr 2.46786e-05
04/19/2022 21:20:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54120 Ep: 1.25 masked_t 0.491 masked_v 0.104 NSP 0.047 lr 2.46761e-05
04/19/2022 21:21:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54200 Ep: 1.25 masked_t 0.473 masked_v 0.101 NSP 0.052 lr 2.46737e-05
04/19/2022 21:22:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54280 Ep: 1.25 masked_t 0.490 masked_v 0.105 NSP 0.047 lr 2.46713e-05
04/19/2022 21:23:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54360 Ep: 1.25 masked_t 0.475 masked_v 0.104 NSP 0.057 lr 2.46689e-05
04/19/2022 21:24:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54440 Ep: 1.25 masked_t 0.520 masked_v 0.102 NSP 0.047 lr 2.46664e-05
04/19/2022 21:25:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54520 Ep: 1.26 masked_t 0.533 masked_v 0.096 NSP 0.047 lr 2.4664e-05
04/19/2022 21:26:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54600 Ep: 1.26 masked_t 0.542 masked_v 0.097 NSP 0.047 lr 2.46616e-05
04/19/2022 21:27:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54680 Ep: 1.26 masked_t 0.470 masked_v 0.101 NSP 0.051 lr 2.46592e-05
04/19/2022 21:28:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54760 Ep: 1.26 masked_t 0.492 masked_v 0.100 NSP 0.053 lr 2.46567e-05
04/19/2022 21:29:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54840 Ep: 1.26 masked_t 0.539 masked_v 0.101 NSP 0.044 lr 2.46543e-05
04/19/2022 21:30:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 54920 Ep: 1.27 masked_t 0.515 masked_v 0.100 NSP 0.052 lr 2.46519e-05
04/19/2022 21:31:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55000 Ep: 1.27 masked_t 0.511 masked_v 0.102 NSP 0.053 lr 2.46495e-05
04/19/2022 21:32:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55080 Ep: 1.27 masked_t 0.482 masked_v 0.105 NSP 0.050 lr 2.4647e-05
04/19/2022 21:33:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55160 Ep: 1.27 masked_t 0.529 masked_v 0.102 NSP 0.043 lr 2.46446e-05
04/19/2022 21:34:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55240 Ep: 1.27 masked_t 0.488 masked_v 0.096 NSP 0.046 lr 2.46422e-05
04/19/2022 21:34:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55320 Ep: 1.27 masked_t 0.491 masked_v 0.102 NSP 0.052 lr 2.46398e-05
04/19/2022 21:35:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55400 Ep: 1.28 masked_t 0.499 masked_v 0.102 NSP 0.050 lr 2.46373e-05
04/19/2022 21:36:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55480 Ep: 1.28 masked_t 0.551 masked_v 0.098 NSP 0.050 lr 2.46349e-05
04/19/2022 21:37:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55560 Ep: 1.28 masked_t 0.500 masked_v 0.105 NSP 0.046 lr 2.46325e-05
04/19/2022 21:38:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55640 Ep: 1.28 masked_t 0.520 masked_v 0.098 NSP 0.049 lr 2.46301e-05
04/19/2022 21:39:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55720 Ep: 1.28 masked_t 0.516 masked_v 0.100 NSP 0.050 lr 2.46276e-05
04/19/2022 21:40:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55800 Ep: 1.29 masked_t 0.514 masked_v 0.100 NSP 0.054 lr 2.46252e-05
04/19/2022 21:41:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55880 Ep: 1.29 masked_t 0.559 masked_v 0.105 NSP 0.048 lr 2.46228e-05
04/19/2022 21:42:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 55960 Ep: 1.29 masked_t 0.511 masked_v 0.096 NSP 0.047 lr 2.46204e-05
04/19/2022 21:43:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56040 Ep: 1.29 masked_t 0.493 masked_v 0.102 NSP 0.050 lr 2.46179e-05
04/19/2022 21:44:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56120 Ep: 1.29 masked_t 0.519 masked_v 0.101 NSP 0.050 lr 2.46155e-05
04/19/2022 21:45:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56200 Ep: 1.29 masked_t 0.463 masked_v 0.102 NSP 0.046 lr 2.46131e-05
04/19/2022 21:46:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56280 Ep: 1.30 masked_t 0.505 masked_v 0.103 NSP 0.051 lr 2.46107e-05
04/19/2022 21:47:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56360 Ep: 1.30 masked_t 0.551 masked_v 0.101 NSP 0.052 lr 2.46082e-05
04/19/2022 21:48:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56440 Ep: 1.30 masked_t 0.552 masked_v 0.101 NSP 0.050 lr 2.46058e-05
04/19/2022 21:49:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56520 Ep: 1.30 masked_t 0.475 masked_v 0.100 NSP 0.057 lr 2.46034e-05
04/19/2022 21:50:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56600 Ep: 1.30 masked_t 0.526 masked_v 0.099 NSP 0.051 lr 2.4601e-05
04/19/2022 21:51:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56680 Ep: 1.31 masked_t 0.515 masked_v 0.100 NSP 0.046 lr 2.45985e-05
04/19/2022 21:52:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56760 Ep: 1.31 masked_t 0.528 masked_v 0.099 NSP 0.051 lr 2.45961e-05
04/19/2022 21:53:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56840 Ep: 1.31 masked_t 0.480 masked_v 0.100 NSP 0.046 lr 2.45937e-05
04/19/2022 21:53:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 56920 Ep: 1.31 masked_t 0.523 masked_v 0.097 NSP 0.047 lr 2.45913e-05
04/19/2022 21:54:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57000 Ep: 1.31 masked_t 0.488 masked_v 0.098 NSP 0.049 lr 2.45888e-05
04/19/2022 21:55:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57080 Ep: 1.32 masked_t 0.491 masked_v 0.099 NSP 0.048 lr 2.45864e-05
04/19/2022 21:56:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57160 Ep: 1.32 masked_t 0.521 masked_v 0.099 NSP 0.048 lr 2.4584e-05
04/19/2022 21:57:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57240 Ep: 1.32 masked_t 0.506 masked_v 0.095 NSP 0.048 lr 2.45816e-05
04/19/2022 21:58:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57320 Ep: 1.32 masked_t 0.505 masked_v 0.100 NSP 0.041 lr 2.45791e-05
04/19/2022 21:59:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57400 Ep: 1.32 masked_t 0.509 masked_v 0.095 NSP 0.050 lr 2.45767e-05
04/19/2022 22:00:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57480 Ep: 1.32 masked_t 0.504 masked_v 0.097 NSP 0.052 lr 2.45743e-05
04/19/2022 22:01:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57560 Ep: 1.33 masked_t 0.486 masked_v 0.099 NSP 0.051 lr 2.45719e-05
04/19/2022 22:02:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57640 Ep: 1.33 masked_t 0.528 masked_v 0.103 NSP 0.047 lr 2.45694e-05
04/19/2022 22:03:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57720 Ep: 1.33 masked_t 0.487 masked_v 0.098 NSP 0.044 lr 2.4567e-05
04/19/2022 22:04:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57800 Ep: 1.33 masked_t 0.499 masked_v 0.093 NSP 0.046 lr 2.45646e-05
04/19/2022 22:05:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57880 Ep: 1.33 masked_t 0.473 masked_v 0.097 NSP 0.044 lr 2.45622e-05
04/19/2022 22:06:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 57960 Ep: 1.34 masked_t 0.540 masked_v 0.097 NSP 0.048 lr 2.45597e-05
04/19/2022 22:07:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58040 Ep: 1.34 masked_t 0.493 masked_v 0.099 NSP 0.054 lr 2.45573e-05
04/19/2022 22:08:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58120 Ep: 1.34 masked_t 0.522 masked_v 0.103 NSP 0.046 lr 2.45549e-05
04/19/2022 22:09:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58200 Ep: 1.34 masked_t 0.502 masked_v 0.102 NSP 0.050 lr 2.45524e-05
04/19/2022 22:10:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58280 Ep: 1.34 masked_t 0.499 masked_v 0.099 NSP 0.049 lr 2.455e-05
04/19/2022 22:11:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58360 Ep: 1.34 masked_t 0.480 masked_v 0.098 NSP 0.039 lr 2.45476e-05
04/19/2022 22:11:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58440 Ep: 1.35 masked_t 0.510 masked_v 0.097 NSP 0.045 lr 2.45452e-05
04/19/2022 22:12:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58520 Ep: 1.35 masked_t 0.530 masked_v 0.097 NSP 0.055 lr 2.45427e-05
04/19/2022 22:13:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58600 Ep: 1.35 masked_t 0.468 masked_v 0.106 NSP 0.056 lr 2.45403e-05
04/19/2022 22:14:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58680 Ep: 1.35 masked_t 0.512 masked_v 0.104 NSP 0.047 lr 2.45379e-05
04/19/2022 22:15:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58760 Ep: 1.35 masked_t 0.526 masked_v 0.095 NSP 0.045 lr 2.45355e-05
04/19/2022 22:16:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58840 Ep: 1.36 masked_t 0.534 masked_v 0.096 NSP 0.046 lr 2.4533e-05
04/19/2022 22:17:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 58920 Ep: 1.36 masked_t 0.509 masked_v 0.100 NSP 0.043 lr 2.45306e-05
04/19/2022 22:18:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59000 Ep: 1.36 masked_t 0.535 masked_v 0.098 NSP 0.050 lr 2.45282e-05
04/19/2022 22:19:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59080 Ep: 1.36 masked_t 0.460 masked_v 0.098 NSP 0.043 lr 2.45258e-05
04/19/2022 22:20:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59160 Ep: 1.36 masked_t 0.516 masked_v 0.097 NSP 0.049 lr 2.45233e-05
04/19/2022 22:21:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59240 Ep: 1.36 masked_t 0.484 masked_v 0.097 NSP 0.045 lr 2.45209e-05
04/19/2022 22:22:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59320 Ep: 1.37 masked_t 0.495 masked_v 0.098 NSP 0.052 lr 2.45185e-05
04/19/2022 22:23:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59400 Ep: 1.37 masked_t 0.489 masked_v 0.097 NSP 0.047 lr 2.45161e-05
04/19/2022 22:24:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59480 Ep: 1.37 masked_t 0.497 masked_v 0.098 NSP 0.050 lr 2.45136e-05
04/19/2022 22:25:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59560 Ep: 1.37 masked_t 0.528 masked_v 0.095 NSP 0.054 lr 2.45112e-05
04/19/2022 22:26:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59640 Ep: 1.37 masked_t 0.476 masked_v 0.097 NSP 0.047 lr 2.45088e-05
04/19/2022 22:27:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59720 Ep: 1.38 masked_t 0.489 masked_v 0.100 NSP 0.048 lr 2.45064e-05
04/19/2022 22:28:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59800 Ep: 1.38 masked_t 0.482 masked_v 0.100 NSP 0.051 lr 2.45039e-05
04/19/2022 22:29:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59880 Ep: 1.38 masked_t 0.512 masked_v 0.099 NSP 0.046 lr 2.45015e-05
04/19/2022 22:29:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 59960 Ep: 1.38 masked_t 0.483 masked_v 0.102 NSP 0.044 lr 2.44991e-05
04/19/2022 22:30:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60040 Ep: 1.38 masked_t 0.469 masked_v 0.100 NSP 0.052 lr 2.44967e-05
04/19/2022 22:31:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60120 Ep: 1.39 masked_t 0.514 masked_v 0.099 NSP 0.047 lr 2.44942e-05
04/19/2022 22:32:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60200 Ep: 1.39 masked_t 0.478 masked_v 0.097 NSP 0.051 lr 2.44918e-05
04/19/2022 22:33:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60280 Ep: 1.39 masked_t 0.536 masked_v 0.105 NSP 0.052 lr 2.44894e-05
04/19/2022 22:34:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60360 Ep: 1.39 masked_t 0.489 masked_v 0.103 NSP 0.054 lr 2.4487e-05
04/19/2022 22:35:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60440 Ep: 1.39 masked_t 0.486 masked_v 0.094 NSP 0.052 lr 2.44845e-05
04/19/2022 22:36:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60520 Ep: 1.39 masked_t 0.479 masked_v 0.095 NSP 0.046 lr 2.44821e-05
04/19/2022 22:37:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60600 Ep: 1.40 masked_t 0.494 masked_v 0.097 NSP 0.046 lr 2.44797e-05
04/19/2022 22:38:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60680 Ep: 1.40 masked_t 0.498 masked_v 0.099 NSP 0.050 lr 2.44773e-05
04/19/2022 22:39:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60760 Ep: 1.40 masked_t 0.477 masked_v 0.098 NSP 0.037 lr 2.44748e-05
04/19/2022 22:40:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60840 Ep: 1.40 masked_t 0.540 masked_v 0.102 NSP 0.047 lr 2.44724e-05
04/19/2022 22:41:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 60920 Ep: 1.40 masked_t 0.533 masked_v 0.101 NSP 0.047 lr 2.447e-05
04/19/2022 22:42:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61000 Ep: 1.41 masked_t 0.503 masked_v 0.097 NSP 0.050 lr 2.44676e-05
04/19/2022 22:43:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61080 Ep: 1.41 masked_t 0.489 masked_v 0.098 NSP 0.049 lr 2.44651e-05
04/19/2022 22:44:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61160 Ep: 1.41 masked_t 0.483 masked_v 0.097 NSP 0.041 lr 2.44627e-05
04/19/2022 22:45:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61240 Ep: 1.41 masked_t 0.499 masked_v 0.095 NSP 0.044 lr 2.44603e-05
04/19/2022 22:46:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61320 Ep: 1.41 masked_t 0.533 masked_v 0.099 NSP 0.052 lr 2.44579e-05
04/19/2022 22:47:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61400 Ep: 1.41 masked_t 0.546 masked_v 0.099 NSP 0.047 lr 2.44554e-05
04/19/2022 22:48:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61480 Ep: 1.42 masked_t 0.517 masked_v 0.097 NSP 0.052 lr 2.4453e-05
04/19/2022 22:48:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61560 Ep: 1.42 masked_t 0.501 masked_v 0.095 NSP 0.051 lr 2.44506e-05
04/19/2022 22:49:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61640 Ep: 1.42 masked_t 0.479 masked_v 0.096 NSP 0.048 lr 2.44482e-05
04/19/2022 22:50:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61720 Ep: 1.42 masked_t 0.509 masked_v 0.101 NSP 0.053 lr 2.44457e-05
04/19/2022 22:51:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61800 Ep: 1.42 masked_t 0.519 masked_v 0.101 NSP 0.051 lr 2.44433e-05
04/19/2022 22:52:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61880 Ep: 1.43 masked_t 0.458 masked_v 0.096 NSP 0.045 lr 2.44409e-05
04/19/2022 22:53:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 61960 Ep: 1.43 masked_t 0.498 masked_v 0.101 NSP 0.048 lr 2.44385e-05
04/19/2022 22:54:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62040 Ep: 1.43 masked_t 0.518 masked_v 0.097 NSP 0.047 lr 2.4436e-05
04/19/2022 22:55:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62120 Ep: 1.43 masked_t 0.507 masked_v 0.090 NSP 0.054 lr 2.44336e-05
04/19/2022 22:56:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62200 Ep: 1.43 masked_t 0.471 masked_v 0.094 NSP 0.042 lr 2.44312e-05
04/19/2022 22:57:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62280 Ep: 1.43 masked_t 0.463 masked_v 0.096 NSP 0.044 lr 2.44288e-05
04/19/2022 22:58:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62360 Ep: 1.44 masked_t 0.474 masked_v 0.099 NSP 0.049 lr 2.44263e-05
04/19/2022 22:59:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62440 Ep: 1.44 masked_t 0.506 masked_v 0.095 NSP 0.043 lr 2.44239e-05
04/19/2022 23:00:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62520 Ep: 1.44 masked_t 0.476 masked_v 0.095 NSP 0.054 lr 2.44215e-05
04/19/2022 23:01:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62600 Ep: 1.44 masked_t 0.496 masked_v 0.094 NSP 0.051 lr 2.44191e-05
04/19/2022 23:02:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62680 Ep: 1.44 masked_t 0.498 masked_v 0.091 NSP 0.052 lr 2.44166e-05
04/19/2022 23:03:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62760 Ep: 1.45 masked_t 0.504 masked_v 0.097 NSP 0.047 lr 2.44142e-05
04/19/2022 23:04:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62840 Ep: 1.45 masked_t 0.494 masked_v 0.096 NSP 0.042 lr 2.44118e-05
04/19/2022 23:05:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 62920 Ep: 1.45 masked_t 0.459 masked_v 0.096 NSP 0.053 lr 2.44093e-05
04/19/2022 23:06:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63000 Ep: 1.45 masked_t 0.499 masked_v 0.094 NSP 0.051 lr 2.44069e-05
04/19/2022 23:07:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63080 Ep: 1.45 masked_t 0.486 masked_v 0.094 NSP 0.044 lr 2.44045e-05
04/19/2022 23:07:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63160 Ep: 1.46 masked_t 0.522 masked_v 0.097 NSP 0.050 lr 2.44021e-05
04/19/2022 23:08:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63240 Ep: 1.46 masked_t 0.473 masked_v 0.102 NSP 0.048 lr 2.43996e-05
04/19/2022 23:09:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63320 Ep: 1.46 masked_t 0.470 masked_v 0.095 NSP 0.053 lr 2.43972e-05
04/19/2022 23:10:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63400 Ep: 1.46 masked_t 0.496 masked_v 0.098 NSP 0.059 lr 2.43948e-05
04/19/2022 23:11:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63480 Ep: 1.46 masked_t 0.519 masked_v 0.095 NSP 0.052 lr 2.43924e-05
04/19/2022 23:12:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63560 Ep: 1.46 masked_t 0.511 masked_v 0.093 NSP 0.045 lr 2.43899e-05
04/19/2022 23:13:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63640 Ep: 1.47 masked_t 0.521 masked_v 0.098 NSP 0.051 lr 2.43875e-05
04/19/2022 23:14:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63720 Ep: 1.47 masked_t 0.526 masked_v 0.093 NSP 0.053 lr 2.43851e-05
04/19/2022 23:15:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63800 Ep: 1.47 masked_t 0.495 masked_v 0.096 NSP 0.043 lr 2.43827e-05
04/19/2022 23:16:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63880 Ep: 1.47 masked_t 0.481 masked_v 0.098 NSP 0.044 lr 2.43802e-05
04/19/2022 23:17:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 63960 Ep: 1.47 masked_t 0.524 masked_v 0.094 NSP 0.050 lr 2.43778e-05
04/19/2022 23:18:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64040 Ep: 1.48 masked_t 0.443 masked_v 0.096 NSP 0.047 lr 2.43754e-05
04/19/2022 23:19:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64120 Ep: 1.48 masked_t 0.490 masked_v 0.092 NSP 0.043 lr 2.4373e-05
04/19/2022 23:20:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64200 Ep: 1.48 masked_t 0.537 masked_v 0.096 NSP 0.041 lr 2.43705e-05
04/19/2022 23:21:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64280 Ep: 1.48 masked_t 0.489 masked_v 0.091 NSP 0.047 lr 2.43681e-05
04/19/2022 23:22:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64360 Ep: 1.48 masked_t 0.506 masked_v 0.098 NSP 0.046 lr 2.43657e-05
04/19/2022 23:23:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64440 Ep: 1.48 masked_t 0.498 masked_v 0.098 NSP 0.049 lr 2.43633e-05
04/19/2022 23:24:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64520 Ep: 1.49 masked_t 0.496 masked_v 0.098 NSP 0.043 lr 2.43608e-05
04/19/2022 23:25:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64600 Ep: 1.49 masked_t 0.492 masked_v 0.092 NSP 0.046 lr 2.43584e-05
04/19/2022 23:26:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64680 Ep: 1.49 masked_t 0.477 masked_v 0.093 NSP 0.053 lr 2.4356e-05
04/19/2022 23:26:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64760 Ep: 1.49 masked_t 0.477 masked_v 0.094 NSP 0.048 lr 2.43536e-05
04/19/2022 23:27:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64840 Ep: 1.49 masked_t 0.503 masked_v 0.093 NSP 0.049 lr 2.43511e-05
04/19/2022 23:28:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 64920 Ep: 1.50 masked_t 0.519 masked_v 0.092 NSP 0.049 lr 2.43487e-05
04/19/2022 23:29:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65000 Ep: 1.50 masked_t 0.543 masked_v 0.096 NSP 0.042 lr 2.43463e-05
04/19/2022 23:30:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65080 Ep: 1.50 masked_t 0.478 masked_v 0.095 NSP 0.045 lr 2.43439e-05
04/19/2022 23:31:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65160 Ep: 1.50 masked_t 0.532 masked_v 0.095 NSP 0.051 lr 2.43414e-05
04/19/2022 23:32:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65240 Ep: 1.50 masked_t 0.495 masked_v 0.095 NSP 0.054 lr 2.4339e-05
04/19/2022 23:33:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65320 Ep: 1.51 masked_t 0.466 masked_v 0.093 NSP 0.051 lr 2.43366e-05
04/19/2022 23:34:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65400 Ep: 1.51 masked_t 0.526 masked_v 0.096 NSP 0.051 lr 2.43342e-05
04/19/2022 23:35:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65480 Ep: 1.51 masked_t 0.497 masked_v 0.090 NSP 0.048 lr 2.43317e-05
04/19/2022 23:36:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65560 Ep: 1.51 masked_t 0.508 masked_v 0.095 NSP 0.045 lr 2.43293e-05
04/19/2022 23:37:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65640 Ep: 1.51 masked_t 0.532 masked_v 0.097 NSP 0.047 lr 2.43269e-05
04/19/2022 23:38:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65720 Ep: 1.51 masked_t 0.464 masked_v 0.090 NSP 0.045 lr 2.43245e-05
04/19/2022 23:39:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65800 Ep: 1.52 masked_t 0.508 masked_v 0.096 NSP 0.045 lr 2.4322e-05
04/19/2022 23:40:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65880 Ep: 1.52 masked_t 0.504 masked_v 0.091 NSP 0.051 lr 2.43196e-05
04/19/2022 23:41:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 65960 Ep: 1.52 masked_t 0.510 masked_v 0.094 NSP 0.052 lr 2.43172e-05
04/19/2022 23:42:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66040 Ep: 1.52 masked_t 0.493 masked_v 0.095 NSP 0.048 lr 2.43148e-05
04/19/2022 23:43:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66120 Ep: 1.52 masked_t 0.495 masked_v 0.094 NSP 0.042 lr 2.43123e-05
04/19/2022 23:44:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66200 Ep: 1.53 masked_t 0.466 masked_v 0.093 NSP 0.051 lr 2.43099e-05
04/19/2022 23:44:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66280 Ep: 1.53 masked_t 0.516 masked_v 0.093 NSP 0.050 lr 2.43075e-05
04/19/2022 23:45:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66360 Ep: 1.53 masked_t 0.472 masked_v 0.091 NSP 0.042 lr 2.43051e-05
04/19/2022 23:46:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66440 Ep: 1.53 masked_t 0.498 masked_v 0.096 NSP 0.050 lr 2.43026e-05
04/19/2022 23:47:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66520 Ep: 1.53 masked_t 0.508 masked_v 0.094 NSP 0.049 lr 2.43002e-05
04/19/2022 23:48:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66600 Ep: 1.53 masked_t 0.492 masked_v 0.092 NSP 0.040 lr 2.42978e-05
04/19/2022 23:49:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66680 Ep: 1.54 masked_t 0.513 masked_v 0.097 NSP 0.046 lr 2.42954e-05
04/19/2022 23:50:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66760 Ep: 1.54 masked_t 0.498 masked_v 0.094 NSP 0.048 lr 2.42929e-05
04/19/2022 23:51:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66840 Ep: 1.54 masked_t 0.471 masked_v 0.096 NSP 0.047 lr 2.42905e-05
04/19/2022 23:52:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 66920 Ep: 1.54 masked_t 0.507 masked_v 0.095 NSP 0.051 lr 2.42881e-05
04/19/2022 23:53:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67000 Ep: 1.54 masked_t 0.518 masked_v 0.094 NSP 0.052 lr 2.42857e-05
04/19/2022 23:54:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67080 Ep: 1.55 masked_t 0.487 masked_v 0.096 NSP 0.045 lr 2.42832e-05
04/19/2022 23:55:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67160 Ep: 1.55 masked_t 0.466 masked_v 0.094 NSP 0.047 lr 2.42808e-05
04/19/2022 23:56:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67240 Ep: 1.55 masked_t 0.537 masked_v 0.096 NSP 0.046 lr 2.42784e-05
04/19/2022 23:57:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67320 Ep: 1.55 masked_t 0.488 masked_v 0.089 NSP 0.047 lr 2.4276e-05
04/19/2022 23:58:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67400 Ep: 1.55 masked_t 0.497 masked_v 0.094 NSP 0.048 lr 2.42735e-05
04/19/2022 23:59:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67480 Ep: 1.55 masked_t 0.487 masked_v 0.092 NSP 0.053 lr 2.42711e-05
04/20/2022 00:00:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67560 Ep: 1.56 masked_t 0.506 masked_v 0.102 NSP 0.045 lr 2.42687e-05
04/20/2022 00:01:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67640 Ep: 1.56 masked_t 0.513 masked_v 0.098 NSP 0.047 lr 2.42663e-05
04/20/2022 00:01:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67720 Ep: 1.56 masked_t 0.490 masked_v 0.095 NSP 0.055 lr 2.42638e-05
04/20/2022 00:02:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67800 Ep: 1.56 masked_t 0.505 masked_v 0.095 NSP 0.051 lr 2.42614e-05
04/20/2022 00:03:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67880 Ep: 1.56 masked_t 0.482 masked_v 0.095 NSP 0.040 lr 2.4259e-05
04/20/2022 00:04:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 67960 Ep: 1.57 masked_t 0.501 masked_v 0.089 NSP 0.051 lr 2.42565e-05
04/20/2022 00:05:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68040 Ep: 1.57 masked_t 0.554 masked_v 0.096 NSP 0.044 lr 2.42541e-05
04/20/2022 00:06:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68120 Ep: 1.57 masked_t 0.480 masked_v 0.094 NSP 0.050 lr 2.42517e-05
04/20/2022 00:07:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68200 Ep: 1.57 masked_t 0.510 masked_v 0.099 NSP 0.046 lr 2.42493e-05
04/20/2022 00:08:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68280 Ep: 1.57 masked_t 0.487 masked_v 0.098 NSP 0.038 lr 2.42468e-05
04/20/2022 00:09:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68360 Ep: 1.58 masked_t 0.490 masked_v 0.092 NSP 0.049 lr 2.42444e-05
04/20/2022 00:10:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68440 Ep: 1.58 masked_t 0.508 masked_v 0.092 NSP 0.049 lr 2.4242e-05
04/20/2022 00:11:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68520 Ep: 1.58 masked_t 0.488 masked_v 0.095 NSP 0.049 lr 2.42396e-05
04/20/2022 00:12:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68600 Ep: 1.58 masked_t 0.488 masked_v 0.090 NSP 0.043 lr 2.42371e-05
04/20/2022 00:13:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68680 Ep: 1.58 masked_t 0.475 masked_v 0.092 NSP 0.041 lr 2.42347e-05
04/20/2022 00:14:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68760 Ep: 1.58 masked_t 0.460 masked_v 0.095 NSP 0.044 lr 2.42323e-05
04/20/2022 00:15:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68840 Ep: 1.59 masked_t 0.511 masked_v 0.093 NSP 0.043 lr 2.42299e-05
04/20/2022 00:16:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 68920 Ep: 1.59 masked_t 0.488 masked_v 0.096 NSP 0.051 lr 2.42274e-05
04/20/2022 00:17:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69000 Ep: 1.59 masked_t 0.501 masked_v 0.092 NSP 0.049 lr 2.4225e-05
04/20/2022 00:17:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69080 Ep: 1.59 masked_t 0.457 masked_v 0.093 NSP 0.046 lr 2.42226e-05
04/20/2022 00:18:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69160 Ep: 1.59 masked_t 0.484 masked_v 0.096 NSP 0.050 lr 2.42202e-05
04/20/2022 00:19:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69240 Ep: 1.60 masked_t 0.512 masked_v 0.095 NSP 0.044 lr 2.42177e-05
04/20/2022 00:20:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69320 Ep: 1.60 masked_t 0.470 masked_v 0.091 NSP 0.048 lr 2.42153e-05
04/20/2022 00:21:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69400 Ep: 1.60 masked_t 0.508 masked_v 0.093 NSP 0.046 lr 2.42129e-05
04/20/2022 00:22:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69480 Ep: 1.60 masked_t 0.503 masked_v 0.095 NSP 0.048 lr 2.42105e-05
04/20/2022 00:23:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69560 Ep: 1.60 masked_t 0.503 masked_v 0.089 NSP 0.042 lr 2.4208e-05
04/20/2022 00:24:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69640 Ep: 1.60 masked_t 0.512 masked_v 0.096 NSP 0.043 lr 2.42056e-05
04/20/2022 00:25:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69720 Ep: 1.61 masked_t 0.459 masked_v 0.091 NSP 0.058 lr 2.42032e-05
04/20/2022 00:26:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69800 Ep: 1.61 masked_t 0.509 masked_v 0.094 NSP 0.041 lr 2.42008e-05
04/20/2022 00:27:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69880 Ep: 1.61 masked_t 0.528 masked_v 0.090 NSP 0.049 lr 2.41983e-05
04/20/2022 00:28:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 69960 Ep: 1.61 masked_t 0.451 masked_v 0.094 NSP 0.045 lr 2.41959e-05
04/20/2022 00:29:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70040 Ep: 1.61 masked_t 0.485 masked_v 0.093 NSP 0.045 lr 2.41935e-05
04/20/2022 00:30:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70120 Ep: 1.62 masked_t 0.491 masked_v 0.093 NSP 0.040 lr 2.41911e-05
04/20/2022 00:31:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70200 Ep: 1.62 masked_t 0.497 masked_v 0.093 NSP 0.043 lr 2.41886e-05
04/20/2022 00:32:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70280 Ep: 1.62 masked_t 0.490 masked_v 0.092 NSP 0.049 lr 2.41862e-05
04/20/2022 00:33:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70360 Ep: 1.62 masked_t 0.492 masked_v 0.088 NSP 0.047 lr 2.41838e-05
04/20/2022 00:34:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70440 Ep: 1.62 masked_t 0.493 masked_v 0.096 NSP 0.051 lr 2.41814e-05
04/20/2022 00:35:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70520 Ep: 1.62 masked_t 0.467 masked_v 0.092 NSP 0.052 lr 2.41789e-05
04/20/2022 00:35:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70600 Ep: 1.63 masked_t 0.538 masked_v 0.088 NSP 0.054 lr 2.41765e-05
04/20/2022 00:36:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70680 Ep: 1.63 masked_t 0.506 masked_v 0.093 NSP 0.046 lr 2.41741e-05
04/20/2022 00:37:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70760 Ep: 1.63 masked_t 0.505 masked_v 0.089 NSP 0.048 lr 2.41717e-05
04/20/2022 00:38:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70840 Ep: 1.63 masked_t 0.523 masked_v 0.096 NSP 0.035 lr 2.41692e-05
04/20/2022 00:39:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 70920 Ep: 1.63 masked_t 0.524 masked_v 0.092 NSP 0.046 lr 2.41668e-05
04/20/2022 00:40:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71000 Ep: 1.64 masked_t 0.500 masked_v 0.091 NSP 0.048 lr 2.41644e-05
04/20/2022 00:41:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71080 Ep: 1.64 masked_t 0.454 masked_v 0.092 NSP 0.048 lr 2.4162e-05
04/20/2022 00:42:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71160 Ep: 1.64 masked_t 0.537 masked_v 0.095 NSP 0.045 lr 2.41595e-05
04/20/2022 00:43:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71240 Ep: 1.64 masked_t 0.498 masked_v 0.093 NSP 0.045 lr 2.41571e-05
04/20/2022 00:44:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71320 Ep: 1.64 masked_t 0.488 masked_v 0.095 NSP 0.047 lr 2.41547e-05
04/20/2022 00:45:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71400 Ep: 1.65 masked_t 0.488 masked_v 0.091 NSP 0.042 lr 2.41523e-05
04/20/2022 00:46:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71480 Ep: 1.65 masked_t 0.478 masked_v 0.092 NSP 0.050 lr 2.41498e-05
04/20/2022 00:47:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71560 Ep: 1.65 masked_t 0.500 masked_v 0.093 NSP 0.038 lr 2.41474e-05
04/20/2022 00:48:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71640 Ep: 1.65 masked_t 0.476 masked_v 0.091 NSP 0.042 lr 2.4145e-05
04/20/2022 00:49:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71720 Ep: 1.65 masked_t 0.536 masked_v 0.101 NSP 0.038 lr 2.41426e-05
04/20/2022 00:49:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71800 Ep: 1.65 masked_t 0.497 masked_v 0.096 NSP 0.054 lr 2.41401e-05
04/20/2022 00:50:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71880 Ep: 1.66 masked_t 0.483 masked_v 0.092 NSP 0.051 lr 2.41377e-05
04/20/2022 00:51:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 71960 Ep: 1.66 masked_t 0.459 masked_v 0.094 NSP 0.042 lr 2.41353e-05
04/20/2022 00:52:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72040 Ep: 1.66 masked_t 0.529 masked_v 0.095 NSP 0.042 lr 2.41329e-05
04/20/2022 00:53:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72120 Ep: 1.66 masked_t 0.517 masked_v 0.090 NSP 0.050 lr 2.41304e-05
04/20/2022 00:54:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72200 Ep: 1.66 masked_t 0.476 masked_v 0.093 NSP 0.049 lr 2.4128e-05
04/20/2022 00:55:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72280 Ep: 1.67 masked_t 0.473 masked_v 0.090 NSP 0.042 lr 2.41256e-05
04/20/2022 00:56:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72360 Ep: 1.67 masked_t 0.523 masked_v 0.092 NSP 0.049 lr 2.41232e-05
04/20/2022 00:57:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72440 Ep: 1.67 masked_t 0.495 masked_v 0.093 NSP 0.048 lr 2.41207e-05
04/20/2022 00:58:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72520 Ep: 1.67 masked_t 0.460 masked_v 0.088 NSP 0.042 lr 2.41183e-05
04/20/2022 00:59:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72600 Ep: 1.67 masked_t 0.478 masked_v 0.096 NSP 0.050 lr 2.41159e-05
04/20/2022 01:00:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72680 Ep: 1.67 masked_t 0.496 masked_v 0.089 NSP 0.041 lr 2.41134e-05
04/20/2022 01:01:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72760 Ep: 1.68 masked_t 0.483 masked_v 0.093 NSP 0.052 lr 2.4111e-05
04/20/2022 01:02:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72840 Ep: 1.68 masked_t 0.468 masked_v 0.089 NSP 0.041 lr 2.41086e-05
04/20/2022 01:03:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 72920 Ep: 1.68 masked_t 0.503 masked_v 0.091 NSP 0.044 lr 2.41062e-05
04/20/2022 01:04:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73000 Ep: 1.68 masked_t 0.489 masked_v 0.091 NSP 0.044 lr 2.41037e-05
04/20/2022 01:05:01 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73080 Ep: 1.68 masked_t 0.488 masked_v 0.094 NSP 0.045 lr 2.41013e-05
04/20/2022 01:05:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73160 Ep: 1.69 masked_t 0.492 masked_v 0.093 NSP 0.045 lr 2.40989e-05
04/20/2022 01:06:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73240 Ep: 1.69 masked_t 0.539 masked_v 0.095 NSP 0.052 lr 2.40965e-05
04/20/2022 01:07:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73320 Ep: 1.69 masked_t 0.530 masked_v 0.090 NSP 0.043 lr 2.4094e-05
04/20/2022 01:08:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73400 Ep: 1.69 masked_t 0.482 masked_v 0.087 NSP 0.046 lr 2.40916e-05
04/20/2022 01:09:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73480 Ep: 1.69 masked_t 0.422 masked_v 0.090 NSP 0.043 lr 2.40892e-05
04/20/2022 01:10:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73560 Ep: 1.69 masked_t 0.504 masked_v 0.093 NSP 0.049 lr 2.40868e-05
04/20/2022 01:11:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73640 Ep: 1.70 masked_t 0.452 masked_v 0.093 NSP 0.041 lr 2.40843e-05
04/20/2022 01:12:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73720 Ep: 1.70 masked_t 0.498 masked_v 0.095 NSP 0.039 lr 2.40819e-05
04/20/2022 01:13:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73800 Ep: 1.70 masked_t 0.536 masked_v 0.093 NSP 0.040 lr 2.40795e-05
04/20/2022 01:14:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73880 Ep: 1.70 masked_t 0.466 masked_v 0.088 NSP 0.047 lr 2.40771e-05
04/20/2022 01:15:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 73960 Ep: 1.70 masked_t 0.515 masked_v 0.092 NSP 0.045 lr 2.40746e-05
04/20/2022 01:16:15 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74040 Ep: 1.71 masked_t 0.509 masked_v 0.087 NSP 0.047 lr 2.40722e-05
04/20/2022 01:17:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74120 Ep: 1.71 masked_t 0.479 masked_v 0.090 NSP 0.043 lr 2.40698e-05
04/20/2022 01:18:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74200 Ep: 1.71 masked_t 0.511 masked_v 0.092 NSP 0.044 lr 2.40674e-05
04/20/2022 01:19:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74280 Ep: 1.71 masked_t 0.503 masked_v 0.092 NSP 0.044 lr 2.40649e-05
04/20/2022 01:20:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74360 Ep: 1.71 masked_t 0.483 masked_v 0.090 NSP 0.046 lr 2.40625e-05
04/20/2022 01:20:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74440 Ep: 1.72 masked_t 0.526 masked_v 0.092 NSP 0.044 lr 2.40601e-05
04/20/2022 01:21:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74520 Ep: 1.72 masked_t 0.500 masked_v 0.093 NSP 0.041 lr 2.40577e-05
04/20/2022 01:22:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74600 Ep: 1.72 masked_t 0.508 masked_v 0.092 NSP 0.040 lr 2.40552e-05
04/20/2022 01:23:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74680 Ep: 1.72 masked_t 0.491 masked_v 0.092 NSP 0.047 lr 2.40528e-05
04/20/2022 01:24:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74760 Ep: 1.72 masked_t 0.488 masked_v 0.090 NSP 0.044 lr 2.40504e-05
04/20/2022 01:25:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74840 Ep: 1.72 masked_t 0.473 masked_v 0.091 NSP 0.044 lr 2.4048e-05
04/20/2022 01:26:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 74920 Ep: 1.73 masked_t 0.469 masked_v 0.094 NSP 0.051 lr 2.40455e-05
04/20/2022 01:27:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75000 Ep: 1.73 masked_t 0.436 masked_v 0.092 NSP 0.049 lr 2.40431e-05
04/20/2022 01:28:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75080 Ep: 1.73 masked_t 0.531 masked_v 0.094 NSP 0.051 lr 2.40407e-05
04/20/2022 01:29:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75160 Ep: 1.73 masked_t 0.504 masked_v 0.097 NSP 0.053 lr 2.40383e-05
04/20/2022 01:30:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75240 Ep: 1.73 masked_t 0.497 masked_v 0.090 NSP 0.047 lr 2.40358e-05
04/20/2022 01:31:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75320 Ep: 1.74 masked_t 0.488 masked_v 0.089 NSP 0.047 lr 2.40334e-05
04/20/2022 01:32:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75400 Ep: 1.74 masked_t 0.481 masked_v 0.091 NSP 0.051 lr 2.4031e-05
04/20/2022 01:33:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75480 Ep: 1.74 masked_t 0.516 masked_v 0.087 NSP 0.037 lr 2.40286e-05
04/20/2022 01:34:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75560 Ep: 1.74 masked_t 0.527 masked_v 0.091 NSP 0.047 lr 2.40261e-05
04/20/2022 01:34:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75640 Ep: 1.74 masked_t 0.522 masked_v 0.091 NSP 0.048 lr 2.40237e-05
04/20/2022 01:35:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75720 Ep: 1.74 masked_t 0.433 masked_v 0.090 NSP 0.044 lr 2.40213e-05
04/20/2022 01:36:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75800 Ep: 1.75 masked_t 0.503 masked_v 0.092 NSP 0.045 lr 2.40189e-05
04/20/2022 01:37:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75880 Ep: 1.75 masked_t 0.445 masked_v 0.092 NSP 0.044 lr 2.40164e-05
04/20/2022 01:38:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 75960 Ep: 1.75 masked_t 0.498 masked_v 0.089 NSP 0.044 lr 2.4014e-05
04/20/2022 01:39:40 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76040 Ep: 1.75 masked_t 0.483 masked_v 0.089 NSP 0.048 lr 2.40116e-05
04/20/2022 01:40:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76120 Ep: 1.75 masked_t 0.476 masked_v 0.093 NSP 0.045 lr 2.40092e-05
04/20/2022 01:41:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76200 Ep: 1.76 masked_t 0.481 masked_v 0.089 NSP 0.043 lr 2.40067e-05
04/20/2022 01:42:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76280 Ep: 1.76 masked_t 0.540 masked_v 0.088 NSP 0.048 lr 2.40043e-05
04/20/2022 01:43:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76360 Ep: 1.76 masked_t 0.471 masked_v 0.091 NSP 0.040 lr 2.40019e-05
04/20/2022 01:44:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76440 Ep: 1.76 masked_t 0.517 masked_v 0.090 NSP 0.043 lr 2.39995e-05
04/20/2022 01:45:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76520 Ep: 1.76 masked_t 0.473 masked_v 0.095 NSP 0.044 lr 2.3997e-05
04/20/2022 01:46:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76600 Ep: 1.76 masked_t 0.515 masked_v 0.088 NSP 0.047 lr 2.39946e-05
04/20/2022 01:47:10 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76680 Ep: 1.77 masked_t 0.482 masked_v 0.089 NSP 0.054 lr 2.39922e-05
04/20/2022 01:48:06 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76760 Ep: 1.77 masked_t 0.502 masked_v 0.086 NSP 0.044 lr 2.39898e-05
04/20/2022 01:49:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76840 Ep: 1.77 masked_t 0.519 masked_v 0.090 NSP 0.040 lr 2.39873e-05
04/20/2022 01:49:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 76920 Ep: 1.77 masked_t 0.470 masked_v 0.090 NSP 0.044 lr 2.39849e-05
04/20/2022 01:50:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77000 Ep: 1.77 masked_t 0.508 masked_v 0.089 NSP 0.047 lr 2.39825e-05
04/20/2022 01:51:51 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77080 Ep: 1.78 masked_t 0.472 masked_v 0.087 NSP 0.046 lr 2.39801e-05
04/20/2022 01:52:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77160 Ep: 1.78 masked_t 0.469 masked_v 0.091 NSP 0.051 lr 2.39776e-05
04/20/2022 01:53:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77240 Ep: 1.78 masked_t 0.482 masked_v 0.086 NSP 0.043 lr 2.39752e-05
04/20/2022 01:54:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77320 Ep: 1.78 masked_t 0.532 masked_v 0.085 NSP 0.041 lr 2.39728e-05
04/20/2022 01:55:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77400 Ep: 1.78 masked_t 0.493 masked_v 0.090 NSP 0.046 lr 2.39703e-05
04/20/2022 01:56:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77480 Ep: 1.79 masked_t 0.501 masked_v 0.087 NSP 0.052 lr 2.39679e-05
04/20/2022 01:57:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77560 Ep: 1.79 masked_t 0.434 masked_v 0.089 NSP 0.047 lr 2.39655e-05
04/20/2022 01:58:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77640 Ep: 1.79 masked_t 0.477 masked_v 0.086 NSP 0.043 lr 2.39631e-05
04/20/2022 01:59:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77720 Ep: 1.79 masked_t 0.499 masked_v 0.094 NSP 0.047 lr 2.39606e-05
04/20/2022 02:00:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77800 Ep: 1.79 masked_t 0.479 masked_v 0.091 NSP 0.053 lr 2.39582e-05
04/20/2022 02:01:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77880 Ep: 1.79 masked_t 0.468 masked_v 0.091 NSP 0.042 lr 2.39558e-05
04/20/2022 02:02:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 77960 Ep: 1.80 masked_t 0.487 masked_v 0.088 NSP 0.047 lr 2.39534e-05
04/20/2022 02:03:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78040 Ep: 1.80 masked_t 0.496 masked_v 0.089 NSP 0.047 lr 2.39509e-05
04/20/2022 02:04:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78120 Ep: 1.80 masked_t 0.478 masked_v 0.094 NSP 0.045 lr 2.39485e-05
04/20/2022 02:04:56 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78200 Ep: 1.80 masked_t 0.480 masked_v 0.093 NSP 0.039 lr 2.39461e-05
04/20/2022 02:05:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78280 Ep: 1.80 masked_t 0.489 masked_v 0.092 NSP 0.044 lr 2.39437e-05
04/20/2022 02:06:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78360 Ep: 1.81 masked_t 0.495 masked_v 0.090 NSP 0.044 lr 2.39412e-05
04/20/2022 02:07:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78440 Ep: 1.81 masked_t 0.506 masked_v 0.086 NSP 0.044 lr 2.39388e-05
04/20/2022 02:08:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78520 Ep: 1.81 masked_t 0.524 masked_v 0.090 NSP 0.046 lr 2.39364e-05
04/20/2022 02:09:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78600 Ep: 1.81 masked_t 0.456 masked_v 0.092 NSP 0.051 lr 2.3934e-05
04/20/2022 02:10:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78680 Ep: 1.81 masked_t 0.483 masked_v 0.090 NSP 0.043 lr 2.39315e-05
04/20/2022 02:11:30 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78760 Ep: 1.81 masked_t 0.508 masked_v 0.092 NSP 0.043 lr 2.39291e-05
04/20/2022 02:12:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78840 Ep: 1.82 masked_t 0.498 masked_v 0.088 NSP 0.039 lr 2.39267e-05
04/20/2022 02:13:23 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 78920 Ep: 1.82 masked_t 0.463 masked_v 0.091 NSP 0.037 lr 2.39243e-05
04/20/2022 02:14:19 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79000 Ep: 1.82 masked_t 0.531 masked_v 0.093 NSP 0.049 lr 2.39218e-05
04/20/2022 02:15:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79080 Ep: 1.82 masked_t 0.517 masked_v 0.090 NSP 0.043 lr 2.39194e-05
04/20/2022 02:16:12 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79160 Ep: 1.82 masked_t 0.526 masked_v 0.086 NSP 0.047 lr 2.3917e-05
04/20/2022 02:17:08 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79240 Ep: 1.83 masked_t 0.478 masked_v 0.090 NSP 0.046 lr 2.39146e-05
04/20/2022 02:18:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79320 Ep: 1.83 masked_t 0.495 masked_v 0.091 NSP 0.044 lr 2.39121e-05
04/20/2022 02:19:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79400 Ep: 1.83 masked_t 0.484 masked_v 0.085 NSP 0.042 lr 2.39097e-05
04/20/2022 02:19:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79480 Ep: 1.83 masked_t 0.498 masked_v 0.090 NSP 0.052 lr 2.39073e-05
04/20/2022 02:20:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79560 Ep: 1.83 masked_t 0.471 masked_v 0.091 NSP 0.048 lr 2.39049e-05
04/20/2022 02:21:49 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79640 Ep: 1.83 masked_t 0.487 masked_v 0.090 NSP 0.041 lr 2.39024e-05
04/20/2022 02:22:45 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79720 Ep: 1.84 masked_t 0.510 masked_v 0.087 NSP 0.045 lr 2.39e-05
04/20/2022 02:23:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79800 Ep: 1.84 masked_t 0.510 masked_v 0.088 NSP 0.049 lr 2.38976e-05
04/20/2022 02:24:38 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79880 Ep: 1.84 masked_t 0.488 masked_v 0.089 NSP 0.044 lr 2.38952e-05
04/20/2022 02:25:34 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 79960 Ep: 1.84 masked_t 0.420 masked_v 0.088 NSP 0.047 lr 2.38927e-05
04/20/2022 02:26:02 - INFO - __main__ -   ** ** * Saving model * ** ** 
04/20/2022 02:27:04 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80040 Ep: 1.84 masked_t 0.507 masked_v 0.091 NSP 0.041 lr 2.38903e-05
04/20/2022 02:28:00 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80120 Ep: 1.85 masked_t 0.496 masked_v 0.091 NSP 0.040 lr 2.38879e-05
04/20/2022 02:28:57 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80200 Ep: 1.85 masked_t 0.493 masked_v 0.096 NSP 0.054 lr 2.38855e-05
04/20/2022 02:29:53 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80280 Ep: 1.85 masked_t 0.492 masked_v 0.097 NSP 0.049 lr 2.3883e-05
04/20/2022 02:30:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80360 Ep: 1.85 masked_t 0.488 masked_v 0.092 NSP 0.043 lr 2.38806e-05
04/20/2022 02:31:46 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80440 Ep: 1.85 masked_t 0.466 masked_v 0.091 NSP 0.050 lr 2.38782e-05
04/20/2022 02:32:42 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80520 Ep: 1.86 masked_t 0.507 masked_v 0.090 NSP 0.045 lr 2.38758e-05
04/20/2022 02:33:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80600 Ep: 1.86 masked_t 0.492 masked_v 0.090 NSP 0.045 lr 2.38733e-05
04/20/2022 02:34:35 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80680 Ep: 1.86 masked_t 0.483 masked_v 0.093 NSP 0.043 lr 2.38709e-05
04/20/2022 02:35:31 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80760 Ep: 1.86 masked_t 0.496 masked_v 0.093 NSP 0.041 lr 2.38685e-05
04/20/2022 02:36:27 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80840 Ep: 1.86 masked_t 0.484 masked_v 0.090 NSP 0.048 lr 2.38661e-05
04/20/2022 02:37:24 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 80920 Ep: 1.86 masked_t 0.453 masked_v 0.089 NSP 0.046 lr 2.38636e-05
04/20/2022 02:38:20 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81000 Ep: 1.87 masked_t 0.472 masked_v 0.090 NSP 0.052 lr 2.38612e-05
04/20/2022 02:39:16 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81080 Ep: 1.87 masked_t 0.528 masked_v 0.088 NSP 0.038 lr 2.38588e-05
04/20/2022 02:40:13 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81160 Ep: 1.87 masked_t 0.477 masked_v 0.087 NSP 0.044 lr 2.38564e-05
04/20/2022 02:41:09 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81240 Ep: 1.87 masked_t 0.512 masked_v 0.090 NSP 0.048 lr 2.38539e-05
04/20/2022 02:42:05 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81320 Ep: 1.87 masked_t 0.516 masked_v 0.084 NSP 0.046 lr 2.38515e-05
04/20/2022 02:43:02 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81400 Ep: 1.88 masked_t 0.504 masked_v 0.090 NSP 0.046 lr 2.38491e-05
04/20/2022 02:43:58 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81480 Ep: 1.88 masked_t 0.466 masked_v 0.089 NSP 0.048 lr 2.38467e-05
04/20/2022 02:44:54 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81560 Ep: 1.88 masked_t 0.510 masked_v 0.089 NSP 0.045 lr 2.38442e-05
04/20/2022 02:45:50 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81640 Ep: 1.88 masked_t 0.507 masked_v 0.092 NSP 0.047 lr 2.38418e-05
04/20/2022 02:46:47 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81720 Ep: 1.88 masked_t 0.467 masked_v 0.088 NSP 0.042 lr 2.38394e-05
04/20/2022 02:47:43 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81800 Ep: 1.88 masked_t 0.491 masked_v 0.088 NSP 0.053 lr 2.3837e-05
04/20/2022 02:48:39 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81880 Ep: 1.89 masked_t 0.498 masked_v 0.086 NSP 0.040 lr 2.38345e-05
04/20/2022 02:49:36 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 81960 Ep: 1.89 masked_t 0.485 masked_v 0.088 NSP 0.045 lr 2.38321e-05
04/20/2022 02:50:32 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82040 Ep: 1.89 masked_t 0.498 masked_v 0.095 NSP 0.048 lr 2.38297e-05
04/20/2022 02:51:28 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82120 Ep: 1.89 masked_t 0.492 masked_v 0.087 NSP 0.043 lr 2.38272e-05
04/20/2022 02:52:25 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82200 Ep: 1.89 masked_t 0.461 masked_v 0.089 NSP 0.044 lr 2.38248e-05
04/20/2022 02:53:21 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82280 Ep: 1.90 masked_t 0.478 masked_v 0.091 NSP 0.039 lr 2.38224e-05
04/20/2022 02:54:17 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82360 Ep: 1.90 masked_t 0.478 masked_v 0.088 NSP 0.045 lr 2.382e-05
04/20/2022 02:55:14 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82440 Ep: 1.90 masked_t 0.499 masked_v 0.085 NSP 0.045 lr 2.38175e-05
04/20/2022 02:56:11 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82520 Ep: 1.90 masked_t 0.502 masked_v 0.089 NSP 0.040 lr 2.38151e-05
04/20/2022 02:57:07 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82600 Ep: 1.90 masked_t 0.478 masked_v 0.087 NSP 0.042 lr 2.38127e-05
04/20/2022 02:58:03 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82680 Ep: 1.91 masked_t 0.484 masked_v 0.091 NSP 0.039 lr 2.38103e-05
04/20/2022 02:58:59 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82760 Ep: 1.91 masked_t 0.499 masked_v 0.090 NSP 0.044 lr 2.38078e-05
04/20/2022 02:59:55 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82840 Ep: 1.91 masked_t 0.495 masked_v 0.090 NSP 0.040 lr 2.38054e-05
04/20/2022 03:00:52 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 82920 Ep: 1.91 masked_t 0.452 masked_v 0.088 NSP 0.040 lr 2.3803e-05
04/20/2022 03:01:48 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83000 Ep: 1.91 masked_t 0.489 masked_v 0.091 NSP 0.044 lr 2.38006e-05
04/20/2022 03:02:44 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83080 Ep: 1.91 masked_t 0.480 masked_v 0.086 NSP 0.041 lr 2.37981e-05
04/20/2022 03:03:41 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83160 Ep: 1.92 masked_t 0.483 masked_v 0.087 NSP 0.046 lr 2.37957e-05
04/20/2022 03:04:37 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83240 Ep: 1.92 masked_t 0.482 masked_v 0.091 NSP 0.042 lr 2.37933e-05
04/20/2022 03:05:33 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83320 Ep: 1.92 masked_t 0.484 masked_v 0.093 NSP 0.042 lr 2.37909e-05
04/20/2022 03:06:29 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83400 Ep: 1.92 masked_t 0.464 masked_v 0.087 NSP 0.049 lr 2.37884e-05
04/20/2022 03:07:26 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83480 Ep: 1.92 masked_t 0.503 masked_v 0.084 NSP 0.042 lr 2.3786e-05
04/20/2022 03:08:22 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83560 Ep: 1.93 masked_t 0.456 masked_v 0.088 NSP 0.044 lr 2.37836e-05
04/20/2022 03:09:18 - INFO - volta.train_utils -   [Conceptual_Caption]: iter 83640 Ep: 1.93 masked_t 0.500 masked_v 0.086 NSP 0.041 lr 2.37812e-05
slurmstepd: error: *** JOB 2128137 ON a00883 CANCELLED AT 2022-04-20T03:09:41 DUE TO TIME LIMIT ***
